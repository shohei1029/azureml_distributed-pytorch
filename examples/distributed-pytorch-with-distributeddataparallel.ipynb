{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Copyright (c) Microsoft Corporation. All rights reserved.\n",
        "\n",
        "Licensed under the MIT License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/how-to-use-azureml/ml-frameworks/pytorch/distributed-pytorch-with-horovod/distributed-pytorch-with-horovod.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Distributed PyTorch with DistributedDataParallel\n",
        "\n",
        "In this tutorial, you will train a PyTorch model on the [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset using distributed training with PyTorch's `DistributedDataParallel` module across a GPU cluster."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 前提条件確認 Prerequisites\n",
        "* If you are using an Azure Machine Learning Notebook VM, you are all set. Otherwise, go through the [Configuration](../../../../configuration.ipynb) notebook to install the Azure Machine Learning Python SDK and create an Azure ML `Workspace`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SDK version: 1.25.0\n"
          ]
        }
      ],
      "source": [
        "# Check core SDK version number\n",
        "import azureml.core\n",
        "\n",
        "print(\"SDK version:\", azureml.core.VERSION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Diagnostics\n",
        "Opt-in diagnostics for better experience, quality, and security of future releases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "tags": [
          "Diagnostics"
        ]
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Turning diagnostics collection on. \n"
          ]
        }
      ],
      "source": [
        "from azureml.telemetry import set_diagnostics_collection\n",
        "\n",
        "set_diagnostics_collection(send_diagnostics=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ワークスペースの設定 Initialize workspace\n",
        "\n",
        "Initialize a [Workspace](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#workspace) object from the existing workspace you created in the Prerequisites step. `Workspace.from_config()` creates a workspace object from the details stored in `config.json`.  \n",
        "Azure ML Studioから構成ファイル (config.json)をダウンロードし、本スクリプトと同一階層に置きます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing interactive authentication. Please follow the instructions on the terminal.\n",
            "To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code SKHZC45VX to authenticate.\n",
            "You have logged in. Now let us find all the subscriptions to which you have access...\n",
            "Failed to authenticate to tenant '488ea627-1f1a-452d-8eb1-904f5c36ec3a' due to error 'Get Token request returned http error: 400 and server response: {\"error\":\"interaction_required\",\"error_description\":\"AADSTS50076: Due to a configuration change made by your administrator, or because you moved to a new location, you must use multi-factor authentication to access '797f4846-ba00-4fd7-ba43-dac1f8f63013'.\\r\\nTrace ID: 514d42f0-728c-4d84-a218-e247b9c54400\\r\\nCorrelation ID: bf9a6664-1885-419a-b2e6-69621e9b81ca\\r\\nTimestamp: 2021-03-29 04:04:12Z\",\"error_codes\":[50076],\"timestamp\":\"2021-03-29 04:04:12Z\",\"trace_id\":\"514d42f0-728c-4d84-a218-e247b9c54400\",\"correlation_id\":\"bf9a6664-1885-419a-b2e6-69621e9b81ca\",\"error_uri\":\"https://login.microsoftonline.com/error?code=50076\",\"suberror\":\"basic_action\"}'.Will continue to look for other tenants to find subscriptions to which you have access\n",
            "Interactive authentication successfully completed.\n",
            "Workspace name: ml-lab\n",
            "Azure region: westus2\n",
            "Subscription id: f57ce3c6-5c6f-4f1e-8cba-b782d8974590\n",
            "Resource group: rg-aml\n"
          ]
        }
      ],
      "source": [
        "from azureml.core.workspace import Workspace\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "print('Workspace name: ' + ws.name, \n",
        "      'Azure region: ' + ws.location, \n",
        "      'Subscription id: ' + ws.subscription_id, \n",
        "      'Resource group: ' + ws.resource_group, sep='\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 計算環境の準備 Create or attach existing AmlCompute\n",
        "You will need to create a [compute target](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#compute-target) for training your model. In this tutorial, we use Azure ML managed compute ([AmlCompute](https://docs.microsoft.com/azure/machine-learning/service/how-to-set-up-training-targets#amlcompute)) for our remote training compute resource. Specifically, the below code creates an `STANDARD_NC6` GPU cluster that autoscales from `0` to `4` nodes.\n",
        "\n",
        "**Creation of AmlCompute takes approximately 5 minutes.** If the AmlCompute with that name is already in your workspace, this code will skip the creation process.\n",
        "\n",
        "As with other Azure services, there are limits on certain resources (e.g. AmlCompute) associated with the Azure Machine Learning service. Please read [this article](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-manage-quotas) on the default limits and how to request more quota."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing compute target.\n",
            "{'currentNodeCount': 0, 'targetNodeCount': 0, 'nodeStateCounts': {'preparingNodeCount': 0, 'runningNodeCount': 0, 'idleNodeCount': 0, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2021-03-23T03:45:29.543000+00:00', 'errors': None, 'creationTime': '2021-03-22T09:03:01.130767+00:00', 'modifiedTime': '2021-03-22T09:03:16.578884+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 4, 'nodeIdleTimeBeforeScaleDown': 'PT120S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_NC6'}\n"
          ]
        }
      ],
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "# choose a name for your cluster\n",
        "cluster_name = 'gpu-cluster'\n",
        "\n",
        "try:\n",
        "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
        "    print('Found existing compute target.')\n",
        "except ComputeTargetException:\n",
        "    print('Creating a new compute target...')\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_NC6',\n",
        "                                                           max_nodes=4)\n",
        "\n",
        "    # create the cluster\n",
        "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
        "\n",
        "    compute_target.wait_for_completion(show_output=True)\n",
        "\n",
        "# use get_status() to get a detailed status for the current AmlCompute. \n",
        "print(compute_target.get_status().serialize())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The above code creates GPU compute. If you instead want to create CPU compute, provide a different VM size to the `vm_size` parameter, such as `STANDARD_D2_V2`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## データセットの準備 Prepare dataset\n",
        "\n",
        "Prepare the dataset used for training. We will first download and extract the publicly available CIFAR-10 dataset from the cs.toronto.edu website and then create an Azure ML FileDataset to use the data for training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Download and extract CIFAR-10 data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import urllib\n",
        "import tarfile\n",
        "import os\n",
        "\n",
        "url = 'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'\n",
        "filename = 'cifar-10-python.tar.gz'\n",
        "data_root = 'cifar-10'\n",
        "filepath = os.path.join(data_root, filename)\n",
        "\n",
        "if not os.path.isdir(data_root):\n",
        "    os.makedirs(data_root, exist_ok=True)\n",
        "    urllib.request.urlretrieve(url, filepath)\n",
        "    with tarfile.open(filepath, \"r:gz\") as tar:\n",
        "        tar.extractall(path=data_root)\n",
        "    os.remove(filepath)  # delete tar.gz file after extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create Azure ML dataset\n",
        "\n",
        "The `upload_directory` method will upload the data to a datastore and create a FileDataset from it. In this tutorial we will use the workspace's default datastore."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Method upload_directory: This is an experimental method, and may change at any time.<br/>For more information, see https://aka.ms/azuremlexperimental.\n",
            "Validating arguments.\n",
            "Arguments validated.\n",
            "Uploading file to cifar-10\n",
            "Uploading an estimated of 8 files\n",
            "Target already exists. Skipping upload for cifar-10/cifar-10-batches-py/data_batch_5\n",
            "Target already exists. Skipping upload for cifar-10/cifar-10-batches-py/batches.meta\n",
            "Target already exists. Skipping upload for cifar-10/cifar-10-batches-py/test_batch\n",
            "Target already exists. Skipping upload for cifar-10/cifar-10-batches-py/data_batch_4\n",
            "Target already exists. Skipping upload for cifar-10/cifar-10-batches-py/data_batch_3\n",
            "Target already exists. Skipping upload for cifar-10/cifar-10-batches-py/data_batch_1\n",
            "Target already exists. Skipping upload for cifar-10/cifar-10-batches-py/readme.html\n",
            "Target already exists. Skipping upload for cifar-10/cifar-10-batches-py/data_batch_2\n",
            "Uploaded 0 files\n",
            "Creating new dataset\n"
          ]
        }
      ],
      "source": [
        "from azureml.core import Dataset\n",
        "\n",
        "datastore = ws.get_default_datastore()\n",
        "dataset = Dataset.File.upload_directory(\n",
        "    src_dir=data_root, target=(datastore, data_root)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## モデル学習 Train model on the remote compute\n",
        "Now that we have the AmlCompute ready to go, let's run our distributed training job."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create a project directory\n",
        "Create a directory that will contain all the necessary code from your local machine that you will need access to on the remote resource. This includes the training script and any additional files your training script depends on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "project_folder = './pytorch-distr'\n",
        "os.makedirs(project_folder, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prepare training script\n",
        "Now you will need to create your training script. In this tutorial, the script for distributed training on CIFAR-10 is already provided for you at `train.py`. In practice, you should be able to take any custom PyTorch training script as is and run it with Azure ML without having to modify your code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once your script is ready, copy the training script `train.py` into the project directory.\n",
        "トレーニングスクリプトをプロジェクトディレクトリ内へコピーします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./pytorch-distr/train.py'"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import shutil\n",
        "\n",
        "shutil.copy('train.py', project_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create an experiment\n",
        "Create an [Experiment](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#experiment) to track all the runs in your workspace for this distributed PyTorch tutorial. \n",
        "実験を設定します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core import Experiment\n",
        "\n",
        "experiment_name = 'pytorch-distr'\n",
        "experiment = Experiment(ws, name=experiment_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create an environment\n",
        "\n",
        "In this tutorial, we will use one of Azure ML's curated PyTorch environments for training. [Curated environments](https://docs.microsoft.com/azure/machine-learning/how-to-use-environments#use-a-curated-environment) are available in your workspace by default. Specifically, we will use the PyTorch 1.6 GPU curated environment.  \n",
        "\n",
        "Azure MLではいくつかの[キュレートされた実行環境](https://docs.microsoft.com/ja-jp/azure/machine-learning/how-to-use-environments#use-a-curated-environment)が用意されています。\n",
        "今回はPyTorch 1.6 GPU環境を使用します。こちらのキュレートされた環境には今回のトレーニングスクリプトで必要なtorch, torchvisionも含まれています。\n",
        "\n",
        "参考：[キュレーションされた環境一覧](https://docs.microsoft.com/ja-jp/azure/machine-learning/resource-curated-environments)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core import Environment\n",
        "\n",
        "pytorch_env = Environment.get(ws, name='AzureML-PyTorch-1.6-GPU')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Configure the training job\n",
        "\n",
        "To launch a distributed PyTorch job on Azure ML, you have two options:\n",
        "\n",
        "1. Per-process launch - specify the total # of worker processes (typically one per GPU) you want to run, and\n",
        "Azure ML will handle launching each process.\n",
        "2. Per-node launch with [torch.distributed.launch](https://pytorch.org/docs/stable/distributed.html#launch-utility) - provide the `torch.distributed.launch` command you want to\n",
        "run on each node.\n",
        "\n",
        "For more information, see the [documentation](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-train-pytorch#distributeddataparallel).\n",
        "\n",
        "Both options are shown below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Per-process launch\n",
        "\n",
        "To use the per-process launch option in which Azure ML will handle launching each of the processes to run your training script,\n",
        "\n",
        "1. Specify the training script and arguments\n",
        "2. Create a `PyTorchConfiguration` and specify `node_count` and `process_count`. The `process_count` is the total number of processes you want to run for the job; this should typically equal the # of GPUs available on each node multiplied by the # of nodes. Since this tutorial uses the `STANDARD_NC6` SKU, which has one GPU, the total process count for a 2-node job is `2`. If you are using a SKU with >1 GPUs, adjust the `process_count` accordingly.\n",
        "\n",
        "Azure ML will set the `MASTER_ADDR`, `MASTER_PORT`, `NODE_RANK`, `WORLD_SIZE` environment variables on each node, in addition to the process-level `RANK` and `LOCAL_RANK` environment variables, that are needed for distributed PyTorch training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core import ScriptRunConfig\n",
        "from azureml.core.runconfig import PyTorchConfiguration\n",
        "\n",
        "# create distributed config\n",
        "distr_config = PyTorchConfiguration(process_count=2, node_count=2)\n",
        "\n",
        "# create args\n",
        "args = [\"--data-dir\", dataset.as_download(), \"--epochs\", 25]\n",
        "\n",
        "# create job config\n",
        "src = ScriptRunConfig(source_directory=project_folder,\n",
        "                      script='train.py',\n",
        "                      arguments=args,\n",
        "                      compute_target=compute_target,\n",
        "                      environment=pytorch_env,\n",
        "                      distributed_job_config=distr_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Per-node launch with `torch.distributed.launch`\n",
        "\n",
        "If you would instead like to use the PyTorch-provided launch utility `torch.distributed.launch` to handle launching the worker processes on each node, you can do so as well. \n",
        "\n",
        "1. Provide the launch command to the `command` parameter of ScriptRunConfig. For PyTorch jobs Azure ML will set the `MASTER_ADDR`, `MASTER_PORT`, and `NODE_RANK` environment variables on each node, so you can simply just reference those environment variables in your command. If you are using a SKU with >1 GPUs, adjust the `--nproc_per_node` argument accordingly.\n",
        "\n",
        "2. Create a `PyTorchConfiguration` and specify the `node_count`. You do not need to specify the `process_count`; by default Azure ML will launch one process per node to run the `command` you provided.\n",
        "\n",
        "Uncomment the code below to configure a job with this method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "from azureml.core import ScriptRunConfig\n",
        "from azureml.core.runconfig import PyTorchConfiguration\n",
        "\n",
        "# create distributed config\n",
        "distr_config = PyTorchConfiguration(node_count=2)\n",
        "\n",
        "# define command\n",
        "launch_cmd = [\"python -m torch.distributed.launch --nproc_per_node 1 --nnodes 2 \" \\\n",
        "    \"--node_rank $NODE_RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT --use_env \" \\\n",
        "    \"train.py --data-dir\", dataset.as_download(), \"--epochs 25\"]\n",
        "\n",
        "# create job config\n",
        "src = ScriptRunConfig(source_directory=project_folder,\n",
        "                      command=launch_cmd,\n",
        "                      compute_target=compute_target,\n",
        "                      environment=pytorch_env,\n",
        "                      distributed_job_config=distr_config)\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Submit job\n",
        "Run your experiment by submitting your `ScriptRunConfig` object. Note that this call is asynchronous."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run(Experiment: pytorch-distr,\nId: pytorch-distr_1616991319_6f6aaad5,\nType: azureml.scriptrun,\nStatus: Preparing)\n"
          ]
        }
      ],
      "source": [
        "run = experiment.submit(src)\n",
        "print(run)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Monitor your run\n",
        "You can monitor the progress of the run with a Jupyter widget. Like the run submission, the widget is asynchronous and provides live updates every 10-15 seconds until the job completes. You can see that the widget automatically plots and visualizes the loss metric that we logged to the Azure ML run.\n",
        "\n",
        "Jupyterウィジェットを使って実行の進捗状況を監視することができます。実行のサブミッションと同様に、ウィジェットは非同期で、ジョブが完了するまで10～15秒ごとに自動で更新されます。ウィジェットでは、Azure MLの実行に記録した損失指標が自動的に表示・可視化されます。\n",
        "\n",
        "※VSCode上で実行する場合、テーマ設定 (背景色)によってはAzure MLウィジェットが見えにくくなる可能性があります。その場合はLightテーマの使用をお勧めします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': True, 'log_level': 'INFO', 's…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "073865e668044f60a4dbbaed2f81442a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/pytorch-distr_1616991319_6f6aaad5?wsid=/subscriptions/f57ce3c6-5c6f-4f1e-8cba-b782d8974590/resourcegroups/rg-aml/workspaces/ml-lab&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\", \"run_id\": \"pytorch-distr_1616991319_6f6aaad5\", \"run_properties\": {\"run_id\": \"pytorch-distr_1616991319_6f6aaad5\", \"created_utc\": \"2021-03-29T04:15:20.71831Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"amlcompute\", \"ContentSnapshotId\": \"c0226cb2-4817-4968-8d05-686acc882c88\", \"azureml.git.repository_uri\": \"git@github.com:shohei1029/azureml_distributed-pytorch.git\", \"mlflow.source.git.repoURL\": \"git@github.com:shohei1029/azureml_distributed-pytorch.git\", \"azureml.git.branch\": \"main\", \"mlflow.source.git.branch\": \"main\", \"azureml.git.commit\": \"d0aca0d1988dc18c160cf520e0a8a845cc590216\", \"mlflow.source.git.commit\": \"d0aca0d1988dc18c160cf520e0a8a845cc590216\", \"azureml.git.dirty\": \"False\", \"ProcessInfoFile\": \"azureml-logs/process_info.json\", \"ProcessStatusFile\": \"azureml-logs/process_status.json\"}, \"tags\": {\"_aml_system_ComputeTargetStatus\": \"{\\\"AllocationState\\\":\\\"steady\\\",\\\"PreparingNodeCount\\\":0,\\\"RunningNodeCount\\\":0,\\\"CurrentNodeCount\\\":0}\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2021-03-29T04:30:16.24287Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/55_azureml-execution-tvmps_0f0f37b68e6c774922818cffea473a3031fe5b5294858c9e3c5d655c581e7600_d.txt\": \"https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616991319_6f6aaad5/azureml-logs/55_azureml-execution-tvmps_0f0f37b68e6c774922818cffea473a3031fe5b5294858c9e3c5d655c581e7600_d.txt?sv=2019-02-02&sr=b&sig=0xuMEPrTjNtIppHl94HRyX9Vb7A7ky87m%2BClOCpJ%2BzY%3D&st=2021-03-29T06%3A21%3A21Z&se=2021-03-29T14%3A31%3A21Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_e84f1fe707c074c991d63ec32397d2a9a809fe61f0a474b5e4f5e9d46be963cf_d.txt\": \"https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616991319_6f6aaad5/azureml-logs/55_azureml-execution-tvmps_e84f1fe707c074c991d63ec32397d2a9a809fe61f0a474b5e4f5e9d46be963cf_d.txt?sv=2019-02-02&sr=b&sig=Qe%2FbITXGbxtvNs7RDUGuJ%2B7C8w6s07zjbupeUxGvzOM%3D&st=2021-03-29T06%3A21%3A21Z&se=2021-03-29T14%3A31%3A21Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_0f0f37b68e6c774922818cffea473a3031fe5b5294858c9e3c5d655c581e7600_d.txt\": \"https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616991319_6f6aaad5/azureml-logs/65_job_prep-tvmps_0f0f37b68e6c774922818cffea473a3031fe5b5294858c9e3c5d655c581e7600_d.txt?sv=2019-02-02&sr=b&sig=%2B3V2Hv54iMOYF%2FnSbktFVuVfzgUGDby3PcfjUA1lBkM%3D&st=2021-03-29T06%3A21%3A21Z&se=2021-03-29T14%3A31%3A21Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_e84f1fe707c074c991d63ec32397d2a9a809fe61f0a474b5e4f5e9d46be963cf_d.txt\": \"https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616991319_6f6aaad5/azureml-logs/65_job_prep-tvmps_e84f1fe707c074c991d63ec32397d2a9a809fe61f0a474b5e4f5e9d46be963cf_d.txt?sv=2019-02-02&sr=b&sig=7PgjG4eOK1axRVGMhkXlSiOz7Uo3BiBC3khnkn5OfSg%3D&st=2021-03-29T06%3A21%3A21Z&se=2021-03-29T14%3A31%3A21Z&sp=r\", \"azureml-logs/70_driver_log_0.txt\": \"https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616991319_6f6aaad5/azureml-logs/70_driver_log_0.txt?sv=2019-02-02&sr=b&sig=2aCYYqqXpnvy0wOaOnRbMSd2xrLzuGFOrNco1cZ6DLU%3D&st=2021-03-29T06%3A21%3A21Z&se=2021-03-29T14%3A31%3A21Z&sp=r\", \"azureml-logs/70_driver_log_1.txt\": \"https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616991319_6f6aaad5/azureml-logs/70_driver_log_1.txt?sv=2019-02-02&sr=b&sig=6uDhVPyxeUpf2yeIta2kSITgMRMUYk%2F%2FmFfPcDYKtDo%3D&st=2021-03-29T06%3A21%3A21Z&se=2021-03-29T14%3A31%3A21Z&sp=r\", \"azureml-logs/75_job_post-tvmps_0f0f37b68e6c774922818cffea473a3031fe5b5294858c9e3c5d655c581e7600_d.txt\": \"https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616991319_6f6aaad5/azureml-logs/75_job_post-tvmps_0f0f37b68e6c774922818cffea473a3031fe5b5294858c9e3c5d655c581e7600_d.txt?sv=2019-02-02&sr=b&sig=zjBJ4kgUWsim0ZwdhhU4X08sdhM0L2yJPw5KcqVhATA%3D&st=2021-03-29T06%3A21%3A21Z&se=2021-03-29T14%3A31%3A21Z&sp=r\", \"azureml-logs/75_job_post-tvmps_e84f1fe707c074c991d63ec32397d2a9a809fe61f0a474b5e4f5e9d46be963cf_d.txt\": \"https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616991319_6f6aaad5/azureml-logs/75_job_post-tvmps_e84f1fe707c074c991d63ec32397d2a9a809fe61f0a474b5e4f5e9d46be963cf_d.txt?sv=2019-02-02&sr=b&sig=s9jEEDM8LRYmPgon0%2BLPm%2FkOuqxoTJgrD3K2FBhrpw4%3D&st=2021-03-29T06%3A21%3A21Z&se=2021-03-29T14%3A31%3A21Z&sp=r\", \"azureml-logs/process_info.json\": \"https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616991319_6f6aaad5/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=Cp3bIt60J96gVcit7X%2BHvYMOHiFz4a10FNZRJyiT3S8%3D&st=2021-03-29T06%3A21%3A21Z&se=2021-03-29T14%3A31%3A21Z&sp=r\", \"azureml-logs/process_status.json\": \"https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616991319_6f6aaad5/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=0EeIjE5F1nmb1HfidM5DBxYOu8718w40VbyGeQXlhOM%3D&st=2021-03-29T06%3A21%3A21Z&se=2021-03-29T14%3A31%3A21Z&sp=r\", \"logs/azureml/0_108_azureml.log\": \"https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616991319_6f6aaad5/logs/azureml/0_108_azureml.log?sv=2019-02-02&sr=b&sig=ebYyIX7dOdaGKP7q0CNo%2BSfjz8GH70Vy0DYr3QmtKGQ%3D&st=2021-03-29T06%3A21%3A26Z&se=2021-03-29T14%3A31%3A26Z&sp=r\", \"logs/azureml/1_88_azureml.log\": \"https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616991319_6f6aaad5/logs/azureml/1_88_azureml.log?sv=2019-02-02&sr=b&sig=bUxXvdNg3d%2FHp4HAl1XAllua3PbvzgvrsUalnP6J8CE%3D&st=2021-03-29T06%3A21%3A27Z&se=2021-03-29T14%3A31%3A27Z&sp=r\", \"logs/azureml/dataprep/backgroundProcess.log\": \"https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616991319_6f6aaad5/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=KSDPDPp5QZyRBURxbbC1llWNOwNmWTirKiSkrTPbX1s%3D&st=2021-03-29T06%3A21%3A27Z&se=2021-03-29T14%3A31%3A27Z&sp=r\", \"logs/azureml/dataprep/backgroundProcess_Telemetry.log\": \"https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616991319_6f6aaad5/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=qdlL2PcS1zYqmqiKWyPtM0v9qmPokS7F%2F7ZV629MEvA%3D&st=2021-03-29T06%3A21%3A27Z&se=2021-03-29T14%3A31%3A27Z&sp=r\", \"logs/azureml/job_prep_azureml.log\": \"https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616991319_6f6aaad5/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=DuJwf58ZHzLelLOF1j%2FHjWVFoT%2BVtefkZ%2BVyB%2FOXXS0%3D&st=2021-03-29T06%3A21%3A27Z&se=2021-03-29T14%3A31%3A27Z&sp=r\", \"logs/azureml/job_release_azureml.log\": \"https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616991319_6f6aaad5/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=e3BsBWIoFVlemVO1vbNr2pljCIeSRo1z9EfQOUq0GGw%3D&st=2021-03-29T06%3A21%3A27Z&se=2021-03-29T14%3A31%3A27Z&sp=r\", \"logs/azureml/sidecar/tvmps_0f0f37b68e6c774922818cffea473a3031fe5b5294858c9e3c5d655c581e7600_d/all.log\": \"https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616991319_6f6aaad5/logs/azureml/sidecar/tvmps_0f0f37b68e6c774922818cffea473a3031fe5b5294858c9e3c5d655c581e7600_d/all.log?sv=2019-02-02&sr=b&sig=6Kqchpyr%2F3P1gmK8NQ5B6JzL1oeq%2BzLDvXlQj4ahkIc%3D&st=2021-03-29T06%3A21%3A27Z&se=2021-03-29T14%3A31%3A27Z&sp=r\", \"logs/azureml/sidecar/tvmps_0f0f37b68e6c774922818cffea473a3031fe5b5294858c9e3c5d655c581e7600_d/task.enter_contexts.log\": \"https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616991319_6f6aaad5/logs/azureml/sidecar/tvmps_0f0f37b68e6c774922818cffea473a3031fe5b5294858c9e3c5d655c581e7600_d/task.enter_contexts.log?sv=2019-02-02&sr=b&sig=EJHlDiEELcRPLk4eBU8mPYArT2vd5%2F%2FfkmEPtilAM9o%3D&st=2021-03-29T06%3A21%3A27Z&se=2021-03-29T14%3A31%3A27Z&sp=r\", \"logs/azureml/sidecar/tvmps_0f0f37b68e6c774922818cffea473a3031fe5b5294858c9e3c5d655c581e7600_d/task.exit_contexts.log\": \"https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616991319_6f6aaad5/logs/azureml/sidecar/tvmps_0f0f37b68e6c774922818cffea473a3031fe5b5294858c9e3c5d655c581e7600_d/task.exit_contexts.log?sv=2019-02-02&sr=b&sig=qUfJ0q0DSSuCvq8ydvowqwZfrzvATiJarM2qjmdt%2FhE%3D&st=2021-03-29T06%3A21%3A27Z&se=2021-03-29T14%3A31%3A27Z&sp=r\", \"logs/azureml/sidecar/tvmps_e84f1fe707c074c991d63ec32397d2a9a809fe61f0a474b5e4f5e9d46be963cf_d/all.log\": \"https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616991319_6f6aaad5/logs/azureml/sidecar/tvmps_e84f1fe707c074c991d63ec32397d2a9a809fe61f0a474b5e4f5e9d46be963cf_d/all.log?sv=2019-02-02&sr=b&sig=AFPt8AJB5TxnB4XaMHykU1xsoomRbW2wOI9IcMwrnB0%3D&st=2021-03-29T06%3A21%3A27Z&se=2021-03-29T14%3A31%3A27Z&sp=r\", \"logs/azureml/sidecar/tvmps_e84f1fe707c074c991d63ec32397d2a9a809fe61f0a474b5e4f5e9d46be963cf_d/task.enter_contexts.log\": \"https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616991319_6f6aaad5/logs/azureml/sidecar/tvmps_e84f1fe707c074c991d63ec32397d2a9a809fe61f0a474b5e4f5e9d46be963cf_d/task.enter_contexts.log?sv=2019-02-02&sr=b&sig=GoUaB4rRuxBP5XyxhB%2BFIBVFrtg0PeHz7FxWqt1GJks%3D&st=2021-03-29T06%3A21%3A27Z&se=2021-03-29T14%3A31%3A27Z&sp=r\", \"logs/azureml/sidecar/tvmps_e84f1fe707c074c991d63ec32397d2a9a809fe61f0a474b5e4f5e9d46be963cf_d/task.exit_contexts.log\": \"https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616991319_6f6aaad5/logs/azureml/sidecar/tvmps_e84f1fe707c074c991d63ec32397d2a9a809fe61f0a474b5e4f5e9d46be963cf_d/task.exit_contexts.log?sv=2019-02-02&sr=b&sig=NM%2BhciGriHvZjFwrRl6rAbtaDmokCqMipRpvg2zxq4o%3D&st=2021-03-29T06%3A21%3A27Z&se=2021-03-29T14%3A31%3A27Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/process_info.json\", \"azureml-logs/process_status.json\", \"logs/azureml/dataprep/backgroundProcess.log\", \"logs/azureml/dataprep/backgroundProcess_Telemetry.log\", \"logs/azureml/job_prep_azureml.log\", \"logs/azureml/job_release_azureml.log\"], [\"logs/azureml/sidecar/tvmps_0f0f37b68e6c774922818cffea473a3031fe5b5294858c9e3c5d655c581e7600_d/all.log\", \"logs/azureml/sidecar/tvmps_0f0f37b68e6c774922818cffea473a3031fe5b5294858c9e3c5d655c581e7600_d/task.enter_contexts.log\", \"logs/azureml/sidecar/tvmps_0f0f37b68e6c774922818cffea473a3031fe5b5294858c9e3c5d655c581e7600_d/task.exit_contexts.log\", \"logs/azureml/0_108_azureml.log\"], [\"logs/azureml/1_88_azureml.log\"], [\"azureml-logs/55_azureml-execution-tvmps_0f0f37b68e6c774922818cffea473a3031fe5b5294858c9e3c5d655c581e7600_d.txt\", \"azureml-logs/55_azureml-execution-tvmps_e84f1fe707c074c991d63ec32397d2a9a809fe61f0a474b5e4f5e9d46be963cf_d.txt\"], [\"azureml-logs/65_job_prep-tvmps_0f0f37b68e6c774922818cffea473a3031fe5b5294858c9e3c5d655c581e7600_d.txt\", \"azureml-logs/65_job_prep-tvmps_e84f1fe707c074c991d63ec32397d2a9a809fe61f0a474b5e4f5e9d46be963cf_d.txt\"], [\"azureml-logs/70_driver_log_0.txt\", \"azureml-logs/70_driver_log_1.txt\"], [\"azureml-logs/75_job_post-tvmps_0f0f37b68e6c774922818cffea473a3031fe5b5294858c9e3c5d655c581e7600_d.txt\", \"azureml-logs/75_job_post-tvmps_e84f1fe707c074c991d63ec32397d2a9a809fe61f0a474b5e4f5e9d46be963cf_d.txt\"], [\"logs/azureml/sidecar/tvmps_e84f1fe707c074c991d63ec32397d2a9a809fe61f0a474b5e4f5e9d46be963cf_d/all.log\", \"logs/azureml/sidecar/tvmps_e84f1fe707c074c991d63ec32397d2a9a809fe61f0a474b5e4f5e9d46be963cf_d/task.enter_contexts.log\", \"logs/azureml/sidecar/tvmps_e84f1fe707c074c991d63ec32397d2a9a809fe61f0a474b5e4f5e9d46be963cf_d/task.exit_contexts.log\"]], \"run_duration\": \"0:14:55\", \"run_number\": \"2\", \"run_queued_details\": {\"status\": \"Completed\", \"details\": null}}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [], \"run_logs\": \"[2021-03-29T04:19:04.001608] INFO azureml.sidecar.sidecar: Received task: enter_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-lab/azureml/pytorch-distr_1616991319_6f6aaad5/mounts/workspaceblobstore/azureml/pytorch-distr_1616991319_6f6aaad5\\n[2021-03-29T04:19:04.002295] INFO azureml.sidecar.sidecar: Invoking \\\"enter_contexts\\\" task with Context Managers: {\\\"context_managers\\\": [\\\"Dataset:context_managers.Datasets\\\"]}\\n[2021-03-29T04:30:05.994077] INFO azureml.sidecar.sidecar: Received task: exit_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-lab/azureml/pytorch-distr_1616991319_6f6aaad5/mounts/workspaceblobstore/azureml/pytorch-distr_1616991319_6f6aaad5\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": true, \"log_level\": \"INFO\", \"sdk_version\": \"1.25.0\"}, \"loading\": false}"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from azureml.widgets import RunDetails\n",
        "\n",
        "RunDetails(run).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Alternatively, you can block until the script has completed training before running more code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RunId: pytorch-distr_1616991319_6f6aaad5\n",
            "Web View: https://ml.azure.com/runs/pytorch-distr_1616991319_6f6aaad5?wsid=/subscriptions/f57ce3c6-5c6f-4f1e-8cba-b782d8974590/resourcegroups/rg-aml/workspaces/ml-lab&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
            "\n",
            "Streaming azureml-logs/65_job_prep-tvmps_0f0f37b68e6c774922818cffea473a3031fe5b5294858c9e3c5d655c581e7600_d.txt\n",
            "===============================================================================================================\n",
            "\n",
            "[2021-03-29T04:19:01.779219] Entering job preparation.\n",
            "[2021-03-29T04:19:02.371080] Starting job preparation.\n",
            "[2021-03-29T04:19:02.371120] Extracting the control code.\n",
            "[2021-03-29T04:19:02.379157] Waiting for master node to finish fetching and extracting the control code. Will check again in 1 seconds.\n",
            "[2021-03-29T04:19:03.383678] Waiting for master node to finish fetching and extracting the control code. Will check again in 3 seconds.\n",
            "[2021-03-29T04:19:06.426009] Finished fetching and extracting the control code.\n",
            "[2021-03-29T04:19:06.426191] Not a master node. Skipping rest of the context managers.\n",
            "[2021-03-29T04:19:06.426252] Entering Data Context Managers in Sidecar\n",
            "[2021-03-29T04:19:06.426818] Running Sidecar prep cmd...\n",
            "[2021-03-29T04:19:06.472531] INFO azureml.sidecar.sidecar: Received task: enter_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-lab/azureml/pytorch-distr_1616991319_6f6aaad5/mounts/workspaceblobstore/azureml/pytorch-distr_1616991319_6f6aaad5\n",
            "[2021-03-29T04:19:06.473456] INFO azureml.sidecar.sidecar: Invoking \"enter_contexts\" task with Context Managers: {\"context_managers\": [\"Dataset:context_managers.Datasets\"]}\n",
            "Enter __enter__ of DatasetContextManager\n",
            "SDK version: azureml-core==1.22.0 azureml-dataprep==2.10.1. Session id: 3d6f8037-e7c5-4e18-9d93-43fafc7d5226. Run id: pytorch-distr_1616991319_6f6aaad5.\n",
            "Processing 'input__d3496a1a'.\n",
            "Processing dataset FileDataset\n",
            "{\n",
            "  \"source\": [\n",
            "    \"('workspaceblobstore', 'cifar-10')\"\n",
            "  ],\n",
            "  \"definition\": [\n",
            "    \"GetDatastoreFiles\"\n",
            "  ],\n",
            "  \"registration\": {\n",
            "    \"id\": \"5552c1f0-d54d-4c12-9dea-c3c6d08c5c4f\",\n",
            "    \"name\": null,\n",
            "    \"version\": null,\n",
            "    \"workspace\": \"Workspace.create(name='ml-lab', subscription_id='f57ce3c6-5c6f-4f1e-8cba-b782d8974590', resource_group='rg-aml')\"\n",
            "  }\n",
            "}\n",
            "Downloading input__d3496a1a to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-lab/azureml/pytorch-distr_1616991319_6f6aaad5/wd/tmpiwbdcszv\n",
            "Downloaded input__d3496a1a to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-lab/azureml/pytorch-distr_1616991319_6f6aaad5/wd/tmpiwbdcszv as folder.\n",
            "Exit __enter__ of DatasetContextManager\n",
            "Set Dataset input__d3496a1a's target path to /mnt/batch/tasks/shared/LS_root/jobs/ml-lab/azureml/pytorch-distr_1616991319_6f6aaad5/wd/tmpiwbdcszv\n",
            "Starting the daemon thread to refresh tokens in background for process with pid = 1\n",
            "[2021-03-29T04:19:12.821021] INFO azureml.sidecar.task.enter_contexts: Entered Context Managers\n",
            "[2021-03-29T04:19:13.996595] Ran Sidecar prep cmd.\n",
            "[2021-03-29T04:19:13.996687] Running Context Managers in Sidecar complete.\n",
            "\n",
            "Streaming azureml-logs/70_driver_log_0.txt\n",
            "==========================================\n",
            "\n",
            "bash: /azureml-envs/azureml_9d2a515d5c77954f2d0562cc5eb8a1fc/lib/libtinfo.so.5: no version information available (required by bash)\n",
            "[2021-03-29T04:20:41.164287] Entering context manager injector.\n",
            "[context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'Dataset:context_managers.Datasets', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError', 'UserExceptions:context_managers.UserExceptions'], invocation=['train.py', '--data-dir', 'DatasetConsumptionConfig:input__d3496a1a', '--epochs', '25'])\n",
            "This is a PyTorch job. Rank:0\n",
            "Script type = None\n",
            "Starting the daemon thread to refresh tokens in background for process with pid = 108\n",
            "[2021-03-29T04:20:43.373526] Entering Run History Context Manager.\n",
            "[2021-03-29T04:20:44.329316] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/ml-lab/azureml/pytorch-distr_1616991319_6f6aaad5/mounts/workspaceblobstore/azureml/pytorch-distr_1616991319_6f6aaad5\n",
            "[2021-03-29T04:20:44.329479] Preparing to call script [train.py] with arguments:['--data-dir', '$input__d3496a1a', '--epochs', '25']\n",
            "[2021-03-29T04:20:44.329567] After variable expansion, calling script [train.py] with arguments:['--data-dir', '/mnt/batch/tasks/shared/LS_root/jobs/ml-lab/azureml/pytorch-distr_1616991319_6f6aaad5/wd/tmpgt9gz9yi', '--epochs', '25']\n",
            "\n",
            "5f0a4c08500c47808fa62c1fdc6c766e000000:108:108 [0] NCCL INFO Bootstrap : Using [0]eth0:10.0.0.4<0>\n",
            "5f0a4c08500c47808fa62c1fdc6c766e000000:108:108 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\n",
            "5f0a4c08500c47808fa62c1fdc6c766e000000:108:108 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
            "5f0a4c08500c47808fa62c1fdc6c766e000000:108:108 [0] NCCL INFO NET/Socket : Using [0]eth0:10.0.0.4<0>\n",
            "NCCL version 2.4.8+cuda10.2\n",
            "5f0a4c08500c47808fa62c1fdc6c766e000000:108:127 [0] NCCL INFO Setting affinity for GPU 0 to 3f\n",
            "5f0a4c08500c47808fa62c1fdc6c766e000000:108:127 [0] NCCL INFO NCCL_TREE_THRESHOLD set by environment to 0.\n",
            "5f0a4c08500c47808fa62c1fdc6c766e000000:108:127 [0] NCCL INFO CUDA Dev 0[0], Socket NIC distance :  PXB\n",
            "5f0a4c08500c47808fa62c1fdc6c766e000000:108:127 [0] NCCL INFO Channel 00 :    0   1\n",
            "5f0a4c08500c47808fa62c1fdc6c766e000000:108:127 [0] NCCL INFO Channel 01 :    0   1\n",
            "5f0a4c08500c47808fa62c1fdc6c766e000000:108:127 [0] NCCL INFO Ring 00 : 1 -> 0 [receive] via NET/Socket/0\n",
            "5f0a4c08500c47808fa62c1fdc6c766e000000:108:127 [0] NCCL INFO NET/Socket: Using 1 threads and 1 sockets per thread\n",
            "5f0a4c08500c47808fa62c1fdc6c766e000000:108:127 [0] NCCL INFO Ring 00 : 0 -> 1 [send] via NET/Socket/0\n",
            "5f0a4c08500c47808fa62c1fdc6c766e000000:108:127 [0] NCCL INFO Ring 01 : 1 -> 0 [receive] via NET/Socket/0\n",
            "5f0a4c08500c47808fa62c1fdc6c766e000000:108:127 [0] NCCL INFO NET/Socket: Using 1 threads and 1 sockets per thread\n",
            "5f0a4c08500c47808fa62c1fdc6c766e000000:108:127 [0] NCCL INFO Ring 01 : 0 -> 1 [send] via NET/Socket/0\n",
            "5f0a4c08500c47808fa62c1fdc6c766e000000:108:127 [0] NCCL INFO Using 128 threads, Min Comp Cap 3, Trees disabled\n",
            "5f0a4c08500c47808fa62c1fdc6c766e000000:108:127 [0] NCCL INFO comm 0x7f1480002270 rank 0 nranks 2 cudaDev 0 nvmlDev 0 - Init COMPLETE\n",
            "5f0a4c08500c47808fa62c1fdc6c766e000000:108:108 [0] NCCL INFO Launch mode Parallel\n",
            "Rank 0: Starting epoch 0\n",
            "Rank 0: [1,     1] loss: 0.011\n",
            "Rank 0: [1,   201] loss: 2.306\n",
            "Rank 0: [1,   401] loss: 2.302\n",
            "Rank 0: [1,   601] loss: 2.296\n",
            "Rank 0: [1,   801] loss: 2.293\n",
            "Rank 0: [1,  1001] loss: 2.278\n",
            "Rank 0: [1,  1201] loss: 2.225\n",
            "Rank 0: [1,  1401] loss: 2.104\n",
            "Rank 0: Starting epoch 1\n",
            "Rank 0: [2,     1] loss: 0.010\n",
            "Rank 0: [2,   201] loss: 1.955\n",
            "Rank 0: [2,   401] loss: 1.879\n",
            "Rank 0: [2,   601] loss: 1.845\n",
            "Rank 0: [2,   801] loss: 1.796\n",
            "Rank 0: [2,  1001] loss: 1.773\n",
            "Rank 0: [2,  1201] loss: 1.733\n",
            "Rank 0: [2,  1401] loss: 1.682\n",
            "Rank 0: Starting epoch 2\n",
            "Rank 0: [3,     1] loss: 0.008\n",
            "Rank 0: [3,   201] loss: 1.637\n",
            "Rank 0: [3,   401] loss: 1.614\n",
            "Rank 0: [3,   601] loss: 1.567\n",
            "Rank 0: [3,   801] loss: 1.557\n",
            "Rank 0: [3,  1001] loss: 1.552\n",
            "Rank 0: [3,  1201] loss: 1.525\n",
            "Rank 0: [3,  1401] loss: 1.502\n",
            "Rank 0: Starting epoch 3\n",
            "Rank 0: [4,     1] loss: 0.008\n",
            "Rank 0: [4,   201] loss: 1.488\n",
            "Rank 0: [4,   401] loss: 1.464\n",
            "Rank 0: [4,   601] loss: 1.437\n",
            "Rank 0: [4,   801] loss: 1.416\n",
            "Rank 0: [4,  1001] loss: 1.402\n",
            "Rank 0: [4,  1201] loss: 1.393\n",
            "Rank 0: [4,  1401] loss: 1.392\n",
            "Rank 0: Starting epoch 4\n",
            "Rank 0: [5,     1] loss: 0.005\n",
            "Rank 0: [5,   201] loss: 1.360\n",
            "Rank 0: [5,   401] loss: 1.312\n",
            "Rank 0: [5,   601] loss: 1.306\n",
            "Rank 0: [5,   801] loss: 1.304\n",
            "Rank 0: [5,  1001] loss: 1.290\n",
            "Rank 0: [5,  1201] loss: 1.281\n",
            "Rank 0: [5,  1401] loss: 1.273\n",
            "Rank 0: Starting epoch 5\n",
            "Rank 0: [6,     1] loss: 0.009\n",
            "Rank 0: [6,   201] loss: 1.209\n",
            "Rank 0: [6,   401] loss: 1.195\n",
            "Rank 0: [6,   601] loss: 1.219\n",
            "Rank 0: [6,   801] loss: 1.212\n",
            "Rank 0: [6,  1001] loss: 1.158\n",
            "Rank 0: [6,  1201] loss: 1.155\n",
            "Rank 0: [6,  1401] loss: 1.153\n",
            "Rank 0: Starting epoch 6\n",
            "Rank 0: [7,     1] loss: 0.004\n",
            "Rank 0: [7,   201] loss: 1.118\n",
            "Rank 0: [7,   401] loss: 1.144\n",
            "Rank 0: [7,   601] loss: 1.093\n",
            "Rank 0: [7,   801] loss: 1.112\n",
            "Rank 0: [7,  1001] loss: 1.075\n",
            "Rank 0: [7,  1201] loss: 1.059\n",
            "Rank 0: [7,  1401] loss: 1.079\n",
            "Rank 0: Starting epoch 7\n",
            "Rank 0: [8,     1] loss: 0.004\n",
            "Rank 0: [8,   201] loss: 1.030\n",
            "Rank 0: [8,   401] loss: 1.025\n",
            "Rank 0: [8,   601] loss: 0.995\n",
            "Rank 0: [8,   801] loss: 1.005\n",
            "Rank 0: [8,  1001] loss: 1.014\n",
            "Rank 0: [8,  1201] loss: 0.992\n",
            "Rank 0: [8,  1401] loss: 1.013\n",
            "Rank 0: Starting epoch 8\n",
            "Rank 0: [9,     1] loss: 0.005\n",
            "Rank 0: [9,   201] loss: 0.943\n",
            "Rank 0: [9,   401] loss: 0.922\n",
            "Rank 0: [9,   601] loss: 0.930\n",
            "Rank 0: [9,   801] loss: 0.945\n",
            "Rank 0: [9,  1001] loss: 0.924\n",
            "Rank 0: [9,  1201] loss: 0.926\n",
            "Rank 0: [9,  1401] loss: 0.920\n",
            "Rank 0: Starting epoch 9\n",
            "Rank 0: [10,     1] loss: 0.006\n",
            "Rank 0: [10,   201] loss: 0.838\n",
            "Rank 0: [10,   401] loss: 0.856\n",
            "Rank 0: [10,   601] loss: 0.879\n",
            "Rank 0: [10,   801] loss: 0.887\n",
            "Rank 0: [10,  1001] loss: 0.900\n",
            "Rank 0: [10,  1201] loss: 0.901\n",
            "Rank 0: [10,  1401] loss: 0.858\n",
            "Rank 0: Starting epoch 10\n",
            "Rank 0: [11,     1] loss: 0.004\n",
            "Rank 0: [11,   201] loss: 0.798\n",
            "Rank 0: [11,   401] loss: 0.822\n",
            "Rank 0: [11,   601] loss: 0.789\n",
            "Rank 0: [11,   801] loss: 0.790\n",
            "Rank 0: [11,  1001] loss: 0.808\n",
            "Rank 0: [11,  1201] loss: 0.791\n",
            "Rank 0: [11,  1401] loss: 0.814\n",
            "Rank 0: Starting epoch 11\n",
            "Rank 0: [12,     1] loss: 0.006\n",
            "Rank 0: [12,   201] loss: 0.737\n",
            "Rank 0: [12,   401] loss: 0.745\n",
            "Rank 0: [12,   601] loss: 0.765\n",
            "Rank 0: [12,   801] loss: 0.738\n",
            "Rank 0: [12,  1001] loss: 0.751\n",
            "Rank 0: [12,  1201] loss: 0.731\n",
            "Rank 0: [12,  1401] loss: 0.765\n",
            "Rank 0: Starting epoch 12\n",
            "Rank 0: [13,     1] loss: 0.002\n",
            "Rank 0: [13,   201] loss: 0.668\n",
            "Rank 0: [13,   401] loss: 0.654\n",
            "Rank 0: [13,   601] loss: 0.702\n",
            "Rank 0: [13,   801] loss: 0.672\n",
            "Rank 0: [13,  1001] loss: 0.696\n",
            "Rank 0: [13,  1201] loss: 0.682\n",
            "Rank 0: [13,  1401] loss: 0.703\n",
            "Rank 0: Starting epoch 13\n",
            "Rank 0: [14,     1] loss: 0.003\n",
            "Rank 0: [14,   201] loss: 0.607\n",
            "Rank 0: [14,   401] loss: 0.624\n",
            "Rank 0: [14,   601] loss: 0.632\n",
            "Rank 0: [14,   801] loss: 0.636\n",
            "Rank 0: [14,  1001] loss: 0.657\n",
            "Rank 0: [14,  1201] loss: 0.610\n",
            "Rank 0: [14,  1401] loss: 0.608\n",
            "Rank 0: Starting epoch 14\n",
            "Rank 0: [15,     1] loss: 0.002\n",
            "Rank 0: [15,   201] loss: 0.568\n",
            "Rank 0: [15,   401] loss: 0.578\n",
            "Rank 0: [15,   601] loss: 0.559\n",
            "Rank 0: [15,   801] loss: 0.563\n",
            "Rank 0: [15,  1001] loss: 0.571\n",
            "Rank 0: [15,  1201] loss: 0.633\n",
            "Rank 0: [15,  1401] loss: 0.595\n",
            "Rank 0: Starting epoch 15\n",
            "Rank 0: [16,     1] loss: 0.003\n",
            "Rank 0: [16,   201] loss: 0.509\n",
            "Rank 0: [16,   401] loss: 0.525\n",
            "Rank 0: [16,   601] loss: 0.532\n",
            "Rank 0: [16,   801] loss: 0.545\n",
            "Rank 0: [16,  1001] loss: 0.554\n",
            "Rank 0: [16,  1201] loss: 0.565\n",
            "Rank 0: [16,  1401] loss: 0.562\n",
            "Rank 0: Starting epoch 16\n",
            "Rank 0: [17,     1] loss: 0.002\n",
            "Rank 0: [17,   201] loss: 0.453\n",
            "Rank 0: [17,   401] loss: 0.457\n",
            "Rank 0: [17,   601] loss: 0.470\n",
            "Rank 0: [17,   801] loss: 0.499\n",
            "Rank 0: [17,  1001] loss: 0.489\n",
            "Rank 0: [17,  1201] loss: 0.477\n",
            "Rank 0: [17,  1401] loss: 0.490\n",
            "Rank 0: Starting epoch 17\n",
            "Rank 0: [18,     1] loss: 0.001\n",
            "Rank 0: [18,   201] loss: 0.402\n",
            "Rank 0: [18,   401] loss: 0.409\n",
            "Rank 0: [18,   601] loss: 0.438\n",
            "Rank 0: [18,   801] loss: 0.443\n",
            "Rank 0: [18,  1001] loss: 0.431\n",
            "Rank 0: [18,  1201] loss: 0.434\n",
            "Rank 0: [18,  1401] loss: 0.432\n",
            "Rank 0: Starting epoch 18\n",
            "Rank 0: [19,     1] loss: 0.001\n",
            "Rank 0: [19,   201] loss: 0.398\n",
            "Rank 0: [19,   401] loss: 0.370\n",
            "Rank 0: [19,   601] loss: 0.367\n",
            "Rank 0: [19,   801] loss: 0.387\n",
            "Rank 0: [19,  1001] loss: 0.379\n",
            "Rank 0: [19,  1201] loss: 0.418\n",
            "Rank 0: [19,  1401] loss: 0.416\n",
            "Rank 0: Starting epoch 19\n",
            "Rank 0: [20,     1] loss: 0.003\n",
            "Rank 0: [20,   201] loss: 0.319\n",
            "Rank 0: [20,   401] loss: 0.319\n",
            "Rank 0: [20,   601] loss: 0.341\n",
            "Rank 0: [20,   801] loss: 0.354\n",
            "Rank 0: [20,  1001] loss: 0.358\n",
            "Rank 0: [20,  1201] loss: 0.356\n",
            "Rank 0: [20,  1401] loss: 0.372\n",
            "Rank 0: Starting epoch 20\n",
            "Rank 0: [21,     1] loss: 0.001\n",
            "Rank 0: [21,   201] loss: 0.266\n",
            "Rank 0: [21,   401] loss: 0.288\n",
            "Rank 0: [21,   601] loss: 0.307\n",
            "Rank 0: [21,   801] loss: 0.323\n",
            "Rank 0: [21,  1001] loss: 0.293\n",
            "Rank 0: [21,  1201] loss: 0.329\n",
            "Rank 0: [21,  1401] loss: 0.306\n",
            "Rank 0: Starting epoch 21\n",
            "Rank 0: [22,     1] loss: 0.000\n",
            "Rank 0: [22,   201] loss: 0.271\n",
            "Rank 0: [22,   401] loss: 0.267\n",
            "Rank 0: [22,   601] loss: 0.288\n",
            "Rank 0: [22,   801] loss: 0.272\n",
            "Rank 0: [22,  1001] loss: 0.308\n",
            "Rank 0: [22,  1201] loss: 0.290\n",
            "Rank 0: [22,  1401] loss: 0.300\n",
            "Rank 0: Starting epoch 22\n",
            "Rank 0: [23,     1] loss: 0.001\n",
            "Rank 0: [23,   201] loss: 0.234\n",
            "Rank 0: [23,   401] loss: 0.221\n",
            "Rank 0: [23,   601] loss: 0.246\n",
            "Rank 0: [23,   801] loss: 0.262\n",
            "Rank 0: [23,  1001] loss: 0.259\n",
            "Rank 0: [23,  1201] loss: 0.282\n",
            "Rank 0: [23,  1401] loss: 0.266\n",
            "Rank 0: Starting epoch 23\n",
            "Rank 0: [24,     1] loss: 0.000\n",
            "Rank 0: [24,   201] loss: 0.194\n",
            "Rank 0: [24,   401] loss: 0.203\n",
            "Rank 0: [24,   601] loss: 0.222\n",
            "\n",
            "Streaming azureml-logs/75_job_post-tvmps_0f0f37b68e6c774922818cffea473a3031fe5b5294858c9e3c5d655c581e7600_d.txt\n",
            "===============================================================================================================\n",
            "\n",
            "[2021-03-29T04:30:03.779273] Entering job release\n",
            "[2021-03-29T04:30:04.835883] job release stage : copy_batchai_cached_logs starting...\n",
            "[2021-03-29T04:30:04.835939] job release stage : copy_batchai_cached_logs completed...\n",
            "[2021-03-29T04:30:04.835998] Running in AzureML-Sidecar, starting to exit user context managers...\n",
            "[2021-03-29T04:30:04.836460] Running Sidecar release cmd...\n",
            "[2021-03-29T04:30:04.844405] INFO azureml.sidecar.sidecar: Received task: exit_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-lab/azureml/pytorch-distr_1616991319_6f6aaad5/mounts/workspaceblobstore/azureml/pytorch-distr_1616991319_6f6aaad5\n",
            "Enter __exit__ of DatasetContextManager\n",
            "Exit __exit__ of DatasetContextManager\n",
            "[2021-03-29T04:30:04.870348] Removing absolute paths from host...\n",
            "[2021-03-29T04:30:05.091913] INFO azureml.sidecar.task.exit_contexts: Exited Context Managers\n",
            "[2021-03-29T04:30:05.381475] Ran Sidecar release cmd.\n",
            "\n",
            "Execution Summary\n",
            "=================\n",
            "RunId: pytorch-distr_1616991319_6f6aaad5\n",
            "Web View: https://ml.azure.com/runs/pytorch-distr_1616991319_6f6aaad5?wsid=/subscriptions/f57ce3c6-5c6f-4f1e-8cba-b782d8974590/resourcegroups/rg-aml/workspaces/ml-lab&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'runId': 'pytorch-distr_1616991319_6f6aaad5',\n",
              " 'target': 'gpu-cluster',\n",
              " 'status': 'Completed',\n",
              " 'startTimeUtc': '2021-03-29T04:18:36.74037Z',\n",
              " 'endTimeUtc': '2021-03-29T04:30:16.24287Z',\n",
              " 'properties': {'_azureml.ComputeTargetType': 'amlcompute',\n",
              "  'ContentSnapshotId': 'c0226cb2-4817-4968-8d05-686acc882c88',\n",
              "  'azureml.git.repository_uri': 'git@github.com:shohei1029/azureml_distributed-pytorch.git',\n",
              "  'mlflow.source.git.repoURL': 'git@github.com:shohei1029/azureml_distributed-pytorch.git',\n",
              "  'azureml.git.branch': 'main',\n",
              "  'mlflow.source.git.branch': 'main',\n",
              "  'azureml.git.commit': 'd0aca0d1988dc18c160cf520e0a8a845cc590216',\n",
              "  'mlflow.source.git.commit': 'd0aca0d1988dc18c160cf520e0a8a845cc590216',\n",
              "  'azureml.git.dirty': 'False',\n",
              "  'ProcessInfoFile': 'azureml-logs/process_info.json',\n",
              "  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n",
              " 'inputDatasets': [{'dataset': {'id': '5552c1f0-d54d-4c12-9dea-c3c6d08c5c4f'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'input__d3496a1a', 'mechanism': 'Download'}}],\n",
              " 'outputDatasets': [],\n",
              " 'runDefinition': {'script': 'train.py',\n",
              "  'command': '',\n",
              "  'useAbsolutePath': False,\n",
              "  'arguments': ['--data-dir',\n",
              "   'DatasetConsumptionConfig:input__d3496a1a',\n",
              "   '--epochs',\n",
              "   '25'],\n",
              "  'sourceDirectoryDataStore': None,\n",
              "  'framework': 'PyTorch',\n",
              "  'communicator': 'Nccl',\n",
              "  'target': 'gpu-cluster',\n",
              "  'dataReferences': {},\n",
              "  'data': {'input__d3496a1a': {'dataLocation': {'dataset': {'id': '5552c1f0-d54d-4c12-9dea-c3c6d08c5c4f',\n",
              "      'name': None,\n",
              "      'version': None},\n",
              "     'dataPath': None},\n",
              "    'mechanism': 'Download',\n",
              "    'environmentVariableName': 'input__d3496a1a',\n",
              "    'pathOnCompute': None,\n",
              "    'overwrite': False}},\n",
              "  'outputData': {},\n",
              "  'jobName': None,\n",
              "  'maxRunDurationSeconds': 2592000,\n",
              "  'nodeCount': 2,\n",
              "  'priority': None,\n",
              "  'credentialPassthrough': False,\n",
              "  'identity': None,\n",
              "  'environment': {'name': 'AzureML-PyTorch-1.6-GPU',\n",
              "   'version': '10',\n",
              "   'python': {'interpreterPath': 'python',\n",
              "    'userManagedDependencies': False,\n",
              "    'condaDependencies': {'channels': ['conda-forge'],\n",
              "     'dependencies': ['python=3.6.2',\n",
              "      {'pip': ['azureml-core==1.18.0.post1',\n",
              "        'azureml-defaults==1.18.0',\n",
              "        'azureml-telemetry==1.18.0',\n",
              "        'azureml-train-restclients-hyperdrive==1.18.0',\n",
              "        'azureml-train-core==1.18.0',\n",
              "        'cmake==3.18.2',\n",
              "        'torch==1.6.0',\n",
              "        'torchvision==0.5.0',\n",
              "        'mkl==2018.0.3',\n",
              "        'horovod==0.20.0',\n",
              "        'tensorboard==1.14.0',\n",
              "        'future==0.17.1']}],\n",
              "     'name': 'azureml_9d2a515d5c77954f2d0562cc5eb8a1fc'},\n",
              "    'baseCondaEnvironment': None},\n",
              "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE',\n",
              "    'NCCL_TREE_THRESHOLD': '0'},\n",
              "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-cuda10.1-cudnn7-ubuntu18.04:20201112.v1',\n",
              "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
              "    'baseDockerfile': None,\n",
              "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
              "    'enabled': False,\n",
              "    'arguments': []},\n",
              "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
              "   'inferencingStackVersion': None},\n",
              "  'history': {'outputCollection': True,\n",
              "   'directoriesToWatch': ['logs'],\n",
              "   'enableMLflowTracking': True,\n",
              "   'snapshotProject': True},\n",
              "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
              "    'spark.yarn.maxAppAttempts': '1'}},\n",
              "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
              "   'workerCountPerNode': 1,\n",
              "   'terminalExitCodes': None,\n",
              "   'configuration': {}},\n",
              "  'amlCompute': {'name': None,\n",
              "   'vmSize': None,\n",
              "   'retainCluster': False,\n",
              "   'clusterMaxNodeCount': None},\n",
              "  'aiSuperComputer': {'instanceType': None,\n",
              "   'imageVersion': None,\n",
              "   'location': None,\n",
              "   'aiSuperComputerStorageData': None,\n",
              "   'interactive': False,\n",
              "   'scalePolicy': None,\n",
              "   'virtualClusterArmId': None},\n",
              "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
              "  'mpi': {'processCountPerNode': 1},\n",
              "  'pyTorch': {'communicationBackend': 'nccl', 'processCount': 2},\n",
              "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
              "  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n",
              "  'exposedPorts': None,\n",
              "  'docker': {'useDocker': False,\n",
              "   'sharedVolumes': True,\n",
              "   'shmSize': '2g',\n",
              "   'arguments': []},\n",
              "  'cmk8sCompute': {'configuration': {}},\n",
              "  'commandReturnCodeConfig': {'returnCode': 'Zero',\n",
              "   'successfulReturnCodes': []},\n",
              "  'environmentVariables': {}},\n",
              " 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_0f0f37b68e6c774922818cffea473a3031fe5b5294858c9e3c5d655c581e7600_d.txt': 'https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616991319_6f6aaad5/azureml-logs/55_azureml-execution-tvmps_0f0f37b68e6c774922818cffea473a3031fe5b5294858c9e3c5d655c581e7600_d.txt?sv=2019-02-02&sr=b&sig=mi9MSZrZ5p6478it0j%2B%2FOHL8ZErhSHine%2FpOd461%2FQ4%3D&st=2021-03-29T04%3A20%3A23Z&se=2021-03-29T12%3A30%3A23Z&sp=r',\n",
              "  'azureml-logs/55_azureml-execution-tvmps_e84f1fe707c074c991d63ec32397d2a9a809fe61f0a474b5e4f5e9d46be963cf_d.txt': 'https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616991319_6f6aaad5/azureml-logs/55_azureml-execution-tvmps_e84f1fe707c074c991d63ec32397d2a9a809fe61f0a474b5e4f5e9d46be963cf_d.txt?sv=2019-02-02&sr=b&sig=EHgB6RL45PQqW8s7AWs2Y8QfuFm84pE7n4k4LRnsP%2Fk%3D&st=2021-03-29T04%3A20%3A23Z&se=2021-03-29T12%3A30%3A23Z&sp=r',\n",
              "  'azureml-logs/65_job_prep-tvmps_0f0f37b68e6c774922818cffea473a3031fe5b5294858c9e3c5d655c581e7600_d.txt': 'https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616991319_6f6aaad5/azureml-logs/65_job_prep-tvmps_0f0f37b68e6c774922818cffea473a3031fe5b5294858c9e3c5d655c581e7600_d.txt?sv=2019-02-02&sr=b&sig=2M%2BXK3ugzkmQds%2F48xO72b4Iw77XwV5sjGxdqCeFl98%3D&st=2021-03-29T04%3A20%3A23Z&se=2021-03-29T12%3A30%3A23Z&sp=r',\n",
              "  'azureml-logs/65_job_prep-tvmps_e84f1fe707c074c991d63ec32397d2a9a809fe61f0a474b5e4f5e9d46be963cf_d.txt': 'https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616991319_6f6aaad5/azureml-logs/65_job_prep-tvmps_e84f1fe707c074c991d63ec32397d2a9a809fe61f0a474b5e4f5e9d46be963cf_d.txt?sv=2019-02-02&sr=b&sig=9%2BlpDYjfI%2F8DDTllPZYDmZAIsffO3%2FnjKq8V0ckSwYQ%3D&st=2021-03-29T04%3A20%3A23Z&se=2021-03-29T12%3A30%3A23Z&sp=r',\n",
              "  'azureml-logs/70_driver_log_0.txt': 'https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616991319_6f6aaad5/azureml-logs/70_driver_log_0.txt?sv=2019-02-02&sr=b&sig=0OfuLtt9tgb%2BdZZHbR4PLesTRSA3CXDg6vUZ8cwNsho%3D&st=2021-03-29T04%3A20%3A23Z&se=2021-03-29T12%3A30%3A23Z&sp=r',\n",
              "  'azureml-logs/70_driver_log_1.txt': 'https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616991319_6f6aaad5/azureml-logs/70_driver_log_1.txt?sv=2019-02-02&sr=b&sig=TfRktJXzFDQF9tn9V%2BqjSfbqnQnjcoyHK%2BkMBzz%2B0VE%3D&st=2021-03-29T04%3A20%3A23Z&se=2021-03-29T12%3A30%3A23Z&sp=r',\n",
              "  'azureml-logs/75_job_post-tvmps_0f0f37b68e6c774922818cffea473a3031fe5b5294858c9e3c5d655c581e7600_d.txt': 'https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616991319_6f6aaad5/azureml-logs/75_job_post-tvmps_0f0f37b68e6c774922818cffea473a3031fe5b5294858c9e3c5d655c581e7600_d.txt?sv=2019-02-02&sr=b&sig=zE0ha1BDMiTOiSetucrgwpRQQUEIJCvet53GsVYrApw%3D&st=2021-03-29T04%3A20%3A23Z&se=2021-03-29T12%3A30%3A23Z&sp=r',\n",
              "  'azureml-logs/75_job_post-tvmps_e84f1fe707c074c991d63ec32397d2a9a809fe61f0a474b5e4f5e9d46be963cf_d.txt': 'https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616991319_6f6aaad5/azureml-logs/75_job_post-tvmps_e84f1fe707c074c991d63ec32397d2a9a809fe61f0a474b5e4f5e9d46be963cf_d.txt?sv=2019-02-02&sr=b&sig=vKx6x9cjGOGjLdQpva2zskRY%2BrWxUOUdmN6HRJDHTJI%3D&st=2021-03-29T04%3A20%3A23Z&se=2021-03-29T12%3A30%3A23Z&sp=r',\n",
              "  'azureml-logs/process_info.json': 'https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616991319_6f6aaad5/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=qXicYCxlh4wDKbpuVzoz0uRawYGnQiJLvqiMOr5hWRs%3D&st=2021-03-29T04%3A20%3A23Z&se=2021-03-29T12%3A30%3A23Z&sp=r',\n",
              "  'azureml-logs/process_status.json': 'https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616991319_6f6aaad5/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=DPjFvyJLfQq6LwpDHGhBDfBplC8acvnoh6WshvFRh3U%3D&st=2021-03-29T04%3A20%3A23Z&se=2021-03-29T12%3A30%3A23Z&sp=r',\n",
              "  'logs/azureml/0_108_azureml.log': 'https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616991319_6f6aaad5/logs/azureml/0_108_azureml.log?sv=2019-02-02&sr=b&sig=VjOhnjUmBu8vAGVUBO4MRVtfUIM9xVvGl5sRaWLjFeU%3D&st=2021-03-29T04%3A20%3A23Z&se=2021-03-29T12%3A30%3A23Z&sp=r',\n",
              "  'logs/azureml/1_88_azureml.log': 'https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616991319_6f6aaad5/logs/azureml/1_88_azureml.log?sv=2019-02-02&sr=b&sig=nJaR19%2BxHEHgiy0cE1mfxVbY5Yt0AkcTCEl%2BCHVj4WM%3D&st=2021-03-29T04%3A20%3A23Z&se=2021-03-29T12%3A30%3A23Z&sp=r',\n",
              "  'logs/azureml/dataprep/backgroundProcess.log': 'https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616991319_6f6aaad5/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=ir4vfQ3cXHG6cKrJktx3WshlQLuTUZOqL6xJ0xKA48E%3D&st=2021-03-29T04%3A20%3A23Z&se=2021-03-29T12%3A30%3A23Z&sp=r',\n",
              "  'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616991319_6f6aaad5/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=lc54PVRxD9mQGde2v%2FL1IYgTOYHtRXHDJznI13EL9n4%3D&st=2021-03-29T04%3A20%3A24Z&se=2021-03-29T12%3A30%3A24Z&sp=r',\n",
              "  'logs/azureml/job_prep_azureml.log': 'https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616991319_6f6aaad5/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=%2FZWtLFH3fu4xzO%2FkDocORYZYW81bLVwrqzcEnl58Vxk%3D&st=2021-03-29T04%3A20%3A24Z&se=2021-03-29T12%3A30%3A24Z&sp=r',\n",
              "  'logs/azureml/job_release_azureml.log': 'https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616991319_6f6aaad5/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=iDNsgajKABycv8GKT5V%2BeIbS4jf4Beg%2Bx7hZ01LWib0%3D&st=2021-03-29T04%3A20%3A24Z&se=2021-03-29T12%3A30%3A24Z&sp=r',\n",
              "  'logs/azureml/sidecar/tvmps_0f0f37b68e6c774922818cffea473a3031fe5b5294858c9e3c5d655c581e7600_d/all.log': 'https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616991319_6f6aaad5/logs/azureml/sidecar/tvmps_0f0f37b68e6c774922818cffea473a3031fe5b5294858c9e3c5d655c581e7600_d/all.log?sv=2019-02-02&sr=b&sig=jyO%2FNHh7zp5vLXJ1eZtU5wtmrrI7yhe4AMgX%2BSlIEDU%3D&st=2021-03-29T04%3A20%3A24Z&se=2021-03-29T12%3A30%3A24Z&sp=r',\n",
              "  'logs/azureml/sidecar/tvmps_0f0f37b68e6c774922818cffea473a3031fe5b5294858c9e3c5d655c581e7600_d/task.enter_contexts.log': 'https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616991319_6f6aaad5/logs/azureml/sidecar/tvmps_0f0f37b68e6c774922818cffea473a3031fe5b5294858c9e3c5d655c581e7600_d/task.enter_contexts.log?sv=2019-02-02&sr=b&sig=n5vYCtHKU3RpPA5vyc5Dmcgd7WoZqB8W7reNWaSChVk%3D&st=2021-03-29T04%3A20%3A24Z&se=2021-03-29T12%3A30%3A24Z&sp=r',\n",
              "  'logs/azureml/sidecar/tvmps_0f0f37b68e6c774922818cffea473a3031fe5b5294858c9e3c5d655c581e7600_d/task.exit_contexts.log': 'https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616991319_6f6aaad5/logs/azureml/sidecar/tvmps_0f0f37b68e6c774922818cffea473a3031fe5b5294858c9e3c5d655c581e7600_d/task.exit_contexts.log?sv=2019-02-02&sr=b&sig=szypeHBqz9NydD0%2FwpZ7c5DCFtCc5GoCLdCqBT%2B014I%3D&st=2021-03-29T04%3A20%3A24Z&se=2021-03-29T12%3A30%3A24Z&sp=r',\n",
              "  'logs/azureml/sidecar/tvmps_e84f1fe707c074c991d63ec32397d2a9a809fe61f0a474b5e4f5e9d46be963cf_d/all.log': 'https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616991319_6f6aaad5/logs/azureml/sidecar/tvmps_e84f1fe707c074c991d63ec32397d2a9a809fe61f0a474b5e4f5e9d46be963cf_d/all.log?sv=2019-02-02&sr=b&sig=zssNz%2FbiAq2pcr1JzFrShNNwN2m6pCkravEkW3TjZGU%3D&st=2021-03-29T04%3A20%3A24Z&se=2021-03-29T12%3A30%3A24Z&sp=r',\n",
              "  'logs/azureml/sidecar/tvmps_e84f1fe707c074c991d63ec32397d2a9a809fe61f0a474b5e4f5e9d46be963cf_d/task.enter_contexts.log': 'https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616991319_6f6aaad5/logs/azureml/sidecar/tvmps_e84f1fe707c074c991d63ec32397d2a9a809fe61f0a474b5e4f5e9d46be963cf_d/task.enter_contexts.log?sv=2019-02-02&sr=b&sig=p%2FxLijAMP0e0tkt9SO0jaMCzhKS%2BxQU%2FZ1zrL2F0qOo%3D&st=2021-03-29T04%3A20%3A24Z&se=2021-03-29T12%3A30%3A24Z&sp=r',\n",
              "  'logs/azureml/sidecar/tvmps_e84f1fe707c074c991d63ec32397d2a9a809fe61f0a474b5e4f5e9d46be963cf_d/task.exit_contexts.log': 'https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616991319_6f6aaad5/logs/azureml/sidecar/tvmps_e84f1fe707c074c991d63ec32397d2a9a809fe61f0a474b5e4f5e9d46be963cf_d/task.exit_contexts.log?sv=2019-02-02&sr=b&sig=VPr5rHKV9UiW2X4dF4Lt%2F1SnONmQ27q1bZYsp3T8Z8s%3D&st=2021-03-29T04%3A20%3A24Z&se=2021-03-29T12%3A30%3A24Z&sp=r'},\n",
              " 'submittedBy': 'Shohei Nagata'}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "run.wait_for_completion(show_output=True) # this provides a verbose log"
      ]
    },
    {
      "source": [
        "## モデルの登録\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "azureml-logs/55_azureml-execution-tvmps_0f0f37b68e6c774922818cffea473a3031fe5b5294858c9e3c5d655c581e7600_d.txt\nazureml-logs/55_azureml-execution-tvmps_e84f1fe707c074c991d63ec32397d2a9a809fe61f0a474b5e4f5e9d46be963cf_d.txt\nazureml-logs/65_job_prep-tvmps_0f0f37b68e6c774922818cffea473a3031fe5b5294858c9e3c5d655c581e7600_d.txt\nazureml-logs/65_job_prep-tvmps_e84f1fe707c074c991d63ec32397d2a9a809fe61f0a474b5e4f5e9d46be963cf_d.txt\nazureml-logs/70_driver_log_0.txt\nazureml-logs/70_driver_log_1.txt\nazureml-logs/75_job_post-tvmps_0f0f37b68e6c774922818cffea473a3031fe5b5294858c9e3c5d655c581e7600_d.txt\nazureml-logs/75_job_post-tvmps_e84f1fe707c074c991d63ec32397d2a9a809fe61f0a474b5e4f5e9d46be963cf_d.txt\nazureml-logs/process_info.json\nazureml-logs/process_status.json\nlogs/azureml/0_108_azureml.log\nlogs/azureml/1_88_azureml.log\nlogs/azureml/dataprep/backgroundProcess.log\nlogs/azureml/dataprep/backgroundProcess_Telemetry.log\nlogs/azureml/job_prep_azureml.log\nlogs/azureml/job_release_azureml.log\nlogs/azureml/sidecar/tvmps_0f0f37b68e6c774922818cffea473a3031fe5b5294858c9e3c5d655c581e7600_d/all.log\nlogs/azureml/sidecar/tvmps_0f0f37b68e6c774922818cffea473a3031fe5b5294858c9e3c5d655c581e7600_d/task.enter_contexts.log\nlogs/azureml/sidecar/tvmps_0f0f37b68e6c774922818cffea473a3031fe5b5294858c9e3c5d655c581e7600_d/task.exit_contexts.log\nlogs/azureml/sidecar/tvmps_e84f1fe707c074c991d63ec32397d2a9a809fe61f0a474b5e4f5e9d46be963cf_d/all.log\nlogs/azureml/sidecar/tvmps_e84f1fe707c074c991d63ec32397d2a9a809fe61f0a474b5e4f5e9d46be963cf_d/task.enter_contexts.log\nlogs/azureml/sidecar/tvmps_e84f1fe707c074c991d63ec32397d2a9a809fe61f0a474b5e4f5e9d46be963cf_d/task.exit_contexts.log\noutputs/cifar_net.pt\n"
          ]
        }
      ],
      "source": [
        "#実行に関係しているファイル一覧の表示\n",
        "for i in run.get_file_names():\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pytorch-distr\tpytorch-distr:2\t2\n"
          ]
        }
      ],
      "source": [
        "model = run.register_model(model_name = 'pytorch-distr', model_path = 'outputs/cifar_net.pt')\n",
        "print(model.name, model.id, model.version, sep = '\\t')"
      ]
    },
    {
      "source": [
        "## モデルデプロイ\n",
        "Webサービスとしてモデルをデプロイします。"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "### スコアリングスクリプトの作成\n",
        "Web サービスの呼び出しに使用される score.py というスコアリング スクリプトを作成してモデルの使用方法を示します。\n",
        "スコアリング スクリプトには、2 つの必要な関数を含める必要があります。\n",
        "- `init()` 関数。通常、グローバル オブジェクトにモデルを読み込みます。 この関数は、Docker コンテナーを開始するときに 1 回だけ実行されます。\n",
        "- `run(input_data)` 関数。モデルを使用して、入力データに基づく値を予測します。 実行に対する入力と出力は、通常、JSON を使用してシリアル化およびシリアル化解除が実行されますが、その他の形式もサポートされています。"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting score.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile score.py\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "import json\n",
        "\n",
        "from azureml.core.model import Model\n",
        "\n",
        "\n",
        "def init():\n",
        "    global model\n",
        "    # AZUREML_MODEL_DIR is an environment variable created during deployment.\n",
        "    # It is the path to the model folder (./azureml-models/$MODEL_NAME/$VERSION)\n",
        "    # For multiple models, it points to the folder containing all deployed models (./azureml-models)\n",
        "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'cifar_net.pt')\n",
        "    model = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
        "    model.eval()\n",
        "\n",
        "\n",
        "def run(input_data):\n",
        "    input_data = torch.tensor(json.loads(input_data)['data'])\n",
        "\n",
        "    # get prediction\n",
        "    with torch.no_grad():\n",
        "        output = model(input_data)\n",
        "        classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "        softmax = nn.Softmax(dim=1)\n",
        "        pred_probs = softmax(output).numpy()[0]\n",
        "        index = torch.argmax(output, 1)\n",
        "\n",
        "    result = {\"label\": classes[index], \"probability\": str(pred_probs[index])}\n",
        "    return result"
      ]
    },
    {
      "source": [
        "### ACIコンテナへのデプロイ\n",
        "デプロイの構成ファイルを作成し、ACI コンテナーに必要な CPU 数と RAM ギガバイト数を指定します。 実際のモデルにもよりますが、通常、多くのモデルには既定値の 1 コアと 1 ギガバイトの RAM で十分です。 後でもっと必要になった場合は、イメージを再作成し、サービスをデプロイし直す必要があります。\n",
        "※今回はデプロイ先の実行環境にはトレーニング時と同一の環境を使用しています。"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "#### デプロイ先conda環境設定\n",
        "(ACI推論用に別環境を設定。(学習用と同じ環境だとデプロイ時にエラーが発生したため))"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing conda_dependencies_deploy.yml\n"
          ]
        }
      ],
      "source": [
        "%%writefile conda_dependencies_deploy.yml\n",
        "\n",
        "channels:\n",
        "- conda-forge\n",
        "dependencies:\n",
        "- python=3.6.2\n",
        "- pip:\n",
        "  - azureml-defaults\n",
        "  - torch==1.6.0\n",
        "  - torchvision==0.7.0\n",
        "  - future==0.17.1\n",
        "  - pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core import Environment\n",
        "\n",
        "aci_pytorch_env = Environment.from_conda_specification(name = 'pytorch-1.6-deploy', file_path = './conda_dependencies_deploy.yml')\n",
        "\n",
        "# # Specify a GPU base image これは学習用かな\n",
        "# pytorch_env.docker.enabled = True\n",
        "# pytorch_env.docker.base_image = 'mcr.microsoft.com/azureml/openmpi3.1.2-cuda10.1-cudnn7-ubuntu18.04'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "'enabled' is deprecated. Please use the azureml.core.runconfig.DockerConfiguration object with the 'use_docker' param instead.\n"
          ]
        }
      ],
      "source": [
        "# #GPU有効化だけしてデプロイ試してみる。仮コード\n",
        "# pytorch_env.docker.enabled = True\n",
        "# pytorch_env.docker.base_image = 'mcr.microsoft.com/azureml/openmpi3.1.2-cuda10.1-cudnn7-ubuntu18.04'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
            "Running\n",
            "2021-03-29 14:38:06+09:00 Creating Container Registry if not exists.\n",
            "2021-03-29 14:38:06+09:00 Registering the environment.\n",
            "2021-03-29 14:38:08+09:00 Use the existing image.\n",
            "2021-03-29 14:38:08+09:00 Generating deployment configuration.\n",
            "2021-03-29 14:38:09+09:00 Submitting deployment to compute.\n",
            "2021-03-29 14:38:12+09:00 Checking the status of deployment aci-cifar10..\n",
            "2021-03-29 14:43:44+09:00 Checking the status of inference endpoint aci-cifar10.\n",
            "Failed\n",
            "Service deployment polling reached non-successful terminal state, current service state: Failed\n",
            "Operation ID: eeacdf58-5648-4265-a866-ea90cba15aa7\n",
            "More information can be found using '.get_logs()'\n",
            "Error:\n",
            "{\n",
            "  \"code\": \"AciDeploymentFailed\",\n",
            "  \"statusCode\": 400,\n",
            "  \"message\": \"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\n",
            "\t1. Please check the logs for your container instance: aci-cifar10. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n",
            "\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n",
            "\t3. You can also try to run image viennaglobal.azurecr.io/azureml/azureml_31eff05d9938cbbdf21dfb15bccdb84f locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\",\n",
            "  \"details\": [\n",
            "    {\n",
            "      \"code\": \"CrashLoopBackOff\",\n",
            "      \"message\": \"Your container application crashed. This may be caused by errors in your scoring file's init() function.\n",
            "\t1. Please check the logs for your container instance: aci-cifar10. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n",
            "\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n",
            "\t3. You can also try to run image viennaglobal.azurecr.io/azureml/azureml_31eff05d9938cbbdf21dfb15bccdb84f locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\"\n",
            "    },\n",
            "    {\n",
            "      \"code\": \"AciDeploymentFailed\",\n",
            "      \"message\": \"Your container application crashed. Please follow the steps to debug:\n",
            "\t1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\n",
            "\t2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https://aka.ms/debugimage#debug-locally for more information.\n",
            "\t3. You can also interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n",
            "\t4. View the diagnostic events to check status of container, it may help you to debug the issue.\n",
            "\"RestartCount\": 3\n",
            "\"CurrentState\": {\"state\":\"Waiting\",\"startTime\":null,\"exitCode\":null,\"finishTime\":null,\"detailStatus\":\"CrashLoopBackOff: Back-off restarting failed\"}\n",
            "\"PreviousState\": {\"state\":\"Terminated\",\"startTime\":\"2021-03-29T05:45:28.726Z\",\"exitCode\":111,\"finishTime\":\"2021-03-29T05:45:37.92Z\",\"detailStatus\":\"Error\"}\n",
            "\"Events\":\n",
            "{\"count\":2,\"firstTimestamp\":\"2021-03-29T05:38:35Z\",\"lastTimestamp\":\"2021-03-29T05:43:16Z\",\"name\":\"Pulling\",\"message\":\"pulling image \"viennaglobal.azurecr.io/azureml/azureml_31eff05d9938cbbdf21dfb15bccdb84f@sha256:76a13c9d20bae83e7b2400ac3cd3bcd609e46e0f98433146017bde5edeeeff68\"\",\"type\":\"Normal\"}\n",
            "{\"count\":2,\"firstTimestamp\":\"2021-03-29T05:43:14Z\",\"lastTimestamp\":\"2021-03-29T05:43:18Z\",\"name\":\"Pulled\",\"message\":\"Successfully pulled image \"viennaglobal.azurecr.io/azureml/azureml_31eff05d9938cbbdf21dfb15bccdb84f@sha256:76a13c9d20bae83e7b2400ac3cd3bcd609e46e0f98433146017bde5edeeeff68\"\",\"type\":\"Normal\"}\n",
            "{\"count\":4,\"firstTimestamp\":\"2021-03-29T05:43:41Z\",\"lastTimestamp\":\"2021-03-29T05:45:28Z\",\"name\":\"Started\",\"message\":\"Started container\",\"type\":\"Normal\"}\n",
            "{\"count\":4,\"firstTimestamp\":\"2021-03-29T05:43:58Z\",\"lastTimestamp\":\"2021-03-29T05:45:37Z\",\"name\":\"Killing\",\"message\":\"Killing container with id f225e8c93c25723cb234a4b30e535129d3db73d05be5def00fc8ad4928886bc8.\",\"type\":\"Normal\"}\n",
            "\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "WebserviceException",
          "evalue": "WebserviceException:\n\tMessage: Service deployment polling reached non-successful terminal state, current service state: Failed\nOperation ID: eeacdf58-5648-4265-a866-ea90cba15aa7\nMore information can be found using '.get_logs()'\nError:\n{\n  \"code\": \"AciDeploymentFailed\",\n  \"statusCode\": 400,\n  \"message\": \"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\n\t1. Please check the logs for your container instance: aci-cifar10. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n\t3. You can also try to run image viennaglobal.azurecr.io/azureml/azureml_31eff05d9938cbbdf21dfb15bccdb84f locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\",\n  \"details\": [\n    {\n      \"code\": \"CrashLoopBackOff\",\n      \"message\": \"Your container application crashed. This may be caused by errors in your scoring file's init() function.\n\t1. Please check the logs for your container instance: aci-cifar10. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n\t3. You can also try to run image viennaglobal.azurecr.io/azureml/azureml_31eff05d9938cbbdf21dfb15bccdb84f locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\"\n    },\n    {\n      \"code\": \"AciDeploymentFailed\",\n      \"message\": \"Your container application crashed. Please follow the steps to debug:\n\t1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\n\t2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https://aka.ms/debugimage#debug-locally for more information.\n\t3. You can also interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n\t4. View the diagnostic events to check status of container, it may help you to debug the issue.\n\"RestartCount\": 3\n\"CurrentState\": {\"state\":\"Waiting\",\"startTime\":null,\"exitCode\":null,\"finishTime\":null,\"detailStatus\":\"CrashLoopBackOff: Back-off restarting failed\"}\n\"PreviousState\": {\"state\":\"Terminated\",\"startTime\":\"2021-03-29T05:45:28.726Z\",\"exitCode\":111,\"finishTime\":\"2021-03-29T05:45:37.92Z\",\"detailStatus\":\"Error\"}\n\"Events\":\n{\"count\":2,\"firstTimestamp\":\"2021-03-29T05:38:35Z\",\"lastTimestamp\":\"2021-03-29T05:43:16Z\",\"name\":\"Pulling\",\"message\":\"pulling image \"viennaglobal.azurecr.io/azureml/azureml_31eff05d9938cbbdf21dfb15bccdb84f@sha256:76a13c9d20bae83e7b2400ac3cd3bcd609e46e0f98433146017bde5edeeeff68\"\",\"type\":\"Normal\"}\n{\"count\":2,\"firstTimestamp\":\"2021-03-29T05:43:14Z\",\"lastTimestamp\":\"2021-03-29T05:43:18Z\",\"name\":\"Pulled\",\"message\":\"Successfully pulled image \"viennaglobal.azurecr.io/azureml/azureml_31eff05d9938cbbdf21dfb15bccdb84f@sha256:76a13c9d20bae83e7b2400ac3cd3bcd609e46e0f98433146017bde5edeeeff68\"\",\"type\":\"Normal\"}\n{\"count\":4,\"firstTimestamp\":\"2021-03-29T05:43:41Z\",\"lastTimestamp\":\"2021-03-29T05:45:28Z\",\"name\":\"Started\",\"message\":\"Started container\",\"type\":\"Normal\"}\n{\"count\":4,\"firstTimestamp\":\"2021-03-29T05:43:58Z\",\"lastTimestamp\":\"2021-03-29T05:45:37Z\",\"name\":\"Killing\",\"message\":\"Killing container with id f225e8c93c25723cb234a4b30e535129d3db73d05be5def00fc8ad4928886bc8.\",\"type\":\"Normal\"}\n\"\n    }\n  ]\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Service deployment polling reached non-successful terminal state, current service state: Failed\\nOperation ID: eeacdf58-5648-4265-a866-ea90cba15aa7\\nMore information can be found using '.get_logs()'\\nError:\\n{\\n  \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n  \\\"statusCode\\\": 400,\\n  \\\"message\\\": \\\"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\\n\\t1. Please check the logs for your container instance: aci-cifar10. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\\n\\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t3. You can also try to run image viennaglobal.azurecr.io/azureml/azureml_31eff05d9938cbbdf21dfb15bccdb84f locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\\\",\\n  \\\"details\\\": [\\n    {\\n      \\\"code\\\": \\\"CrashLoopBackOff\\\",\\n      \\\"message\\\": \\\"Your container application crashed. This may be caused by errors in your scoring file's init() function.\\n\\t1. Please check the logs for your container instance: aci-cifar10. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\\n\\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t3. You can also try to run image viennaglobal.azurecr.io/azureml/azureml_31eff05d9938cbbdf21dfb15bccdb84f locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\\\"\\n    },\\n    {\\n      \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n      \\\"message\\\": \\\"Your container application crashed. Please follow the steps to debug:\\n\\t1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\\n\\t2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https://aka.ms/debugimage#debug-locally for more information.\\n\\t3. You can also interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t4. View the diagnostic events to check status of container, it may help you to debug the issue.\\n\\\"RestartCount\\\": 3\\n\\\"CurrentState\\\": {\\\"state\\\":\\\"Waiting\\\",\\\"startTime\\\":null,\\\"exitCode\\\":null,\\\"finishTime\\\":null,\\\"detailStatus\\\":\\\"CrashLoopBackOff: Back-off restarting failed\\\"}\\n\\\"PreviousState\\\": {\\\"state\\\":\\\"Terminated\\\",\\\"startTime\\\":\\\"2021-03-29T05:45:28.726Z\\\",\\\"exitCode\\\":111,\\\"finishTime\\\":\\\"2021-03-29T05:45:37.92Z\\\",\\\"detailStatus\\\":\\\"Error\\\"}\\n\\\"Events\\\":\\n{\\\"count\\\":2,\\\"firstTimestamp\\\":\\\"2021-03-29T05:38:35Z\\\",\\\"lastTimestamp\\\":\\\"2021-03-29T05:43:16Z\\\",\\\"name\\\":\\\"Pulling\\\",\\\"message\\\":\\\"pulling image \\\"viennaglobal.azurecr.io/azureml/azureml_31eff05d9938cbbdf21dfb15bccdb84f@sha256:76a13c9d20bae83e7b2400ac3cd3bcd609e46e0f98433146017bde5edeeeff68\\\"\\\",\\\"type\\\":\\\"Normal\\\"}\\n{\\\"count\\\":2,\\\"firstTimestamp\\\":\\\"2021-03-29T05:43:14Z\\\",\\\"lastTimestamp\\\":\\\"2021-03-29T05:43:18Z\\\",\\\"name\\\":\\\"Pulled\\\",\\\"message\\\":\\\"Successfully pulled image \\\"viennaglobal.azurecr.io/azureml/azureml_31eff05d9938cbbdf21dfb15bccdb84f@sha256:76a13c9d20bae83e7b2400ac3cd3bcd609e46e0f98433146017bde5edeeeff68\\\"\\\",\\\"type\\\":\\\"Normal\\\"}\\n{\\\"count\\\":4,\\\"firstTimestamp\\\":\\\"2021-03-29T05:43:41Z\\\",\\\"lastTimestamp\\\":\\\"2021-03-29T05:45:28Z\\\",\\\"name\\\":\\\"Started\\\",\\\"message\\\":\\\"Started container\\\",\\\"type\\\":\\\"Normal\\\"}\\n{\\\"count\\\":4,\\\"firstTimestamp\\\":\\\"2021-03-29T05:43:58Z\\\",\\\"lastTimestamp\\\":\\\"2021-03-29T05:45:37Z\\\",\\\"name\\\":\\\"Killing\\\",\\\"message\\\":\\\"Killing container with id f225e8c93c25723cb234a4b30e535129d3db73d05be5def00fc8ad4928886bc8.\\\",\\\"type\\\":\\\"Normal\\\"}\\n\\\"\\n    }\\n  ]\\n}\"\n    }\n}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m~/.anyenv/envs/pyenv/versions/anaconda3-2020.11/envs/azureml_env/lib/python3.6/site-packages/azureml/core/webservice/webservice.py\u001b[0m in \u001b[0;36mwait_for_deployment\u001b[0;34m(self, show_output, timeout_sec)\u001b[0m\n\u001b[1;32m    921\u001b[0m                                           \u001b[0;34m'Error:\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m                                           '{}'.format(self.state, self._operation_endpoint.split('/')[-1],\n\u001b[0;32m--> 923\u001b[0;31m                                                       logs_response, format_error_response), logger=module_logger)\n\u001b[0m\u001b[1;32m    924\u001b[0m             print('{} service creation operation finished, operation \"{}\"'.format(self._webservice_type,\n\u001b[1;32m    925\u001b[0m                                                                                   operation_state))\n",
            "\u001b[0;31mWebserviceException\u001b[0m: WebserviceException:\n\tMessage: Service deployment polling reached non-successful terminal state, current service state: Failed\nOperation ID: eeacdf58-5648-4265-a866-ea90cba15aa7\nMore information can be found using '.get_logs()'\nError:\n{\n  \"code\": \"AciDeploymentFailed\",\n  \"statusCode\": 400,\n  \"message\": \"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\n\t1. Please check the logs for your container instance: aci-cifar10. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n\t3. You can also try to run image viennaglobal.azurecr.io/azureml/azureml_31eff05d9938cbbdf21dfb15bccdb84f locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\",\n  \"details\": [\n    {\n      \"code\": \"CrashLoopBackOff\",\n      \"message\": \"Your container application crashed. This may be caused by errors in your scoring file's init() function.\n\t1. Please check the logs for your container instance: aci-cifar10. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n\t3. You can also try to run image viennaglobal.azurecr.io/azureml/azureml_31eff05d9938cbbdf21dfb15bccdb84f locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\"\n    },\n    {\n      \"code\": \"AciDeploymentFailed\",\n      \"message\": \"Your container application crashed. Please follow the steps to debug:\n\t1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\n\t2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https://aka.ms/debugimage#debug-locally for more information.\n\t3. You can also interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n\t4. View the diagnostic events to check status of container, it may help you to debug the issue.\n\"RestartCount\": 3\n\"CurrentState\": {\"state\":\"Waiting\",\"startTime\":null,\"exitCode\":null,\"finishTime\":null,\"detailStatus\":\"CrashLoopBackOff: Back-off restarting failed\"}\n\"PreviousState\": {\"state\":\"Terminated\",\"startTime\":\"2021-03-29T05:45:28.726Z\",\"exitCode\":111,\"finishTime\":\"2021-03-29T05:45:37.92Z\",\"detailStatus\":\"Error\"}\n\"Events\":\n{\"count\":2,\"firstTimestamp\":\"2021-03-29T05:38:35Z\",\"lastTimestamp\":\"2021-03-29T05:43:16Z\",\"name\":\"Pulling\",\"message\":\"pulling image \"viennaglobal.azurecr.io/azureml/azureml_31eff05d9938cbbdf21dfb15bccdb84f@sha256:76a13c9d20bae83e7b2400ac3cd3bcd609e46e0f98433146017bde5edeeeff68\"\",\"type\":\"Normal\"}\n{\"count\":2,\"firstTimestamp\":\"2021-03-29T05:43:14Z\",\"lastTimestamp\":\"2021-03-29T05:43:18Z\",\"name\":\"Pulled\",\"message\":\"Successfully pulled image \"viennaglobal.azurecr.io/azureml/azureml_31eff05d9938cbbdf21dfb15bccdb84f@sha256:76a13c9d20bae83e7b2400ac3cd3bcd609e46e0f98433146017bde5edeeeff68\"\",\"type\":\"Normal\"}\n{\"count\":4,\"firstTimestamp\":\"2021-03-29T05:43:41Z\",\"lastTimestamp\":\"2021-03-29T05:45:28Z\",\"name\":\"Started\",\"message\":\"Started container\",\"type\":\"Normal\"}\n{\"count\":4,\"firstTimestamp\":\"2021-03-29T05:43:58Z\",\"lastTimestamp\":\"2021-03-29T05:45:37Z\",\"name\":\"Killing\",\"message\":\"Killing container with id f225e8c93c25723cb234a4b30e535129d3db73d05be5def00fc8ad4928886bc8.\",\"type\":\"Normal\"}\n\"\n    }\n  ]\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Service deployment polling reached non-successful terminal state, current service state: Failed\\nOperation ID: eeacdf58-5648-4265-a866-ea90cba15aa7\\nMore information can be found using '.get_logs()'\\nError:\\n{\\n  \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n  \\\"statusCode\\\": 400,\\n  \\\"message\\\": \\\"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\\n\\t1. Please check the logs for your container instance: aci-cifar10. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\\n\\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t3. You can also try to run image viennaglobal.azurecr.io/azureml/azureml_31eff05d9938cbbdf21dfb15bccdb84f locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\\\",\\n  \\\"details\\\": [\\n    {\\n      \\\"code\\\": \\\"CrashLoopBackOff\\\",\\n      \\\"message\\\": \\\"Your container application crashed. This may be caused by errors in your scoring file's init() function.\\n\\t1. Please check the logs for your container instance: aci-cifar10. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\\n\\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t3. You can also try to run image viennaglobal.azurecr.io/azureml/azureml_31eff05d9938cbbdf21dfb15bccdb84f locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\\\"\\n    },\\n    {\\n      \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n      \\\"message\\\": \\\"Your container application crashed. Please follow the steps to debug:\\n\\t1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\\n\\t2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https://aka.ms/debugimage#debug-locally for more information.\\n\\t3. You can also interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t4. View the diagnostic events to check status of container, it may help you to debug the issue.\\n\\\"RestartCount\\\": 3\\n\\\"CurrentState\\\": {\\\"state\\\":\\\"Waiting\\\",\\\"startTime\\\":null,\\\"exitCode\\\":null,\\\"finishTime\\\":null,\\\"detailStatus\\\":\\\"CrashLoopBackOff: Back-off restarting failed\\\"}\\n\\\"PreviousState\\\": {\\\"state\\\":\\\"Terminated\\\",\\\"startTime\\\":\\\"2021-03-29T05:45:28.726Z\\\",\\\"exitCode\\\":111,\\\"finishTime\\\":\\\"2021-03-29T05:45:37.92Z\\\",\\\"detailStatus\\\":\\\"Error\\\"}\\n\\\"Events\\\":\\n{\\\"count\\\":2,\\\"firstTimestamp\\\":\\\"2021-03-29T05:38:35Z\\\",\\\"lastTimestamp\\\":\\\"2021-03-29T05:43:16Z\\\",\\\"name\\\":\\\"Pulling\\\",\\\"message\\\":\\\"pulling image \\\"viennaglobal.azurecr.io/azureml/azureml_31eff05d9938cbbdf21dfb15bccdb84f@sha256:76a13c9d20bae83e7b2400ac3cd3bcd609e46e0f98433146017bde5edeeeff68\\\"\\\",\\\"type\\\":\\\"Normal\\\"}\\n{\\\"count\\\":2,\\\"firstTimestamp\\\":\\\"2021-03-29T05:43:14Z\\\",\\\"lastTimestamp\\\":\\\"2021-03-29T05:43:18Z\\\",\\\"name\\\":\\\"Pulled\\\",\\\"message\\\":\\\"Successfully pulled image \\\"viennaglobal.azurecr.io/azureml/azureml_31eff05d9938cbbdf21dfb15bccdb84f@sha256:76a13c9d20bae83e7b2400ac3cd3bcd609e46e0f98433146017bde5edeeeff68\\\"\\\",\\\"type\\\":\\\"Normal\\\"}\\n{\\\"count\\\":4,\\\"firstTimestamp\\\":\\\"2021-03-29T05:43:41Z\\\",\\\"lastTimestamp\\\":\\\"2021-03-29T05:45:28Z\\\",\\\"name\\\":\\\"Started\\\",\\\"message\\\":\\\"Started container\\\",\\\"type\\\":\\\"Normal\\\"}\\n{\\\"count\\\":4,\\\"firstTimestamp\\\":\\\"2021-03-29T05:43:58Z\\\",\\\"lastTimestamp\\\":\\\"2021-03-29T05:45:37Z\\\",\\\"name\\\":\\\"Killing\\\",\\\"message\\\":\\\"Killing container with id f225e8c93c25723cb234a4b30e535129d3db73d05be5def00fc8ad4928886bc8.\\\",\\\"type\\\":\\\"Normal\\\"}\\n\\\"\\n    }\\n  ]\\n}\"\n    }\n}"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "from azureml.core.webservice import AciWebservice\n",
        "from azureml.core.model import InferenceConfig\n",
        "from azureml.core.webservice import Webservice\n",
        "from azureml.core.model import Model\n",
        "\n",
        "#推論スクリプト・環境の指定\n",
        "inference_config = InferenceConfig(entry_script=\"score.py\", environment=aci_pytorch_env)\n",
        "\n",
        "#デプロイの構成設定\n",
        "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n",
        "                                               memory_gb=1, \n",
        "                                               tags={'data': 'cifar-10',  'model':'pytorch-distr', 'framework':'pytorch'},\n",
        "                                               description='Classify daily objects from the cifar-10 dataset using PyTorch')\n",
        "\n",
        "# model = Model(ws, 'pytorch-distr')\n",
        "\n",
        "service = Model.deploy(workspace=ws, \n",
        "                           name='aci-cifar10', \n",
        "                           models=[model], \n",
        "                           inference_config=inference_config, \n",
        "                           deployment_config=aciconfig,\n",
        "                           overwrite=True)\n",
        "\n",
        "service.wait_for_deployment(show_output=True)\n",
        "print(service.state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "# デプロイ中に問題が発生した場合にログ取得\n",
        "service.get_logs()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'service' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-ed7ba6c18264>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 再デプロイ前に既存のACIサービスを削除\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'service' is not defined"
          ]
        }
      ],
      "source": [
        "# 再デプロイ前に既存のACIサービスを削除\n",
        "service.delete()\n"
      ]
    },
    {
      "source": [
        "## モデルのテスト\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    }
  ],
  "metadata": {
    "authors": [
      {
        "name": "minxia"
      }
    ],
    "category": "training",
    "compute": [
      "AML Compute"
    ],
    "datasets": [
      "CIFAR-10"
    ],
    "deployment": [
      "None"
    ],
    "exclude_from_index": false,
    "framework": [
      "PyTorch"
    ],
    "friendly_name": "Distributed training with PyTorch",
    "index_order": 1,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.6.13 64-bit ('azureml_env': conda)",
      "metadata": {
        "interpreter": {
          "hash": "a42a8c4c03685684dad491b418acc9fb57f943aca37dd55d301283286111ed4f"
        }
      }
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "tags": [
      "None"
    ],
    "task": "Train a model using distributed training via PyTorch DistributedDataParallel"
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
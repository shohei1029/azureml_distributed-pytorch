{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Copyright (c) Microsoft Corporation. All rights reserved.\n",
        "\n",
        "Licensed under the MIT License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/how-to-use-azureml/ml-frameworks/pytorch/distributed-pytorch-with-horovod/distributed-pytorch-with-horovod.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Distributed PyTorch with DistributedDataParallel\n",
        "\n",
        "In this tutorial, you will train a PyTorch model on the [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset using distributed training with PyTorch's `DistributedDataParallel` module across a GPU cluster."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 前提条件確認 Prerequisites\n",
        "* If you are using an Azure Machine Learning Notebook VM, you are all set. Otherwise, go through the [Configuration](../../../../configuration.ipynb) notebook to install the Azure Machine Learning Python SDK and create an Azure ML `Workspace`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SDK version: 1.24.0\n"
          ]
        }
      ],
      "source": [
        "# Check core SDK version number\n",
        "import azureml.core\n",
        "\n",
        "print(\"SDK version:\", azureml.core.VERSION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Diagnostics\n",
        "Opt-in diagnostics for better experience, quality, and security of future releases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "tags": [
          "Diagnostics"
        ]
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Turning diagnostics collection on. \n"
          ]
        }
      ],
      "source": [
        "from azureml.telemetry import set_diagnostics_collection\n",
        "\n",
        "set_diagnostics_collection(send_diagnostics=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ワークスペースの設定 Initialize workspace\n",
        "\n",
        "Initialize a [Workspace](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#workspace) object from the existing workspace you created in the Prerequisites step. `Workspace.from_config()` creates a workspace object from the details stored in `config.json`.  \n",
        "Azure ML Studioから構成ファイル (config.json)をダウンロードし、本スクリプトと同一階層に置きます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Workspace name: ml-lab\nAzure region: westus2\nSubscription id: f57ce3c6-5c6f-4f1e-8cba-b782d8974590\nResource group: rg-aml\n"
          ]
        }
      ],
      "source": [
        "from azureml.core.workspace import Workspace\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "print('Workspace name: ' + ws.name, \n",
        "      'Azure region: ' + ws.location, \n",
        "      'Subscription id: ' + ws.subscription_id, \n",
        "      'Resource group: ' + ws.resource_group, sep='\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 計算環境の準備 Create or attach existing AmlCompute\n",
        "You will need to create a [compute target](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#compute-target) for training your model. In this tutorial, we use Azure ML managed compute ([AmlCompute](https://docs.microsoft.com/azure/machine-learning/service/how-to-set-up-training-targets#amlcompute)) for our remote training compute resource. Specifically, the below code creates an `STANDARD_NC6` GPU cluster that autoscales from `0` to `4` nodes.\n",
        "\n",
        "**Creation of AmlCompute takes approximately 5 minutes.** If the AmlCompute with that name is already in your workspace, this code will skip the creation process.\n",
        "\n",
        "As with other Azure services, there are limits on certain resources (e.g. AmlCompute) associated with the Azure Machine Learning service. Please read [this article](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-manage-quotas) on the default limits and how to request more quota."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating a new compute target...\n",
            "Creating...\n",
            "SucceededProvisioning operation finished, operation \"Succeeded\"\n",
            "Succeeded\n",
            "AmlCompute wait for completion finished\n",
            "\n",
            "Minimum number of nodes requested have been provisioned\n",
            "{'currentNodeCount': 0, 'targetNodeCount': 0, 'nodeStateCounts': {'preparingNodeCount': 0, 'runningNodeCount': 0, 'idleNodeCount': 0, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2021-03-22T09:03:03.412000+00:00', 'errors': None, 'creationTime': '2021-03-22T09:03:01.130767+00:00', 'modifiedTime': '2021-03-22T09:03:16.578884+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 4, 'nodeIdleTimeBeforeScaleDown': 'PT120S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_NC6'}\n"
          ]
        }
      ],
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "# choose a name for your cluster\n",
        "cluster_name = 'gpu-cluster'\n",
        "\n",
        "try:\n",
        "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
        "    print('Found existing compute target.')\n",
        "except ComputeTargetException:\n",
        "    print('Creating a new compute target...')\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_NC6',\n",
        "                                                           max_nodes=4)\n",
        "\n",
        "    # create the cluster\n",
        "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
        "\n",
        "    compute_target.wait_for_completion(show_output=True)\n",
        "\n",
        "# use get_status() to get a detailed status for the current AmlCompute. \n",
        "print(compute_target.get_status().serialize())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The above code creates GPU compute. If you instead want to create CPU compute, provide a different VM size to the `vm_size` parameter, such as `STANDARD_D2_V2`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## データセットの準備 Prepare dataset\n",
        "\n",
        "Prepare the dataset used for training. We will first download and extract the publicly available CIFAR-10 dataset from the cs.toronto.edu website and then create an Azure ML FileDataset to use the data for training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Download and extract CIFAR-10 data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import urllib\n",
        "import tarfile\n",
        "import os\n",
        "\n",
        "url = 'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'\n",
        "filename = 'cifar-10-python.tar.gz'\n",
        "data_root = 'cifar-10'\n",
        "filepath = os.path.join(data_root, filename)\n",
        "\n",
        "if not os.path.isdir(data_root):\n",
        "    os.makedirs(data_root, exist_ok=True)\n",
        "    urllib.request.urlretrieve(url, filepath)\n",
        "    with tarfile.open(filepath, \"r:gz\") as tar:\n",
        "        tar.extractall(path=data_root)\n",
        "    os.remove(filepath)  # delete tar.gz file after extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create Azure ML dataset\n",
        "\n",
        "The `upload_directory` method will upload the data to a datastore and create a FileDataset from it. In this tutorial we will use the workspace's default datastore."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Method upload_directory: This is an experimental method, and may change at any time.<br/>For more information, see https://aka.ms/azuremlexperimental.\n",
            "Validating arguments.\n",
            "Arguments validated.\n",
            "Uploading file to cifar-10\n",
            "Uploading an estimated of 8 files\n",
            "Uploading cifar-10/cifar-10-batches-py/batches.meta\n",
            "Uploaded cifar-10/cifar-10-batches-py/batches.meta, 1 files out of an estimated total of 8\n",
            "Uploading cifar-10/cifar-10-batches-py/readme.html\n",
            "Uploaded cifar-10/cifar-10-batches-py/readme.html, 2 files out of an estimated total of 8\n",
            "Uploading cifar-10/cifar-10-batches-py/data_batch_4\n",
            "Uploaded cifar-10/cifar-10-batches-py/data_batch_4, 3 files out of an estimated total of 8\n",
            "Uploading cifar-10/cifar-10-batches-py/data_batch_5\n",
            "Uploaded cifar-10/cifar-10-batches-py/data_batch_5, 4 files out of an estimated total of 8\n",
            "Uploading cifar-10/cifar-10-batches-py/data_batch_3\n",
            "Uploaded cifar-10/cifar-10-batches-py/data_batch_3, 5 files out of an estimated total of 8\n",
            "Uploading cifar-10/cifar-10-batches-py/test_batch\n",
            "Uploaded cifar-10/cifar-10-batches-py/test_batch, 6 files out of an estimated total of 8\n",
            "Uploading cifar-10/cifar-10-batches-py/data_batch_1\n",
            "Uploaded cifar-10/cifar-10-batches-py/data_batch_1, 7 files out of an estimated total of 8\n",
            "Uploading cifar-10/cifar-10-batches-py/data_batch_2\n",
            "Uploaded cifar-10/cifar-10-batches-py/data_batch_2, 8 files out of an estimated total of 8\n",
            "Uploaded 8 files\n",
            "Creating new dataset\n"
          ]
        }
      ],
      "source": [
        "from azureml.core import Dataset\n",
        "\n",
        "datastore = ws.get_default_datastore()\n",
        "dataset = Dataset.File.upload_directory(\n",
        "    src_dir=data_root, target=(datastore, data_root)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## モデル学習 Train model on the remote compute\n",
        "Now that we have the AmlCompute ready to go, let's run our distributed training job."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create a project directory\n",
        "Create a directory that will contain all the necessary code from your local machine that you will need access to on the remote resource. This includes the training script and any additional files your training script depends on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "project_folder = './pytorch-distr'\n",
        "os.makedirs(project_folder, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prepare training script\n",
        "Now you will need to create your training script. In this tutorial, the script for distributed training on CIFAR-10 is already provided for you at `train.py`. In practice, you should be able to take any custom PyTorch training script as is and run it with Azure ML without having to modify your code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once your script is ready, copy the training script `train.py` into the project directory.\n",
        "トレーニングスクリプトをプロジェクトディレクトリ内へコピーします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./pytorch-distr/train.py'"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "import shutil\n",
        "\n",
        "shutil.copy('train.py', project_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create an experiment\n",
        "Create an [Experiment](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#experiment) to track all the runs in your workspace for this distributed PyTorch tutorial. \n",
        "実験を設定します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core import Experiment\n",
        "\n",
        "experiment_name = 'pytorch-distr'\n",
        "experiment = Experiment(ws, name=experiment_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create an environment\n",
        "\n",
        "In this tutorial, we will use one of Azure ML's curated PyTorch environments for training. [Curated environments](https://docs.microsoft.com/azure/machine-learning/how-to-use-environments#use-a-curated-environment) are available in your workspace by default. Specifically, we will use the PyTorch 1.6 GPU curated environment.  \n",
        "\n",
        "Azure MLではいくつかの[キュレートされた実行環境](https://docs.microsoft.com/ja-jp/azure/machine-learning/how-to-use-environments#use-a-curated-environment)が用意されています。\n",
        "今回はPyTorch 1.6 GPU環境を使用します。こちらのキュレートされた環境には今回のトレーニングスクリプトで必要なtorch, torchvisionも含まれています。\n",
        "\n",
        "参考：[キュレーションされた環境一覧](https://docs.microsoft.com/ja-jp/azure/machine-learning/resource-curated-environments)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core import Environment\n",
        "\n",
        "pytorch_env = Environment.get(ws, name='AzureML-PyTorch-1.6-GPU')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Configure the training job\n",
        "\n",
        "To launch a distributed PyTorch job on Azure ML, you have two options:\n",
        "\n",
        "1. Per-process launch - specify the total # of worker processes (typically one per GPU) you want to run, and\n",
        "Azure ML will handle launching each process.\n",
        "2. Per-node launch with [torch.distributed.launch](https://pytorch.org/docs/stable/distributed.html#launch-utility) - provide the `torch.distributed.launch` command you want to\n",
        "run on each node.\n",
        "\n",
        "For more information, see the [documentation](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-train-pytorch#distributeddataparallel).\n",
        "\n",
        "Both options are shown below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Per-process launch\n",
        "\n",
        "To use the per-process launch option in which Azure ML will handle launching each of the processes to run your training script,\n",
        "\n",
        "1. Specify the training script and arguments\n",
        "2. Create a `PyTorchConfiguration` and specify `node_count` and `process_count`. The `process_count` is the total number of processes you want to run for the job; this should typically equal the # of GPUs available on each node multiplied by the # of nodes. Since this tutorial uses the `STANDARD_NC6` SKU, which has one GPU, the total process count for a 2-node job is `2`. If you are using a SKU with >1 GPUs, adjust the `process_count` accordingly.\n",
        "\n",
        "Azure ML will set the `MASTER_ADDR`, `MASTER_PORT`, `NODE_RANK`, `WORLD_SIZE` environment variables on each node, in addition to the process-level `RANK` and `LOCAL_RANK` environment variables, that are needed for distributed PyTorch training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core import ScriptRunConfig\n",
        "from azureml.core.runconfig import PyTorchConfiguration\n",
        "\n",
        "# create distributed config\n",
        "distr_config = PyTorchConfiguration(process_count=2, node_count=2)\n",
        "\n",
        "# create args\n",
        "args = [\"--data-dir\", dataset.as_download(), \"--epochs\", 25]\n",
        "\n",
        "# create job config\n",
        "src = ScriptRunConfig(source_directory=project_folder,\n",
        "                      script='train.py',\n",
        "                      arguments=args,\n",
        "                      compute_target=compute_target,\n",
        "                      environment=pytorch_env,\n",
        "                      distributed_job_config=distr_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Per-node launch with `torch.distributed.launch`\n",
        "\n",
        "If you would instead like to use the PyTorch-provided launch utility `torch.distributed.launch` to handle launching the worker processes on each node, you can do so as well. \n",
        "\n",
        "1. Provide the launch command to the `command` parameter of ScriptRunConfig. For PyTorch jobs Azure ML will set the `MASTER_ADDR`, `MASTER_PORT`, and `NODE_RANK` environment variables on each node, so you can simply just reference those environment variables in your command. If you are using a SKU with >1 GPUs, adjust the `--nproc_per_node` argument accordingly.\n",
        "\n",
        "2. Create a `PyTorchConfiguration` and specify the `node_count`. You do not need to specify the `process_count`; by default Azure ML will launch one process per node to run the `command` you provided.\n",
        "\n",
        "Uncomment the code below to configure a job with this method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "from azureml.core import ScriptRunConfig\n",
        "from azureml.core.runconfig import PyTorchConfiguration\n",
        "\n",
        "# create distributed config\n",
        "distr_config = PyTorchConfiguration(node_count=2)\n",
        "\n",
        "# define command\n",
        "launch_cmd = [\"python -m torch.distributed.launch --nproc_per_node 1 --nnodes 2 \" \\\n",
        "    \"--node_rank $NODE_RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT --use_env \" \\\n",
        "    \"train.py --data-dir\", dataset.as_download(), \"--epochs 25\"]\n",
        "\n",
        "# create job config\n",
        "src = ScriptRunConfig(source_directory=project_folder,\n",
        "                      command=launch_cmd,\n",
        "                      compute_target=compute_target,\n",
        "                      environment=pytorch_env,\n",
        "                      distributed_job_config=distr_config)\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Submit job\n",
        "Run your experiment by submitting your `ScriptRunConfig` object. Note that this call is asynchronous."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run(Experiment: pytorch-distr,\nId: pytorch-distr_1616469757_10343fff,\nType: azureml.scriptrun,\nStatus: Preparing)\n"
          ]
        }
      ],
      "source": [
        "run = experiment.submit(src)\n",
        "print(run)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Monitor your run\n",
        "You can monitor the progress of the run with a Jupyter widget. Like the run submission, the widget is asynchronous and provides live updates every 10-15 seconds until the job completes. You can see that the widget automatically plots and visualizes the loss metric that we logged to the Azure ML run.\n",
        "\n",
        "Jupyterウィジェットを使って実行の進捗状況を監視することができます。実行のサブミッションと同様に、ウィジェットは非同期で、ジョブが完了するまで10～15秒ごとに自動で更新されます。ウィジェットでは、Azure MLの実行に記録した損失指標が自動的に表示・可視化されます。\n",
        "\n",
        "※VSCode上で実行する場合、テーマ設定 (背景色)によってはAzure MLウィジェットが見えにくくなる可能性があります。その場合はLightテーマの使用をお勧めします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': True, 'log_level': 'INFO', 's…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5fcac5e674d54d728aceb77fd51fa95b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/pytorch-distr/runs/pytorch-distr_1616469757_10343fff?wsid=/subscriptions/f57ce3c6-5c6f-4f1e-8cba-b782d8974590/resourcegroups/rg-aml/workspaces/ml-lab\", \"run_id\": \"pytorch-distr_1616469757_10343fff\", \"run_properties\": {\"run_id\": \"pytorch-distr_1616469757_10343fff\", \"created_utc\": \"2021-03-23T03:22:43.974327Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"amlcompute\", \"ContentSnapshotId\": \"c0226cb2-4817-4968-8d05-686acc882c88\", \"azureml.git.repository_uri\": \"git@github.com:shohei1029/azureml_distributed-pytorch.git\", \"mlflow.source.git.repoURL\": \"git@github.com:shohei1029/azureml_distributed-pytorch.git\", \"azureml.git.branch\": \"main\", \"mlflow.source.git.branch\": \"main\", \"azureml.git.commit\": \"84044cc0fe460472a82c57dc72329f82d8ab098f\", \"mlflow.source.git.commit\": \"84044cc0fe460472a82c57dc72329f82d8ab098f\", \"azureml.git.dirty\": \"True\", \"ProcessInfoFile\": \"azureml-logs/process_info.json\", \"ProcessStatusFile\": \"azureml-logs/process_status.json\"}, \"tags\": {\"_aml_system_ComputeTargetStatus\": \"{\\\"AllocationState\\\":\\\"steady\\\",\\\"PreparingNodeCount\\\":0,\\\"RunningNodeCount\\\":0,\\\"CurrentNodeCount\\\":0}\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2021-03-23T03:39:42.480751Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/55_azureml-execution-tvmps_4f13e3e147a6a49a8fc39a6306f5d937293ceb882e0caaf97da18838e9af81b1_d.txt\": \"https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616469757_10343fff/azureml-logs/55_azureml-execution-tvmps_4f13e3e147a6a49a8fc39a6306f5d937293ceb882e0caaf97da18838e9af81b1_d.txt?sv=2019-02-02&sr=b&sig=TXlrSUDMNiXgC3LLRowYfDDYKcKd6Pe9T8CZREeZOBU%3D&st=2021-03-23T07%3A31%3A20Z&se=2021-03-23T15%3A41%3A20Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_b9f912d8d6d3d93bc36ffdeb087aae97569c4c6a2acd31376ef2b5fecf92fc95_d.txt\": \"https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616469757_10343fff/azureml-logs/55_azureml-execution-tvmps_b9f912d8d6d3d93bc36ffdeb087aae97569c4c6a2acd31376ef2b5fecf92fc95_d.txt?sv=2019-02-02&sr=b&sig=%2FxcLbruWauvMszce2RU7lURnbl0pNWLRXFMGiVDELbY%3D&st=2021-03-23T07%3A31%3A20Z&se=2021-03-23T15%3A41%3A20Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_4f13e3e147a6a49a8fc39a6306f5d937293ceb882e0caaf97da18838e9af81b1_d.txt\": \"https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616469757_10343fff/azureml-logs/65_job_prep-tvmps_4f13e3e147a6a49a8fc39a6306f5d937293ceb882e0caaf97da18838e9af81b1_d.txt?sv=2019-02-02&sr=b&sig=hsiMPYBAko3oiavHV6DvXh5CAG4VvmEghelYTA383uo%3D&st=2021-03-23T07%3A31%3A20Z&se=2021-03-23T15%3A41%3A20Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_b9f912d8d6d3d93bc36ffdeb087aae97569c4c6a2acd31376ef2b5fecf92fc95_d.txt\": \"https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616469757_10343fff/azureml-logs/65_job_prep-tvmps_b9f912d8d6d3d93bc36ffdeb087aae97569c4c6a2acd31376ef2b5fecf92fc95_d.txt?sv=2019-02-02&sr=b&sig=vTTFz6ZJ5%2FCTy7ZuxNw0SdwDWxRy%2B5RfRu1zrd%2BdbT4%3D&st=2021-03-23T07%3A31%3A20Z&se=2021-03-23T15%3A41%3A20Z&sp=r\", \"azureml-logs/70_driver_log_0.txt\": \"https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616469757_10343fff/azureml-logs/70_driver_log_0.txt?sv=2019-02-02&sr=b&sig=hYC2v5GfBC8lcWw7i1qWacQn5zHc%2FHz2eQvV%2BcKKjh4%3D&st=2021-03-23T07%3A31%3A20Z&se=2021-03-23T15%3A41%3A20Z&sp=r\", \"azureml-logs/70_driver_log_1.txt\": \"https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616469757_10343fff/azureml-logs/70_driver_log_1.txt?sv=2019-02-02&sr=b&sig=ePiCkd%2BQpMBxzlO7yFUUeuXXW8qSvtJWkD7JIOleu60%3D&st=2021-03-23T07%3A31%3A20Z&se=2021-03-23T15%3A41%3A20Z&sp=r\", \"azureml-logs/75_job_post-tvmps_4f13e3e147a6a49a8fc39a6306f5d937293ceb882e0caaf97da18838e9af81b1_d.txt\": \"https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616469757_10343fff/azureml-logs/75_job_post-tvmps_4f13e3e147a6a49a8fc39a6306f5d937293ceb882e0caaf97da18838e9af81b1_d.txt?sv=2019-02-02&sr=b&sig=Mdw9qgrE%2FZFdwwGYNdhElCGNWZkHS7ZKq9snbJQyG54%3D&st=2021-03-23T07%3A31%3A20Z&se=2021-03-23T15%3A41%3A20Z&sp=r\", \"azureml-logs/75_job_post-tvmps_b9f912d8d6d3d93bc36ffdeb087aae97569c4c6a2acd31376ef2b5fecf92fc95_d.txt\": \"https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616469757_10343fff/azureml-logs/75_job_post-tvmps_b9f912d8d6d3d93bc36ffdeb087aae97569c4c6a2acd31376ef2b5fecf92fc95_d.txt?sv=2019-02-02&sr=b&sig=WogmepwRSKziZr9292LL6fFdoY88mljJVU1qmk4W8vQ%3D&st=2021-03-23T07%3A31%3A20Z&se=2021-03-23T15%3A41%3A20Z&sp=r\", \"azureml-logs/process_info.json\": \"https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616469757_10343fff/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=nkNWmthQjhiIpFZP5zF5i6ALd67sLuVC71xJOO0Zz4s%3D&st=2021-03-23T07%3A31%3A20Z&se=2021-03-23T15%3A41%3A20Z&sp=r\", \"azureml-logs/process_status.json\": \"https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616469757_10343fff/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=pnjv5Wzq7jH9oe8U7Ya3dRtjFC8vLiYLtuIbgfCdNKM%3D&st=2021-03-23T07%3A31%3A20Z&se=2021-03-23T15%3A41%3A20Z&sp=r\", \"logs/azureml/0_109_azureml.log\": \"https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616469757_10343fff/logs/azureml/0_109_azureml.log?sv=2019-02-02&sr=b&sig=uijh7ehgqcPrSfk4YN1SM4cBrVvGoOLSUv%2FElnptosA%3D&st=2021-03-23T07%3A31%3A20Z&se=2021-03-23T15%3A41%3A20Z&sp=r\", \"logs/azureml/1_88_azureml.log\": \"https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616469757_10343fff/logs/azureml/1_88_azureml.log?sv=2019-02-02&sr=b&sig=4cZkdi5DHADGvgJK3qu%2FoZYzxM6weq5vFfv162sZnmI%3D&st=2021-03-23T07%3A31%3A20Z&se=2021-03-23T15%3A41%3A20Z&sp=r\", \"logs/azureml/dataprep/backgroundProcess.log\": \"https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616469757_10343fff/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=oDvSalB9ak1fPV972uUhow3EtkboX9YyDQnKsDPeyDQ%3D&st=2021-03-23T07%3A31%3A21Z&se=2021-03-23T15%3A41%3A21Z&sp=r\", \"logs/azureml/dataprep/backgroundProcess_Telemetry.log\": \"https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616469757_10343fff/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=TYntA4dCGsatObOFRXwp9f8iSci5%2BEtBnq9vkUC7J%2FA%3D&st=2021-03-23T07%3A31%3A21Z&se=2021-03-23T15%3A41%3A21Z&sp=r\", \"logs/azureml/job_prep_azureml.log\": \"https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616469757_10343fff/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=XjD%2FgGehLTwDUDCQO8m5F4kj5CZmwUjl0PJ32NCagD4%3D&st=2021-03-23T07%3A31%3A21Z&se=2021-03-23T15%3A41%3A21Z&sp=r\", \"logs/azureml/job_release_azureml.log\": \"https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616469757_10343fff/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=wbMDQvpDwGIP46DWTNqvUTNvJ8VcvxMtralCfsRRlzQ%3D&st=2021-03-23T07%3A31%3A21Z&se=2021-03-23T15%3A41%3A21Z&sp=r\", \"logs/azureml/sidecar/tvmps_4f13e3e147a6a49a8fc39a6306f5d937293ceb882e0caaf97da18838e9af81b1_d/all.log\": \"https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616469757_10343fff/logs/azureml/sidecar/tvmps_4f13e3e147a6a49a8fc39a6306f5d937293ceb882e0caaf97da18838e9af81b1_d/all.log?sv=2019-02-02&sr=b&sig=GipYI8s4XkZ7M0bYIhW%2BPN2gNQJJYweFiRzswWqXb3U%3D&st=2021-03-23T07%3A31%3A21Z&se=2021-03-23T15%3A41%3A21Z&sp=r\", \"logs/azureml/sidecar/tvmps_4f13e3e147a6a49a8fc39a6306f5d937293ceb882e0caaf97da18838e9af81b1_d/task.enter_contexts.log\": \"https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616469757_10343fff/logs/azureml/sidecar/tvmps_4f13e3e147a6a49a8fc39a6306f5d937293ceb882e0caaf97da18838e9af81b1_d/task.enter_contexts.log?sv=2019-02-02&sr=b&sig=doPVQJDvpOUFc9ks6r5p3Kd68NVjKmhic6W%2FwZFO6Lg%3D&st=2021-03-23T07%3A31%3A21Z&se=2021-03-23T15%3A41%3A21Z&sp=r\", \"logs/azureml/sidecar/tvmps_4f13e3e147a6a49a8fc39a6306f5d937293ceb882e0caaf97da18838e9af81b1_d/task.exit_contexts.log\": \"https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616469757_10343fff/logs/azureml/sidecar/tvmps_4f13e3e147a6a49a8fc39a6306f5d937293ceb882e0caaf97da18838e9af81b1_d/task.exit_contexts.log?sv=2019-02-02&sr=b&sig=qwp%2B1KdwEOWesF0gvSGxjOsrQ2BSXg8JpyGxSZzhdJ8%3D&st=2021-03-23T07%3A31%3A21Z&se=2021-03-23T15%3A41%3A21Z&sp=r\", \"logs/azureml/sidecar/tvmps_b9f912d8d6d3d93bc36ffdeb087aae97569c4c6a2acd31376ef2b5fecf92fc95_d/all.log\": \"https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616469757_10343fff/logs/azureml/sidecar/tvmps_b9f912d8d6d3d93bc36ffdeb087aae97569c4c6a2acd31376ef2b5fecf92fc95_d/all.log?sv=2019-02-02&sr=b&sig=OAlfpgC2JXczWWBsEvfOOUMLCaLyA%2BU7HS6jXOtjHNs%3D&st=2021-03-23T07%3A31%3A21Z&se=2021-03-23T15%3A41%3A21Z&sp=r\", \"logs/azureml/sidecar/tvmps_b9f912d8d6d3d93bc36ffdeb087aae97569c4c6a2acd31376ef2b5fecf92fc95_d/task.enter_contexts.log\": \"https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616469757_10343fff/logs/azureml/sidecar/tvmps_b9f912d8d6d3d93bc36ffdeb087aae97569c4c6a2acd31376ef2b5fecf92fc95_d/task.enter_contexts.log?sv=2019-02-02&sr=b&sig=7XbmaJHnrOP0u%2BtRvpK%2BOu%2BMbxUafXBx8R8XaqXPZmo%3D&st=2021-03-23T07%3A31%3A21Z&se=2021-03-23T15%3A41%3A21Z&sp=r\", \"logs/azureml/sidecar/tvmps_b9f912d8d6d3d93bc36ffdeb087aae97569c4c6a2acd31376ef2b5fecf92fc95_d/task.exit_contexts.log\": \"https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616469757_10343fff/logs/azureml/sidecar/tvmps_b9f912d8d6d3d93bc36ffdeb087aae97569c4c6a2acd31376ef2b5fecf92fc95_d/task.exit_contexts.log?sv=2019-02-02&sr=b&sig=MsP2%2BQI%2BT6CRRQeSPVuR69QbridvtHMJVP7ySIhzpjY%3D&st=2021-03-23T07%3A31%3A21Z&se=2021-03-23T15%3A41%3A21Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/process_info.json\", \"azureml-logs/process_status.json\", \"logs/azureml/dataprep/backgroundProcess.log\", \"logs/azureml/dataprep/backgroundProcess_Telemetry.log\", \"logs/azureml/job_prep_azureml.log\", \"logs/azureml/job_release_azureml.log\"], [\"logs/azureml/0_109_azureml.log\"], [\"logs/azureml/1_88_azureml.log\"], [\"logs/azureml/sidecar/tvmps_4f13e3e147a6a49a8fc39a6306f5d937293ceb882e0caaf97da18838e9af81b1_d/all.log\", \"logs/azureml/sidecar/tvmps_4f13e3e147a6a49a8fc39a6306f5d937293ceb882e0caaf97da18838e9af81b1_d/task.enter_contexts.log\", \"logs/azureml/sidecar/tvmps_4f13e3e147a6a49a8fc39a6306f5d937293ceb882e0caaf97da18838e9af81b1_d/task.exit_contexts.log\"], [\"logs/azureml/sidecar/tvmps_b9f912d8d6d3d93bc36ffdeb087aae97569c4c6a2acd31376ef2b5fecf92fc95_d/all.log\", \"logs/azureml/sidecar/tvmps_b9f912d8d6d3d93bc36ffdeb087aae97569c4c6a2acd31376ef2b5fecf92fc95_d/task.enter_contexts.log\", \"logs/azureml/sidecar/tvmps_b9f912d8d6d3d93bc36ffdeb087aae97569c4c6a2acd31376ef2b5fecf92fc95_d/task.exit_contexts.log\"], [\"azureml-logs/55_azureml-execution-tvmps_4f13e3e147a6a49a8fc39a6306f5d937293ceb882e0caaf97da18838e9af81b1_d.txt\", \"azureml-logs/55_azureml-execution-tvmps_b9f912d8d6d3d93bc36ffdeb087aae97569c4c6a2acd31376ef2b5fecf92fc95_d.txt\"], [\"azureml-logs/65_job_prep-tvmps_4f13e3e147a6a49a8fc39a6306f5d937293ceb882e0caaf97da18838e9af81b1_d.txt\", \"azureml-logs/65_job_prep-tvmps_b9f912d8d6d3d93bc36ffdeb087aae97569c4c6a2acd31376ef2b5fecf92fc95_d.txt\"], [\"azureml-logs/70_driver_log_0.txt\", \"azureml-logs/70_driver_log_1.txt\"], [\"azureml-logs/75_job_post-tvmps_4f13e3e147a6a49a8fc39a6306f5d937293ceb882e0caaf97da18838e9af81b1_d.txt\", \"azureml-logs/75_job_post-tvmps_b9f912d8d6d3d93bc36ffdeb087aae97569c4c6a2acd31376ef2b5fecf92fc95_d.txt\"]], \"run_duration\": \"0:16:58\", \"run_number\": \"1\", \"run_queued_details\": {\"status\": \"Completed\", \"details\": null}}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [], \"run_logs\": \"[2021-03-23T03:39:22.861006] Entering job release\\r\\n[2021-03-23T03:39:23.914653] job release stage : copy_batchai_cached_logs starting...\\r\\n[2021-03-23T03:39:23.914703] job release stage : copy_batchai_cached_logs completed...\\r\\n[2021-03-23T03:39:23.914754] Running in AzureML-Sidecar, starting to exit user context managers...\\r\\n[2021-03-23T03:39:23.915204] Running Sidecar release cmd...\\r\\n[2021-03-23T03:39:23.923062] INFO azureml.sidecar.sidecar: Received task: exit_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-lab/azureml/pytorch-distr_1616469757_10343fff/mounts/workspaceblobstore/azureml/pytorch-distr_1616469757_10343fff\\r\\nEnter __exit__ of DatasetContextManager\\r\\nExit __exit__ of DatasetContextManager\\r\\n[2021-03-23T03:39:23.947204] Removing absolute paths from host...\\r\\n[2021-03-23T03:39:24.158704] INFO azureml.sidecar.task.exit_contexts: Exited Context Managers\\r\\n[2021-03-23T03:39:24.996758] Ran Sidecar release cmd.\\r\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": true, \"log_level\": \"INFO\", \"sdk_version\": \"1.24.0\"}, \"loading\": false}"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from azureml.widgets import RunDetails\n",
        "\n",
        "RunDetails(run).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Alternatively, you can block until the script has completed training before running more code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RunId: pytorch-distr_1616469757_10343fff\n",
            "Web View: https://ml.azure.com/experiments/pytorch-distr/runs/pytorch-distr_1616469757_10343fff?wsid=/subscriptions/f57ce3c6-5c6f-4f1e-8cba-b782d8974590/resourcegroups/rg-aml/workspaces/ml-lab\n",
            "\n",
            "Execution Summary\n",
            "=================\n",
            "RunId: pytorch-distr_1616469757_10343fff\n",
            "Web View: https://ml.azure.com/experiments/pytorch-distr/runs/pytorch-distr_1616469757_10343fff?wsid=/subscriptions/f57ce3c6-5c6f-4f1e-8cba-b782d8974590/resourcegroups/rg-aml/workspaces/ml-lab\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'runId': 'pytorch-distr_1616469757_10343fff',\n",
              " 'target': 'gpu-cluster',\n",
              " 'status': 'Completed',\n",
              " 'startTimeUtc': '2021-03-23T03:26:20.712897Z',\n",
              " 'endTimeUtc': '2021-03-23T03:39:42.480751Z',\n",
              " 'properties': {'_azureml.ComputeTargetType': 'amlcompute',\n",
              "  'ContentSnapshotId': 'c0226cb2-4817-4968-8d05-686acc882c88',\n",
              "  'azureml.git.repository_uri': 'git@github.com:shohei1029/azureml_distributed-pytorch.git',\n",
              "  'mlflow.source.git.repoURL': 'git@github.com:shohei1029/azureml_distributed-pytorch.git',\n",
              "  'azureml.git.branch': 'main',\n",
              "  'mlflow.source.git.branch': 'main',\n",
              "  'azureml.git.commit': '84044cc0fe460472a82c57dc72329f82d8ab098f',\n",
              "  'mlflow.source.git.commit': '84044cc0fe460472a82c57dc72329f82d8ab098f',\n",
              "  'azureml.git.dirty': 'True',\n",
              "  'ProcessInfoFile': 'azureml-logs/process_info.json',\n",
              "  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n",
              " 'inputDatasets': [{'dataset': {'id': '5552c1f0-d54d-4c12-9dea-c3c6d08c5c4f'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'input__9a93846a', 'mechanism': 'Download'}}],\n",
              " 'outputDatasets': [],\n",
              " 'runDefinition': {'script': 'train.py',\n",
              "  'command': '',\n",
              "  'useAbsolutePath': False,\n",
              "  'arguments': ['--data-dir',\n",
              "   'DatasetConsumptionConfig:input__9a93846a',\n",
              "   '--epochs',\n",
              "   '25'],\n",
              "  'sourceDirectoryDataStore': None,\n",
              "  'framework': 'PyTorch',\n",
              "  'communicator': 'Nccl',\n",
              "  'target': 'gpu-cluster',\n",
              "  'dataReferences': {},\n",
              "  'data': {'input__9a93846a': {'dataLocation': {'dataset': {'id': '5552c1f0-d54d-4c12-9dea-c3c6d08c5c4f',\n",
              "      'name': None,\n",
              "      'version': None},\n",
              "     'dataPath': None},\n",
              "    'mechanism': 'Download',\n",
              "    'environmentVariableName': 'input__9a93846a',\n",
              "    'pathOnCompute': None,\n",
              "    'overwrite': False}},\n",
              "  'outputData': {},\n",
              "  'jobName': None,\n",
              "  'maxRunDurationSeconds': 2592000,\n",
              "  'nodeCount': 2,\n",
              "  'priority': None,\n",
              "  'credentialPassthrough': False,\n",
              "  'identity': None,\n",
              "  'environment': {'name': 'AzureML-PyTorch-1.6-GPU',\n",
              "   'version': '10',\n",
              "   'python': {'interpreterPath': 'python',\n",
              "    'userManagedDependencies': False,\n",
              "    'condaDependencies': {'channels': ['conda-forge'],\n",
              "     'dependencies': ['python=3.6.2',\n",
              "      {'pip': ['azureml-core==1.18.0.post1',\n",
              "        'azureml-defaults==1.18.0',\n",
              "        'azureml-telemetry==1.18.0',\n",
              "        'azureml-train-restclients-hyperdrive==1.18.0',\n",
              "        'azureml-train-core==1.18.0',\n",
              "        'cmake==3.18.2',\n",
              "        'torch==1.6.0',\n",
              "        'torchvision==0.5.0',\n",
              "        'mkl==2018.0.3',\n",
              "        'horovod==0.20.0',\n",
              "        'tensorboard==1.14.0',\n",
              "        'future==0.17.1']}],\n",
              "     'name': 'azureml_9d2a515d5c77954f2d0562cc5eb8a1fc'},\n",
              "    'baseCondaEnvironment': None},\n",
              "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE',\n",
              "    'NCCL_TREE_THRESHOLD': '0'},\n",
              "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-cuda10.1-cudnn7-ubuntu18.04:20201112.v1',\n",
              "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
              "    'baseDockerfile': None,\n",
              "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
              "    'enabled': False,\n",
              "    'arguments': []},\n",
              "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
              "   'inferencingStackVersion': None},\n",
              "  'history': {'outputCollection': True,\n",
              "   'directoriesToWatch': ['logs'],\n",
              "   'enableMLflowTracking': True,\n",
              "   'snapshotProject': True},\n",
              "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
              "    'spark.yarn.maxAppAttempts': '1'}},\n",
              "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
              "   'workerCountPerNode': 1,\n",
              "   'terminalExitCodes': None,\n",
              "   'configuration': {}},\n",
              "  'amlCompute': {'name': None,\n",
              "   'vmSize': None,\n",
              "   'retainCluster': False,\n",
              "   'clusterMaxNodeCount': None},\n",
              "  'aiSuperComputer': {'instanceType': None,\n",
              "   'imageVersion': None,\n",
              "   'location': None,\n",
              "   'aiSuperComputerStorageData': None,\n",
              "   'interactive': False,\n",
              "   'scalePolicy': None,\n",
              "   'virtualClusterArmId': None},\n",
              "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
              "  'mpi': {'processCountPerNode': 1},\n",
              "  'pyTorch': {'communicationBackend': 'nccl', 'processCount': 2},\n",
              "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
              "  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n",
              "  'exposedPorts': None,\n",
              "  'docker': {'useDocker': False,\n",
              "   'sharedVolumes': True,\n",
              "   'shmSize': '2g',\n",
              "   'arguments': []},\n",
              "  'cmk8sCompute': {'configuration': {}},\n",
              "  'commandReturnCodeConfig': {'returnCode': 'Zero',\n",
              "   'successfulReturnCodes': []},\n",
              "  'environmentVariables': {}},\n",
              " 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_4f13e3e147a6a49a8fc39a6306f5d937293ceb882e0caaf97da18838e9af81b1_d.txt': 'https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616469757_10343fff/azureml-logs/55_azureml-execution-tvmps_4f13e3e147a6a49a8fc39a6306f5d937293ceb882e0caaf97da18838e9af81b1_d.txt?sv=2019-02-02&sr=b&sig=7ud0FmFgWfjQh4hJ9%2Fa3FYmVQkeHAyKeM%2BGu5HiHlQw%3D&st=2021-03-23T04%3A29%3A54Z&se=2021-03-23T12%3A39%3A54Z&sp=r',\n",
              "  'azureml-logs/55_azureml-execution-tvmps_b9f912d8d6d3d93bc36ffdeb087aae97569c4c6a2acd31376ef2b5fecf92fc95_d.txt': 'https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616469757_10343fff/azureml-logs/55_azureml-execution-tvmps_b9f912d8d6d3d93bc36ffdeb087aae97569c4c6a2acd31376ef2b5fecf92fc95_d.txt?sv=2019-02-02&sr=b&sig=8t3p0CWxfkAn8rTY87Fy%2Bzc60LxPDC6iZUlIcdlqpfw%3D&st=2021-03-23T04%3A29%3A54Z&se=2021-03-23T12%3A39%3A54Z&sp=r',\n",
              "  'azureml-logs/65_job_prep-tvmps_4f13e3e147a6a49a8fc39a6306f5d937293ceb882e0caaf97da18838e9af81b1_d.txt': 'https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616469757_10343fff/azureml-logs/65_job_prep-tvmps_4f13e3e147a6a49a8fc39a6306f5d937293ceb882e0caaf97da18838e9af81b1_d.txt?sv=2019-02-02&sr=b&sig=Sq6BOzVvsCCQSksHVWGWH76hokpofaFooK895XKdf4s%3D&st=2021-03-23T04%3A29%3A54Z&se=2021-03-23T12%3A39%3A54Z&sp=r',\n",
              "  'azureml-logs/65_job_prep-tvmps_b9f912d8d6d3d93bc36ffdeb087aae97569c4c6a2acd31376ef2b5fecf92fc95_d.txt': 'https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616469757_10343fff/azureml-logs/65_job_prep-tvmps_b9f912d8d6d3d93bc36ffdeb087aae97569c4c6a2acd31376ef2b5fecf92fc95_d.txt?sv=2019-02-02&sr=b&sig=%2BFK2xEJ1K4ZpmDhl4FoQCiZOAikctO1BpKfS5hvJSJ8%3D&st=2021-03-23T04%3A29%3A55Z&se=2021-03-23T12%3A39%3A55Z&sp=r',\n",
              "  'azureml-logs/70_driver_log_0.txt': 'https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616469757_10343fff/azureml-logs/70_driver_log_0.txt?sv=2019-02-02&sr=b&sig=8cJJlDAd5wPtGePTRF3tLCvc7lS6pcMNdEwxHoD1jXw%3D&st=2021-03-23T04%3A29%3A55Z&se=2021-03-23T12%3A39%3A55Z&sp=r',\n",
              "  'azureml-logs/70_driver_log_1.txt': 'https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616469757_10343fff/azureml-logs/70_driver_log_1.txt?sv=2019-02-02&sr=b&sig=nBo6wmOeFoBTGWig3LbP9VFprvhe8KHhu4sYQvrVw6w%3D&st=2021-03-23T04%3A29%3A55Z&se=2021-03-23T12%3A39%3A55Z&sp=r',\n",
              "  'azureml-logs/75_job_post-tvmps_4f13e3e147a6a49a8fc39a6306f5d937293ceb882e0caaf97da18838e9af81b1_d.txt': 'https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616469757_10343fff/azureml-logs/75_job_post-tvmps_4f13e3e147a6a49a8fc39a6306f5d937293ceb882e0caaf97da18838e9af81b1_d.txt?sv=2019-02-02&sr=b&sig=KlCClzhO2OczWtqHH3aGK3qe4gKtVQW%2Flr6KzoVyfgk%3D&st=2021-03-23T04%3A29%3A55Z&se=2021-03-23T12%3A39%3A55Z&sp=r',\n",
              "  'azureml-logs/75_job_post-tvmps_b9f912d8d6d3d93bc36ffdeb087aae97569c4c6a2acd31376ef2b5fecf92fc95_d.txt': 'https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616469757_10343fff/azureml-logs/75_job_post-tvmps_b9f912d8d6d3d93bc36ffdeb087aae97569c4c6a2acd31376ef2b5fecf92fc95_d.txt?sv=2019-02-02&sr=b&sig=XtgYpOBhwsXEtN63Gqa54AECq2iQ0QWgtMVw68bpo7c%3D&st=2021-03-23T04%3A29%3A55Z&se=2021-03-23T12%3A39%3A55Z&sp=r',\n",
              "  'azureml-logs/process_info.json': 'https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616469757_10343fff/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=87ezdLE1ZM9gtszGFHNLBNcNHI2odEOQirhvW2HE6Gc%3D&st=2021-03-23T04%3A29%3A55Z&se=2021-03-23T12%3A39%3A55Z&sp=r',\n",
              "  'azureml-logs/process_status.json': 'https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616469757_10343fff/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=4u0B%2BSdEtTo9qYXXNEGz8UQbeRTaNz66UR8mQ7aGjA8%3D&st=2021-03-23T04%3A29%3A55Z&se=2021-03-23T12%3A39%3A55Z&sp=r',\n",
              "  'logs/azureml/0_109_azureml.log': 'https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616469757_10343fff/logs/azureml/0_109_azureml.log?sv=2019-02-02&sr=b&sig=tIm0RnorFCKMcARFjT%2FGN7Lgkr10udWm3VTlqmgVkII%3D&st=2021-03-23T04%3A29%3A55Z&se=2021-03-23T12%3A39%3A55Z&sp=r',\n",
              "  'logs/azureml/1_88_azureml.log': 'https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616469757_10343fff/logs/azureml/1_88_azureml.log?sv=2019-02-02&sr=b&sig=v0eNOisIOBFh9WYu0lIXMaNbWP0%2FtKPCqiauEk3PtSA%3D&st=2021-03-23T04%3A29%3A55Z&se=2021-03-23T12%3A39%3A55Z&sp=r',\n",
              "  'logs/azureml/dataprep/backgroundProcess.log': 'https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616469757_10343fff/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=EAHhIPRkAAH7BF4UDjJ4bzBxVZYIqBtmue1N8GEbjzg%3D&st=2021-03-23T04%3A29%3A55Z&se=2021-03-23T12%3A39%3A55Z&sp=r',\n",
              "  'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616469757_10343fff/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=%2BYi0A8%2FEX6AySrNh%2FKj5wplJzhGpYTXcaAXso17cGFk%3D&st=2021-03-23T04%3A29%3A55Z&se=2021-03-23T12%3A39%3A55Z&sp=r',\n",
              "  'logs/azureml/job_prep_azureml.log': 'https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616469757_10343fff/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=GmxjbusCOk5gIQAspdawh2RTTiZfJzt91Js8SmNofJA%3D&st=2021-03-23T04%3A29%3A55Z&se=2021-03-23T12%3A39%3A55Z&sp=r',\n",
              "  'logs/azureml/job_release_azureml.log': 'https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616469757_10343fff/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=%2FMvY5IiaG%2F9axgq5aX42tO1duz28OnP2B0JYYbMZN0s%3D&st=2021-03-23T04%3A29%3A55Z&se=2021-03-23T12%3A39%3A55Z&sp=r',\n",
              "  'logs/azureml/sidecar/tvmps_4f13e3e147a6a49a8fc39a6306f5d937293ceb882e0caaf97da18838e9af81b1_d/all.log': 'https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616469757_10343fff/logs/azureml/sidecar/tvmps_4f13e3e147a6a49a8fc39a6306f5d937293ceb882e0caaf97da18838e9af81b1_d/all.log?sv=2019-02-02&sr=b&sig=%2FmCiu7iDYHuhikHmkZh%2BPT70dIcbdQ26YPZ6mqgOvLA%3D&st=2021-03-23T04%3A29%3A55Z&se=2021-03-23T12%3A39%3A55Z&sp=r',\n",
              "  'logs/azureml/sidecar/tvmps_4f13e3e147a6a49a8fc39a6306f5d937293ceb882e0caaf97da18838e9af81b1_d/task.enter_contexts.log': 'https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616469757_10343fff/logs/azureml/sidecar/tvmps_4f13e3e147a6a49a8fc39a6306f5d937293ceb882e0caaf97da18838e9af81b1_d/task.enter_contexts.log?sv=2019-02-02&sr=b&sig=Tf%2B4H5GxM6kIo0nmE9Uw24N3qF%2Bx4XWgo5KiJEN6OIU%3D&st=2021-03-23T04%3A29%3A55Z&se=2021-03-23T12%3A39%3A55Z&sp=r',\n",
              "  'logs/azureml/sidecar/tvmps_4f13e3e147a6a49a8fc39a6306f5d937293ceb882e0caaf97da18838e9af81b1_d/task.exit_contexts.log': 'https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616469757_10343fff/logs/azureml/sidecar/tvmps_4f13e3e147a6a49a8fc39a6306f5d937293ceb882e0caaf97da18838e9af81b1_d/task.exit_contexts.log?sv=2019-02-02&sr=b&sig=0Jr%2FwAnOPy2fWGZmkf%2BqA0krDRCzOKltmXITk%2Bbrhok%3D&st=2021-03-23T04%3A29%3A55Z&se=2021-03-23T12%3A39%3A55Z&sp=r',\n",
              "  'logs/azureml/sidecar/tvmps_b9f912d8d6d3d93bc36ffdeb087aae97569c4c6a2acd31376ef2b5fecf92fc95_d/all.log': 'https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616469757_10343fff/logs/azureml/sidecar/tvmps_b9f912d8d6d3d93bc36ffdeb087aae97569c4c6a2acd31376ef2b5fecf92fc95_d/all.log?sv=2019-02-02&sr=b&sig=JDJlz2lrKtyH38brzOIDi33UFZwByyQ8T8PGp5ccRSg%3D&st=2021-03-23T04%3A29%3A55Z&se=2021-03-23T12%3A39%3A55Z&sp=r',\n",
              "  'logs/azureml/sidecar/tvmps_b9f912d8d6d3d93bc36ffdeb087aae97569c4c6a2acd31376ef2b5fecf92fc95_d/task.enter_contexts.log': 'https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616469757_10343fff/logs/azureml/sidecar/tvmps_b9f912d8d6d3d93bc36ffdeb087aae97569c4c6a2acd31376ef2b5fecf92fc95_d/task.enter_contexts.log?sv=2019-02-02&sr=b&sig=tdLDK%2Feca7iF3xyWzwOh7da8SaFo5LrFcOYNq1u%2F06U%3D&st=2021-03-23T04%3A29%3A55Z&se=2021-03-23T12%3A39%3A55Z&sp=r',\n",
              "  'logs/azureml/sidecar/tvmps_b9f912d8d6d3d93bc36ffdeb087aae97569c4c6a2acd31376ef2b5fecf92fc95_d/task.exit_contexts.log': 'https://mllab6442967193.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-distr_1616469757_10343fff/logs/azureml/sidecar/tvmps_b9f912d8d6d3d93bc36ffdeb087aae97569c4c6a2acd31376ef2b5fecf92fc95_d/task.exit_contexts.log?sv=2019-02-02&sr=b&sig=VImPuvS6QlEgPeyD3cPCG9asDlfzZ1WTSYP4ofWUcyo%3D&st=2021-03-23T04%3A29%3A55Z&se=2021-03-23T12%3A39%3A55Z&sp=r'},\n",
              " 'submittedBy': 'Shohei Nagata'}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "run.wait_for_completion(show_output=True) # this provides a verbose log"
      ]
    },
    {
      "source": [
        "## モデルの登録\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "azureml-logs/55_azureml-execution-tvmps_4f13e3e147a6a49a8fc39a6306f5d937293ceb882e0caaf97da18838e9af81b1_d.txt\nazureml-logs/55_azureml-execution-tvmps_b9f912d8d6d3d93bc36ffdeb087aae97569c4c6a2acd31376ef2b5fecf92fc95_d.txt\nazureml-logs/65_job_prep-tvmps_4f13e3e147a6a49a8fc39a6306f5d937293ceb882e0caaf97da18838e9af81b1_d.txt\nazureml-logs/65_job_prep-tvmps_b9f912d8d6d3d93bc36ffdeb087aae97569c4c6a2acd31376ef2b5fecf92fc95_d.txt\nazureml-logs/70_driver_log_0.txt\nazureml-logs/70_driver_log_1.txt\nazureml-logs/75_job_post-tvmps_4f13e3e147a6a49a8fc39a6306f5d937293ceb882e0caaf97da18838e9af81b1_d.txt\nazureml-logs/75_job_post-tvmps_b9f912d8d6d3d93bc36ffdeb087aae97569c4c6a2acd31376ef2b5fecf92fc95_d.txt\nazureml-logs/process_info.json\nazureml-logs/process_status.json\nlogs/azureml/0_109_azureml.log\nlogs/azureml/1_88_azureml.log\nlogs/azureml/dataprep/backgroundProcess.log\nlogs/azureml/dataprep/backgroundProcess_Telemetry.log\nlogs/azureml/job_prep_azureml.log\nlogs/azureml/job_release_azureml.log\nlogs/azureml/sidecar/tvmps_4f13e3e147a6a49a8fc39a6306f5d937293ceb882e0caaf97da18838e9af81b1_d/all.log\nlogs/azureml/sidecar/tvmps_4f13e3e147a6a49a8fc39a6306f5d937293ceb882e0caaf97da18838e9af81b1_d/task.enter_contexts.log\nlogs/azureml/sidecar/tvmps_4f13e3e147a6a49a8fc39a6306f5d937293ceb882e0caaf97da18838e9af81b1_d/task.exit_contexts.log\nlogs/azureml/sidecar/tvmps_b9f912d8d6d3d93bc36ffdeb087aae97569c4c6a2acd31376ef2b5fecf92fc95_d/all.log\nlogs/azureml/sidecar/tvmps_b9f912d8d6d3d93bc36ffdeb087aae97569c4c6a2acd31376ef2b5fecf92fc95_d/task.enter_contexts.log\nlogs/azureml/sidecar/tvmps_b9f912d8d6d3d93bc36ffdeb087aae97569c4c6a2acd31376ef2b5fecf92fc95_d/task.exit_contexts.log\noutputs/cifar_net.pt\n"
          ]
        }
      ],
      "source": [
        "#実行に関係しているファイル一覧の表示\n",
        "for i in run.get_file_names():\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pytorch-distr\tpytorch-distr:1\t1\n"
          ]
        }
      ],
      "source": [
        "model = run.register_model(model_name = 'pytorch-distr', model_path = 'outputs/cifar_net.pt')\n",
        "print(model.name, model.id, model.version, sep = '\\t')"
      ]
    },
    {
      "source": [
        "## モデルデプロイ\n",
        "Webサービスとしてモデルをデプロイします。"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "### スコアリングスクリプトの作成\n",
        "Web サービスの呼び出しに使用される score.py というスコアリング スクリプトを作成してモデルの使用方法を示します。\n",
        "スコアリング スクリプトには、2 つの必要な関数を含める必要があります。\n",
        "- `init()` 関数。通常、グローバル オブジェクトにモデルを読み込みます。 この関数は、Docker コンテナーを開始するときに 1 回だけ実行されます。\n",
        "- `run(input_data)` 関数。モデルを使用して、入力データに基づく値を予測します。 実行に対する入力と出力は、通常、JSON を使用してシリアル化およびシリアル化解除が実行されますが、その他の形式もサポートされています。"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing score.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile score.py\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "import json\n",
        "\n",
        "from azureml.core.model import Model\n",
        "\n",
        "\n",
        "def init():\n",
        "    global model\n",
        "    # AZUREML_MODEL_DIR is an environment variable created during deployment.\n",
        "    # It is the path to the model folder (./azureml-models/$MODEL_NAME/$VERSION)\n",
        "    # For multiple models, it points to the folder containing all deployed models (./azureml-models)\n",
        "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'cifar_net.pt')\n",
        "    model = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
        "    model.eval()\n",
        "\n",
        "\n",
        "def run(input_data):\n",
        "    input_data = torch.tensor(json.loads(input_data)['data'])\n",
        "\n",
        "    # get prediction\n",
        "    with torch.no_grad():\n",
        "        output = model(input_data)\n",
        "        classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "        softmax = nn.Softmax(dim=1)\n",
        "        pred_probs = softmax(output).numpy()[0]\n",
        "        index = torch.argmax(output, 1)\n",
        "\n",
        "    result = {\"label\": classes[index], \"probability\": str(pred_probs[index])}\n",
        "    return result"
      ]
    },
    {
      "source": [
        "### ACIコンテナへのデプロイ\n",
        "デプロイの構成ファイルを作成し、ACI コンテナーに必要な CPU 数と RAM ギガバイト数を指定します。 実際のモデルにもよりますが、通常、多くのモデルには既定値の 1 コアと 1 ギガバイトの RAM で十分です。 後でもっと必要になった場合は、イメージを再作成し、サービスをデプロイし直す必要があります。\n",
        "※今回はデプロイ先の実行環境にはトレーニング時と同一の環境 (pytorch_env)を使用"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
            "Running\n",
            "2021-03-23 17:15:59+09:00 Creating Container Registry if not exists.\n",
            "2021-03-23 17:16:00+09:00 Registering the environment.\n",
            "2021-03-23 17:16:00+09:00 Use the existing image.\n",
            "2021-03-23 17:16:00+09:00 Generating deployment configuration.\n",
            "2021-03-23 17:16:01+09:00 Submitting deployment to compute.\n",
            "2021-03-23 17:16:05+09:00 Checking the status of deployment aci-cifar10..\n",
            "2021-03-23 17:22:24+09:00 Checking the status of inference endpoint aci-cifar10.\n",
            "Failed\n",
            "Service deployment polling reached non-successful terminal state, current service state: Failed\n",
            "Operation ID: b134b8d6-a721-4870-8af1-f31c8f0cbc60\n",
            "More information can be found using '.get_logs()'\n",
            "Error:\n",
            "{\n",
            "  \"code\": \"AciDeploymentFailed\",\n",
            "  \"statusCode\": 400,\n",
            "  \"message\": \"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\n",
            "\t1. Please check the logs for your container instance: aci-cifar10. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n",
            "\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n",
            "\t3. You can also try to run image viennaglobal.azurecr.io/azureml/azureml_31eff05d9938cbbdf21dfb15bccdb84f locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\",\n",
            "  \"details\": [\n",
            "    {\n",
            "      \"code\": \"CrashLoopBackOff\",\n",
            "      \"message\": \"Your container application crashed. This may be caused by errors in your scoring file's init() function.\n",
            "\t1. Please check the logs for your container instance: aci-cifar10. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n",
            "\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n",
            "\t3. You can also try to run image viennaglobal.azurecr.io/azureml/azureml_31eff05d9938cbbdf21dfb15bccdb84f locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\"\n",
            "    },\n",
            "    {\n",
            "      \"code\": \"AciDeploymentFailed\",\n",
            "      \"message\": \"Your container application crashed. Please follow the steps to debug:\n",
            "\t1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\n",
            "\t2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https://aka.ms/debugimage#debug-locally for more information.\n",
            "\t3. You can also interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n",
            "\t4. View the diagnostic events to check status of container, it may help you to debug the issue.\n",
            "\"RestartCount\": 3\n",
            "\"CurrentState\": {\"state\":\"Waiting\",\"startTime\":null,\"exitCode\":null,\"finishTime\":null,\"detailStatus\":\"CrashLoopBackOff: Back-off restarting failed\"}\n",
            "\"PreviousState\": {\"state\":\"Terminated\",\"startTime\":\"2021-03-23T08:24:04.512Z\",\"exitCode\":111,\"finishTime\":\"2021-03-23T08:24:12.704Z\",\"detailStatus\":\"Error\"}\n",
            "\"Events\":\n",
            "{\"count\":2,\"firstTimestamp\":\"2021-03-23T08:16:25Z\",\"lastTimestamp\":\"2021-03-23T08:21:55Z\",\"name\":\"Pulling\",\"message\":\"pulling image \"viennaglobal.azurecr.io/azureml/azureml_31eff05d9938cbbdf21dfb15bccdb84f@sha256:76a13c9d20bae83e7b2400ac3cd3bcd609e46e0f98433146017bde5edeeeff68\"\",\"type\":\"Normal\"}\n",
            "{\"count\":2,\"firstTimestamp\":\"2021-03-23T08:21:45Z\",\"lastTimestamp\":\"2021-03-23T08:21:58Z\",\"name\":\"Pulled\",\"message\":\"Successfully pulled image \"viennaglobal.azurecr.io/azureml/azureml_31eff05d9938cbbdf21dfb15bccdb84f@sha256:76a13c9d20bae83e7b2400ac3cd3bcd609e46e0f98433146017bde5edeeeff68\"\",\"type\":\"Normal\"}\n",
            "{\"count\":4,\"firstTimestamp\":\"2021-03-23T08:22:19Z\",\"lastTimestamp\":\"2021-03-23T08:24:04Z\",\"name\":\"Started\",\"message\":\"Started container\",\"type\":\"Normal\"}\n",
            "{\"count\":4,\"firstTimestamp\":\"2021-03-23T08:22:36Z\",\"lastTimestamp\":\"2021-03-23T08:24:12Z\",\"name\":\"Killing\",\"message\":\"Killing container with id c31b3873204f265690d555c8c5e00693e88121455c362e359015a0430b68609b.\",\"type\":\"Normal\"}\n",
            "\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "WebserviceException",
          "evalue": "WebserviceException:\n\tMessage: Service deployment polling reached non-successful terminal state, current service state: Failed\nOperation ID: b134b8d6-a721-4870-8af1-f31c8f0cbc60\nMore information can be found using '.get_logs()'\nError:\n{\n  \"code\": \"AciDeploymentFailed\",\n  \"statusCode\": 400,\n  \"message\": \"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\n\t1. Please check the logs for your container instance: aci-cifar10. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n\t3. You can also try to run image viennaglobal.azurecr.io/azureml/azureml_31eff05d9938cbbdf21dfb15bccdb84f locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\",\n  \"details\": [\n    {\n      \"code\": \"CrashLoopBackOff\",\n      \"message\": \"Your container application crashed. This may be caused by errors in your scoring file's init() function.\n\t1. Please check the logs for your container instance: aci-cifar10. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n\t3. You can also try to run image viennaglobal.azurecr.io/azureml/azureml_31eff05d9938cbbdf21dfb15bccdb84f locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\"\n    },\n    {\n      \"code\": \"AciDeploymentFailed\",\n      \"message\": \"Your container application crashed. Please follow the steps to debug:\n\t1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\n\t2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https://aka.ms/debugimage#debug-locally for more information.\n\t3. You can also interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n\t4. View the diagnostic events to check status of container, it may help you to debug the issue.\n\"RestartCount\": 3\n\"CurrentState\": {\"state\":\"Waiting\",\"startTime\":null,\"exitCode\":null,\"finishTime\":null,\"detailStatus\":\"CrashLoopBackOff: Back-off restarting failed\"}\n\"PreviousState\": {\"state\":\"Terminated\",\"startTime\":\"2021-03-23T08:24:04.512Z\",\"exitCode\":111,\"finishTime\":\"2021-03-23T08:24:12.704Z\",\"detailStatus\":\"Error\"}\n\"Events\":\n{\"count\":2,\"firstTimestamp\":\"2021-03-23T08:16:25Z\",\"lastTimestamp\":\"2021-03-23T08:21:55Z\",\"name\":\"Pulling\",\"message\":\"pulling image \"viennaglobal.azurecr.io/azureml/azureml_31eff05d9938cbbdf21dfb15bccdb84f@sha256:76a13c9d20bae83e7b2400ac3cd3bcd609e46e0f98433146017bde5edeeeff68\"\",\"type\":\"Normal\"}\n{\"count\":2,\"firstTimestamp\":\"2021-03-23T08:21:45Z\",\"lastTimestamp\":\"2021-03-23T08:21:58Z\",\"name\":\"Pulled\",\"message\":\"Successfully pulled image \"viennaglobal.azurecr.io/azureml/azureml_31eff05d9938cbbdf21dfb15bccdb84f@sha256:76a13c9d20bae83e7b2400ac3cd3bcd609e46e0f98433146017bde5edeeeff68\"\",\"type\":\"Normal\"}\n{\"count\":4,\"firstTimestamp\":\"2021-03-23T08:22:19Z\",\"lastTimestamp\":\"2021-03-23T08:24:04Z\",\"name\":\"Started\",\"message\":\"Started container\",\"type\":\"Normal\"}\n{\"count\":4,\"firstTimestamp\":\"2021-03-23T08:22:36Z\",\"lastTimestamp\":\"2021-03-23T08:24:12Z\",\"name\":\"Killing\",\"message\":\"Killing container with id c31b3873204f265690d555c8c5e00693e88121455c362e359015a0430b68609b.\",\"type\":\"Normal\"}\n\"\n    }\n  ]\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Service deployment polling reached non-successful terminal state, current service state: Failed\\nOperation ID: b134b8d6-a721-4870-8af1-f31c8f0cbc60\\nMore information can be found using '.get_logs()'\\nError:\\n{\\n  \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n  \\\"statusCode\\\": 400,\\n  \\\"message\\\": \\\"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\\n\\t1. Please check the logs for your container instance: aci-cifar10. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\\n\\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t3. You can also try to run image viennaglobal.azurecr.io/azureml/azureml_31eff05d9938cbbdf21dfb15bccdb84f locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\\\",\\n  \\\"details\\\": [\\n    {\\n      \\\"code\\\": \\\"CrashLoopBackOff\\\",\\n      \\\"message\\\": \\\"Your container application crashed. This may be caused by errors in your scoring file's init() function.\\n\\t1. Please check the logs for your container instance: aci-cifar10. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\\n\\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t3. You can also try to run image viennaglobal.azurecr.io/azureml/azureml_31eff05d9938cbbdf21dfb15bccdb84f locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\\\"\\n    },\\n    {\\n      \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n      \\\"message\\\": \\\"Your container application crashed. Please follow the steps to debug:\\n\\t1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\\n\\t2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https://aka.ms/debugimage#debug-locally for more information.\\n\\t3. You can also interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t4. View the diagnostic events to check status of container, it may help you to debug the issue.\\n\\\"RestartCount\\\": 3\\n\\\"CurrentState\\\": {\\\"state\\\":\\\"Waiting\\\",\\\"startTime\\\":null,\\\"exitCode\\\":null,\\\"finishTime\\\":null,\\\"detailStatus\\\":\\\"CrashLoopBackOff: Back-off restarting failed\\\"}\\n\\\"PreviousState\\\": {\\\"state\\\":\\\"Terminated\\\",\\\"startTime\\\":\\\"2021-03-23T08:24:04.512Z\\\",\\\"exitCode\\\":111,\\\"finishTime\\\":\\\"2021-03-23T08:24:12.704Z\\\",\\\"detailStatus\\\":\\\"Error\\\"}\\n\\\"Events\\\":\\n{\\\"count\\\":2,\\\"firstTimestamp\\\":\\\"2021-03-23T08:16:25Z\\\",\\\"lastTimestamp\\\":\\\"2021-03-23T08:21:55Z\\\",\\\"name\\\":\\\"Pulling\\\",\\\"message\\\":\\\"pulling image \\\"viennaglobal.azurecr.io/azureml/azureml_31eff05d9938cbbdf21dfb15bccdb84f@sha256:76a13c9d20bae83e7b2400ac3cd3bcd609e46e0f98433146017bde5edeeeff68\\\"\\\",\\\"type\\\":\\\"Normal\\\"}\\n{\\\"count\\\":2,\\\"firstTimestamp\\\":\\\"2021-03-23T08:21:45Z\\\",\\\"lastTimestamp\\\":\\\"2021-03-23T08:21:58Z\\\",\\\"name\\\":\\\"Pulled\\\",\\\"message\\\":\\\"Successfully pulled image \\\"viennaglobal.azurecr.io/azureml/azureml_31eff05d9938cbbdf21dfb15bccdb84f@sha256:76a13c9d20bae83e7b2400ac3cd3bcd609e46e0f98433146017bde5edeeeff68\\\"\\\",\\\"type\\\":\\\"Normal\\\"}\\n{\\\"count\\\":4,\\\"firstTimestamp\\\":\\\"2021-03-23T08:22:19Z\\\",\\\"lastTimestamp\\\":\\\"2021-03-23T08:24:04Z\\\",\\\"name\\\":\\\"Started\\\",\\\"message\\\":\\\"Started container\\\",\\\"type\\\":\\\"Normal\\\"}\\n{\\\"count\\\":4,\\\"firstTimestamp\\\":\\\"2021-03-23T08:22:36Z\\\",\\\"lastTimestamp\\\":\\\"2021-03-23T08:24:12Z\\\",\\\"name\\\":\\\"Killing\\\",\\\"message\\\":\\\"Killing container with id c31b3873204f265690d555c8c5e00693e88121455c362e359015a0430b68609b.\\\",\\\"type\\\":\\\"Normal\\\"}\\n\\\"\\n    }\\n  ]\\n}\"\n    }\n}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m~/.anyenv/envs/pyenv/versions/anaconda3-2020.11/envs/pytorch_env/lib/python3.6/site-packages/azureml/core/webservice/webservice.py\u001b[0m in \u001b[0;36mwait_for_deployment\u001b[0;34m(self, show_output, timeout_sec)\u001b[0m\n\u001b[1;32m    921\u001b[0m                                           \u001b[0;34m'Error:\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m                                           '{}'.format(self.state, self._operation_endpoint.split('/')[-1],\n\u001b[0;32m--> 923\u001b[0;31m                                                       logs_response, format_error_response), logger=module_logger)\n\u001b[0m\u001b[1;32m    924\u001b[0m             print('{} service creation operation finished, operation \"{}\"'.format(self._webservice_type,\n\u001b[1;32m    925\u001b[0m                                                                                   operation_state))\n",
            "\u001b[0;31mWebserviceException\u001b[0m: WebserviceException:\n\tMessage: Service deployment polling reached non-successful terminal state, current service state: Failed\nOperation ID: b134b8d6-a721-4870-8af1-f31c8f0cbc60\nMore information can be found using '.get_logs()'\nError:\n{\n  \"code\": \"AciDeploymentFailed\",\n  \"statusCode\": 400,\n  \"message\": \"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\n\t1. Please check the logs for your container instance: aci-cifar10. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n\t3. You can also try to run image viennaglobal.azurecr.io/azureml/azureml_31eff05d9938cbbdf21dfb15bccdb84f locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\",\n  \"details\": [\n    {\n      \"code\": \"CrashLoopBackOff\",\n      \"message\": \"Your container application crashed. This may be caused by errors in your scoring file's init() function.\n\t1. Please check the logs for your container instance: aci-cifar10. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n\t3. You can also try to run image viennaglobal.azurecr.io/azureml/azureml_31eff05d9938cbbdf21dfb15bccdb84f locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\"\n    },\n    {\n      \"code\": \"AciDeploymentFailed\",\n      \"message\": \"Your container application crashed. Please follow the steps to debug:\n\t1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\n\t2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https://aka.ms/debugimage#debug-locally for more information.\n\t3. You can also interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n\t4. View the diagnostic events to check status of container, it may help you to debug the issue.\n\"RestartCount\": 3\n\"CurrentState\": {\"state\":\"Waiting\",\"startTime\":null,\"exitCode\":null,\"finishTime\":null,\"detailStatus\":\"CrashLoopBackOff: Back-off restarting failed\"}\n\"PreviousState\": {\"state\":\"Terminated\",\"startTime\":\"2021-03-23T08:24:04.512Z\",\"exitCode\":111,\"finishTime\":\"2021-03-23T08:24:12.704Z\",\"detailStatus\":\"Error\"}\n\"Events\":\n{\"count\":2,\"firstTimestamp\":\"2021-03-23T08:16:25Z\",\"lastTimestamp\":\"2021-03-23T08:21:55Z\",\"name\":\"Pulling\",\"message\":\"pulling image \"viennaglobal.azurecr.io/azureml/azureml_31eff05d9938cbbdf21dfb15bccdb84f@sha256:76a13c9d20bae83e7b2400ac3cd3bcd609e46e0f98433146017bde5edeeeff68\"\",\"type\":\"Normal\"}\n{\"count\":2,\"firstTimestamp\":\"2021-03-23T08:21:45Z\",\"lastTimestamp\":\"2021-03-23T08:21:58Z\",\"name\":\"Pulled\",\"message\":\"Successfully pulled image \"viennaglobal.azurecr.io/azureml/azureml_31eff05d9938cbbdf21dfb15bccdb84f@sha256:76a13c9d20bae83e7b2400ac3cd3bcd609e46e0f98433146017bde5edeeeff68\"\",\"type\":\"Normal\"}\n{\"count\":4,\"firstTimestamp\":\"2021-03-23T08:22:19Z\",\"lastTimestamp\":\"2021-03-23T08:24:04Z\",\"name\":\"Started\",\"message\":\"Started container\",\"type\":\"Normal\"}\n{\"count\":4,\"firstTimestamp\":\"2021-03-23T08:22:36Z\",\"lastTimestamp\":\"2021-03-23T08:24:12Z\",\"name\":\"Killing\",\"message\":\"Killing container with id c31b3873204f265690d555c8c5e00693e88121455c362e359015a0430b68609b.\",\"type\":\"Normal\"}\n\"\n    }\n  ]\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Service deployment polling reached non-successful terminal state, current service state: Failed\\nOperation ID: b134b8d6-a721-4870-8af1-f31c8f0cbc60\\nMore information can be found using '.get_logs()'\\nError:\\n{\\n  \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n  \\\"statusCode\\\": 400,\\n  \\\"message\\\": \\\"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\\n\\t1. Please check the logs for your container instance: aci-cifar10. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\\n\\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t3. You can also try to run image viennaglobal.azurecr.io/azureml/azureml_31eff05d9938cbbdf21dfb15bccdb84f locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\\\",\\n  \\\"details\\\": [\\n    {\\n      \\\"code\\\": \\\"CrashLoopBackOff\\\",\\n      \\\"message\\\": \\\"Your container application crashed. This may be caused by errors in your scoring file's init() function.\\n\\t1. Please check the logs for your container instance: aci-cifar10. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\\n\\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t3. You can also try to run image viennaglobal.azurecr.io/azureml/azureml_31eff05d9938cbbdf21dfb15bccdb84f locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\\\"\\n    },\\n    {\\n      \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n      \\\"message\\\": \\\"Your container application crashed. Please follow the steps to debug:\\n\\t1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\\n\\t2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https://aka.ms/debugimage#debug-locally for more information.\\n\\t3. You can also interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t4. View the diagnostic events to check status of container, it may help you to debug the issue.\\n\\\"RestartCount\\\": 3\\n\\\"CurrentState\\\": {\\\"state\\\":\\\"Waiting\\\",\\\"startTime\\\":null,\\\"exitCode\\\":null,\\\"finishTime\\\":null,\\\"detailStatus\\\":\\\"CrashLoopBackOff: Back-off restarting failed\\\"}\\n\\\"PreviousState\\\": {\\\"state\\\":\\\"Terminated\\\",\\\"startTime\\\":\\\"2021-03-23T08:24:04.512Z\\\",\\\"exitCode\\\":111,\\\"finishTime\\\":\\\"2021-03-23T08:24:12.704Z\\\",\\\"detailStatus\\\":\\\"Error\\\"}\\n\\\"Events\\\":\\n{\\\"count\\\":2,\\\"firstTimestamp\\\":\\\"2021-03-23T08:16:25Z\\\",\\\"lastTimestamp\\\":\\\"2021-03-23T08:21:55Z\\\",\\\"name\\\":\\\"Pulling\\\",\\\"message\\\":\\\"pulling image \\\"viennaglobal.azurecr.io/azureml/azureml_31eff05d9938cbbdf21dfb15bccdb84f@sha256:76a13c9d20bae83e7b2400ac3cd3bcd609e46e0f98433146017bde5edeeeff68\\\"\\\",\\\"type\\\":\\\"Normal\\\"}\\n{\\\"count\\\":2,\\\"firstTimestamp\\\":\\\"2021-03-23T08:21:45Z\\\",\\\"lastTimestamp\\\":\\\"2021-03-23T08:21:58Z\\\",\\\"name\\\":\\\"Pulled\\\",\\\"message\\\":\\\"Successfully pulled image \\\"viennaglobal.azurecr.io/azureml/azureml_31eff05d9938cbbdf21dfb15bccdb84f@sha256:76a13c9d20bae83e7b2400ac3cd3bcd609e46e0f98433146017bde5edeeeff68\\\"\\\",\\\"type\\\":\\\"Normal\\\"}\\n{\\\"count\\\":4,\\\"firstTimestamp\\\":\\\"2021-03-23T08:22:19Z\\\",\\\"lastTimestamp\\\":\\\"2021-03-23T08:24:04Z\\\",\\\"name\\\":\\\"Started\\\",\\\"message\\\":\\\"Started container\\\",\\\"type\\\":\\\"Normal\\\"}\\n{\\\"count\\\":4,\\\"firstTimestamp\\\":\\\"2021-03-23T08:22:36Z\\\",\\\"lastTimestamp\\\":\\\"2021-03-23T08:24:12Z\\\",\\\"name\\\":\\\"Killing\\\",\\\"message\\\":\\\"Killing container with id c31b3873204f265690d555c8c5e00693e88121455c362e359015a0430b68609b.\\\",\\\"type\\\":\\\"Normal\\\"}\\n\\\"\\n    }\\n  ]\\n}\"\n    }\n}"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "from azureml.core.webservice import AciWebservice\n",
        "from azureml.core.model import InferenceConfig\n",
        "from azureml.core.webservice import Webservice\n",
        "from azureml.core.model import Model\n",
        "\n",
        "inference_config = InferenceConfig(entry_script=\"score.py\", environment=pytorch_env)\n",
        "\n",
        "#デプロイの構成設定\n",
        "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n",
        "                                               memory_gb=1, \n",
        "                                               tags={'data': 'cifar-10',  'model':'pytorch-distr', 'framework':'pytorch'},\n",
        "                                               description='Classify daily objects from the cifar-10 dataset using PyTorch')\n",
        "\n",
        "model = Model(ws, 'pytorch-distr')\n",
        "\n",
        "service = Model.deploy(workspace=ws, \n",
        "                           name='aci-cifar10', \n",
        "                           models=[model], \n",
        "                           inference_config=inference_config, \n",
        "                           deployment_config=aciconfig)\n",
        "\n",
        "service.wait_for_deployment(show_output=True)\n",
        "print(service.state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "# デプロイ中に問題が発生した場合にログ取得\n",
        "service.get_logs()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 再デプロイ前に既存のACIサービスを削除\n",
        "service.delete()\n"
      ]
    },
    {
      "source": [
        "## モデルのテスト\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    }
  ],
  "metadata": {
    "authors": [
      {
        "name": "minxia"
      }
    ],
    "category": "training",
    "compute": [
      "AML Compute"
    ],
    "datasets": [
      "CIFAR-10"
    ],
    "deployment": [
      "None"
    ],
    "exclude_from_index": false,
    "framework": [
      "PyTorch"
    ],
    "friendly_name": "Distributed training with PyTorch",
    "index_order": 1,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.6.13 64-bit ('pytorch_env': conda)",
      "metadata": {
        "interpreter": {
          "hash": "d96db7ae1bfe5e848ddbb3d9f09a0495f9c7dadf65d50dee51a93893ffed0ce4"
        }
      }
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "tags": [
      "None"
    ],
    "task": "Train a model using distributed training via PyTorch DistributedDataParallel"
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
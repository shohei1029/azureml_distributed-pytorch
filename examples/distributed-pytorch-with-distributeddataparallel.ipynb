{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Copyright (c) Microsoft Corporation. All rights reserved.\n",
        "Licensed under the MIT License.\n",
        "Modified by Shohei Nagata, 1st April 2021."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PyTorchの分散学習 (DistributedDataParallel版)\n",
        "本日のハンズオンでは[CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html)データセットを対象に、PyTorchの`DistributedDataParallel`モジュールを用いてGPUクラスター間で分散学習を行い、PyTorchモデルを学習します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 前提条件確認\n",
        "\n",
        "事前にAzure Machine Learning Python SDKをインストールし、Azure ML `Workspace`を作成してください。  \n",
        "※Azure Machine Learning Notebook VMを使用している場合は、すべての設定が完了しています。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Azure ML SDKのバージョン確認\n",
        "import azureml.core\n",
        "\n",
        "print(\"SDK version:\", azureml.core.VERSION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ワークスペースの設定\n",
        "Azure ML ワークスペースによってAzure MLで使用するアセット類 (データ、スクリプト、出力、等々)を管理していきます。\n",
        "![](https://docs.microsoft.com/ja-jp/azure/machine-learning/media/concept-azure-machine-learning-architecture/architecture.svg)\n",
        "\n",
        "前提条件のステップで作成した既存のワークスペースから、[Workspace](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#workspace)オブジェクトを初期化します。`Workspace.from_config()` は、`config.json` に格納された詳細情報から、ワークスペース・オブジェクトを作成します。   \n",
        "\n",
        "事前にAzure ML Studioから構成ファイル (config.json)をダウンロードし、本スクリプトと同一階層に置きます。  \n",
        "\n",
        "初回実行時は認証を行う必要があるため、実行結果部分の指示に従って https://microsoft.com/devicelogin にアクセスし、認証コードを入力します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core.workspace import Workspace\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "print('Workspace name: ' + ws.name, \n",
        "      'Azure region: ' + ws.location, \n",
        "      'Subscription id: ' + ws.subscription_id, \n",
        "      'Resource group: ' + ws.resource_group, sep='\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 計算環境の準備\n",
        "\n",
        "モデルをトレーニングするためには、[コンピューティング先](hhttps://docs.microsoft.com/ja-jp/azure/machine-learning/concept-azure-machine-learning-architecture#computes)を作成する必要があります。このノートブックでは、コンピューティング クラスターをリモートトレーニング用のコンピュートリソースとして使用します。  \n",
        "具体的には，以下のコードで，`STANDARD_NC6`のGPUクラスターを作成し，`0`から`4`のノードにオートスケールします。\n",
        "\n",
        "**コンピューティングクラスターの作成には約5分かかります。** 同一名称のものがワークスペースにある場合、下記コードは作成プロセスをスキップします。\n",
        "\n",
        "他のAzureサービスと同様に、Azure Machine Learningサービスに関連する特定のリソース（コンピューティング インスタンス、コンピューティング クラスターなど）には制限があります。  \n",
        "参考：[Azure Machine Learning を使用するリソースのクォータの管理と引き上げ](https://docs.microsoft.com/ja-jp/azure/machine-learning/how-to-manage-quotas)、\n",
        "[申請手順](https://docs.microsoft.com/ja-jp/azure/azure-portal/supportability/regional-quota-requests#request-a-quota-increase-by-region-from-help--support)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "# choose a name for your cluster\n",
        "cluster_name = 'gpu-cluster'\n",
        "\n",
        "try:\n",
        "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
        "    print('Found existing compute target.')\n",
        "except ComputeTargetException:\n",
        "    print('Creating a new compute target...')\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_NC6', # 使用するVMインスタンスを指定します.  (Standard_NC6s_v3)\n",
        "                                                           max_nodes=2)\n",
        "\n",
        "    # create the cluster\n",
        "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
        "\n",
        "    compute_target.wait_for_completion(show_output=True)\n",
        "\n",
        "# use get_status() to get a detailed status for the current AmlCompute. \n",
        "print(compute_target.get_status().serialize())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## データセットの準備\n",
        "\n",
        "学習に使用するデータセットを準備します。まず、cs.toronto.eduのサイトから公開されているCIFAR-10データセットをダウンロードして抽出し、Azure ML FileDatasetを作成して学習に使用します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### CIFAR-10 データのダウンロードと解凍"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import urllib\n",
        "import tarfile\n",
        "import os\n",
        "\n",
        "url = 'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'\n",
        "filename = 'cifar-10-python.tar.gz'\n",
        "data_root = 'cifar-10'\n",
        "filepath = os.path.join(data_root, filename)\n",
        "\n",
        "if not os.path.isdir(data_root):\n",
        "    os.makedirs(data_root, exist_ok=True)\n",
        "    urllib.request.urlretrieve(url, filepath)\n",
        "    with tarfile.open(filepath, \"r:gz\") as tar:\n",
        "        tar.extractall(path=data_root)\n",
        "    os.remove(filepath)  # delete tar.gz file after extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Azure MLデータセットの作成\n",
        "\n",
        "`upload_directory`メソッドは、データストアにデータをアップロードし、そこからFileDatasetを作成します。このチュートリアルでは、ワークスペースのデフォルトのデータストアを使用します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core import Dataset\n",
        "\n",
        "datastore = ws.get_default_datastore()\n",
        "dataset = Dataset.File.upload_directory(\n",
        "    src_dir=data_root, target=(datastore, data_root)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## リモートでのモデル学習 \n",
        "リモート (Azure ML上の)計算環境が準備できたので、分散学習ジョブを実行してみましょう。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### プロジェクトディレクトリの作成\n",
        "ローカルマシンからリモートリソースにアクセスするために必要なコードをすべて格納するディレクトリを作成します。このディレクトリには、トレーニングスクリプトと、トレーニングスクリプトが依存する追加ファイルが含まれます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "project_folder = './pytorch-distr'\n",
        "os.makedirs(project_folder, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### トレーニングスクリプトの準備\n",
        "ここでは、トレーニング用のスクリプトを作成します。このチュートリアルでは、CIFAR-10の分散学習用のスクリプトを`train.py`で用意しています。実際には、カスタムのPyTorchトレーニングスクリプトをそのまま使用して、コードを変更することなくAzure MLで実行することが可能です。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "トレーニングスクリプト `train.py`をプロジェクトディレクトリ内へコピーします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "shutil.copy('train.py', project_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 実験の作成\n",
        "[実験 (Experiment)](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#experiment)を作成して、この分散PyTorchチュートリアルのワークスペースでのすべての実行を追跡します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core import Experiment\n",
        "\n",
        "experiment_name = 'pytorch-distr'\n",
        "experiment = Experiment(ws, name=experiment_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 環境の作成\n",
        "\n",
        "Azure MLではいくつかの[キュレートされた実行環境](https://docs.microsoft.com/ja-jp/azure/machine-learning/how-to-use-environments#use-a-curated-environment)が用意されています。\n",
        "今回はPyTorch 1.6 GPU環境を使用します。こちらのキュレートされた環境には今回のトレーニングスクリプトで必要なtorch, torchvisionも含まれています。\n",
        "\n",
        "参考：[キュレーションされた環境一覧](https://docs.microsoft.com/ja-jp/azure/machine-learning/resource-curated-environments)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core import Environment\n",
        "\n",
        "pytorch_env = Environment.get(ws, name='AzureML-PyTorch-1.6-GPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 中身の確認\n",
        "print(pytorch_env.python.conda_dependencies.serialize_to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### トレーニングジョブの設定\n",
        "`ScriptRunConfig`を用いてスクリプトの実行構成を作成します。\n",
        "![](../img/scriptrunconfig.png)\n",
        "\n",
        "参考：[スクリプトの実行構成を作成する](https://docs.microsoft.com/ja-jp/azure/machine-learning/how-to-set-up-training-targets#create-the-script-run-configuration)\n",
        "\n",
        "#### 分散ジョブの構成を指定する\n",
        "分散トレーニング ジョブを実行する場合は、分散ジョブ固有の構成を `distributed_job_config` パラメーターに指定します。 \n",
        "\n",
        "\n",
        "Azure MLで分散PyTorchジョブを開始するには、次の2つの方法があります。\n",
        "\n",
        "1. プロセスごとの起動 - 実行するワーカープロセスの総数を指定します (通常、GPUごとに1つ)。\n",
        "Azure ML によって各プロセスの起動が処理されます。\n",
        "2. [torch.distributed.launch](https://pytorch.org/docs/stable/distributed.html#launch-utility) を使ったノード単位の起動 - 各ノードで実行したい「torch.distributed.launch」コマンドを指定します。Torch 起動ユーティリティによって、各ノードのワーカー プロセスの起動が処理されます。\n",
        "\n",
        "これらの起動オプションには、基本的な違いはありません。\n",
        "詳細は[ドキュメント](https://docs.microsoft.com/ja-jp/azure/machine-learning/how-to-train-pytorch#distributeddataparallel)を参照してください。\n",
        "\n",
        "両方のオプションを以下に示します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### プロセスごとの起動\n",
        "\n",
        "トレーニングスクリプトを実行するための各プロセスの起動をAzure MLが処理して分散 PyTorch ジョブを実行するには、次の操作を行います。\n",
        "\n",
        "1. トレーニング スクリプトと引数を指定します。\n",
        "2. `PyTorchConfiguration` を作成し、`process_count` と `node_count` を指定します。 `process_count` は、ジョブに対して実行するプロセスの合計数に対応しています。 これは通常、ノードあたりの GPU の数にノード数を掛けた値と同じにします。 `process_count` を指定しないと、Azure ML では、既定でノードごとに 1 つのプロセスが起動されます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core import ScriptRunConfig\n",
        "from azureml.core.runconfig import PyTorchConfiguration\n",
        "\n",
        "# create distributed config\n",
        "distr_config = PyTorchConfiguration(process_count=2, node_count=2)\n",
        "\n",
        "# create args\n",
        "args = [\"--data-dir\", dataset.as_download(), \"--epochs\", 25]\n",
        "\n",
        "# create job config\n",
        "src = ScriptRunConfig(source_directory=project_folder,\n",
        "                      script='train.py',\n",
        "                      arguments=args,\n",
        "                      compute_target=compute_target,\n",
        "                      environment=pytorch_env,\n",
        "                      distributed_job_config=distr_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### `torch.distributed.launch` によるノード毎の起動\n",
        "\n",
        "もし、PyTorchが提供する起動ユーティリティー `torch.distributed.launch` を使って、各ノードのワーカープロセスの起動を処理したい場合は、以下のようにしても構いません。\n",
        "\n",
        "1. ScriptRunConfigの`command`パラメータにlaunchコマンドを指定します。PyTorch のジョブの場合、Azure ML は各ノードに環境変数 `MASTER_ADDR`, `MASTER_PORT`, `NODE_RANK` を設定しますので、コマンドの中でこれらの環境変数を参照すればよいのです。GPU数が1以上のSKUを使用している場合は、`--nproc_per_node`の引数を適宜調整してください。\n",
        "\n",
        "2. `PyTorchConfiguration`を作成し、`node_count`を指定します。デフォルトでは、Azure MLはノードごとに1つのプロセスを起動して、指定した`コマンド`を実行しますので、`process_count`を指定する必要はありません。\n",
        "\n",
        "以下のコードをコメントアウト解除して、この方法でジョブを設定してください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "from azureml.core import ScriptRunConfig\n",
        "from azureml.core.runconfig import PyTorchConfiguration\n",
        "\n",
        "# create distributed config\n",
        "distr_config = PyTorchConfiguration(node_count=2)\n",
        "\n",
        "# define command\n",
        "launch_cmd = [\"python -m torch.distributed.launch --nproc_per_node 1 --nnodes 2 \" \\\n",
        "    \"--node_rank $NODE_RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT --use_env \" \\\n",
        "    \"train.py --data-dir\", dataset.as_download(), \"--epochs 25\"]\n",
        "\n",
        "# create job config\n",
        "src = ScriptRunConfig(source_directory=project_folder,\n",
        "                      command=launch_cmd,\n",
        "                      compute_target=compute_target,\n",
        "                      environment=pytorch_env,\n",
        "                      distributed_job_config=distr_config)\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### トレーニングジョブの実行 (送信)\n",
        "前項の`ScriptRunConfig`で設定した条件に基づいて実験を実行 (送信)します。\n",
        "Run your experiment by submitting your `ScriptRunConfig` object. Note that this call is asynchronous."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "run = experiment.submit(src)\n",
        "print(run)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### モニタリング\n",
        "Jupyterウィジェットを使って実行の進捗状況を監視することができます。実行のサブミッションと同様に、ウィジェットは非同期で、ジョブが完了するまで10～15秒ごとに自動で更新されます。ウィジェットでは、Azure MLの実行に記録した損失指標が自動的に表示・可視化されます。\n",
        "\n",
        "※VSCode上で実行する場合、テーマ設定 (背景色)によってはAzure MLウィジェットが見えにくくなる可能性があります。その場合はLightテーマの使用をお勧めします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.widgets import RunDetails\n",
        "\n",
        "RunDetails(run).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "また、スクリプトのトレーニングが完了するまでノートブックの実行をブロックしてから、さらにそれ以降のコードを実行していく形にもできます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "run.wait_for_completion(show_output=True) # this provides a verbose log"
      ]
    },
    {
      "source": [
        "## モデルの登録\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#実行に関係しているファイル一覧の表示\n",
        "for i in run.get_file_names():\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = run.register_model(model_name = 'pytorch-distr', model_path = 'outputs/cifar_net.pt')\n",
        "print(model.name, model.id, model.version, sep = '\\t')"
      ]
    },
    {
      "source": [
        "## モデルデプロイ\n",
        "Azure Container Instances (ACI) にモデルをWebサービスとしてモデルをデプロイしていきます。  \n",
        "参考：[Azure Container Instances とは](https://docs.microsoft.com/ja-jp/azure/container-instances/container-instances-overview)"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "### スコアリングスクリプトの作成\n",
        "Web サービスの呼び出しに使用される score.py というスコアリング スクリプトを作成してモデルの使用方法を示します。\n",
        "スコアリング スクリプトには、2 つの必要な関数を含める必要があります。\n",
        "- `init()` 関数。通常、グローバル オブジェクトにモデルを読み込みます。 この関数は、Docker コンテナーを開始するときに 1 回だけ実行されます。\n",
        "- `run(input_data)` 関数。モデルを使用して、入力データに基づく値を予測します。 実行に対する入力と出力は、通常、JSON を使用してシリアル化およびシリアル化解除が実行されますが、その他の形式もサポートされています。"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile score.py\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "\n",
        "from azureml.core.model import Model\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3) # in_channels, out_channels, kernel_size, \n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3)\n",
        "        self.fc1 = nn.Linear(128 * 6 * 6, 120)\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = x.view(-1, 128 * 6 * 6)\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def init():\n",
        "    global model\n",
        "    # AZUREML_MODEL_DIR is an environment variable created during deployment.\n",
        "    # It is the path to the model folder (./azureml-models/$MODEL_NAME/$VERSION)\n",
        "    # For multiple models, it points to the folder containing all deployed models (./azureml-models)\n",
        "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'cifar_net.pt')\n",
        "    model = Net()    \n",
        "    model.load_state_dict(torch.load(model_path,map_location=torch.device('cpu')))\n",
        "    model.eval()\n",
        "\n",
        "def run(input_data):\n",
        "    input_data = torch.tensor(json.loads(input_data)['data'])\n",
        "\n",
        "    # get prediction\n",
        "    with torch.no_grad():\n",
        "        input_data = input_data.unsqueeze(0) # add batch dimension\n",
        "        output = model(input_data) \n",
        "        classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "        softmax = nn.Softmax(dim=1)\n",
        "        pred_probs = softmax(output).numpy()[0]\n",
        "        index = torch.argmax(output, 1) \n",
        "\n",
        "    result = {\"label\": classes[index], \"probability\": str(pred_probs[index])}\n",
        "    return result"
      ]
    },
    {
      "source": [
        "### ACIコンテナへのデプロイ\n",
        "デプロイの構成ファイルを作成し、ACI コンテナーに必要な CPU 数と RAM ギガバイト数を指定します。 実際のモデルにもよりますが、通常、多くのモデルには既定値の 1 コアと 1 ギガバイトの RAM で十分です。 後でもっと必要になった場合は、イメージを再作成し、サービスをデプロイし直す必要があります。\n",
        "※今回はデプロイ先の実行環境にはトレーニング時と同一の環境を使用しています。"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "from azureml.core.webservice import AciWebservice\n",
        "from azureml.core.model import InferenceConfig\n",
        "from azureml.core.webservice import Webservice\n",
        "from azureml.core.model import Model\n",
        "\n",
        "#推論スクリプト・環境の指定\n",
        "inference_config = InferenceConfig(entry_script=\"score.py\", environment=pytorch_env) # 学習時と同じ環境を使用\n",
        "\n",
        "#デプロイの構成設定\n",
        "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n",
        "                                               memory_gb=1, \n",
        "                                               tags={'data': 'cifar-10',  'model':'pytorch-distr', 'framework':'pytorch'},\n",
        "                                               description='Classify daily objects from the cifar-10 dataset using PyTorch')\n",
        "\n",
        "model = Model(ws, 'pytorch-distr')\n",
        "\n",
        "service = Model.deploy(workspace=ws, \n",
        "                           name='aci-cifar10', \n",
        "                           models=[model], \n",
        "                           inference_config=inference_config, \n",
        "                           deployment_config=aciconfig,\n",
        "                           overwrite=True)\n",
        "\n",
        "service.wait_for_deployment(show_output=True)\n",
        "print(service.state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # デプロイ中に問題が発生した場合にログ取得\n",
        "# service.get_logs()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # 再デプロイ前に既存のACIサービスを削除\n",
        "# service.delete()"
      ]
    },
    {
      "source": [
        "## Webサービスのテスト\n",
        "最後に、デプロイしたWebサービスをテストしてみましょう。ACIにホストされているWebサービスにJSON文字列としてデータを送信し、SDKのrun APIを使ってサービスを呼び出してみます。ここでは、検証データから画像を取り出して予測を行います。\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing interactive authentication. Please follow the instructions on the terminal.\n",
            "To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code S8KCU8A72 to authenticate.\n",
            "You have logged in. Now let us find all the subscriptions to which you have access...\n",
            "Failed to authenticate to tenant '488ea627-1f1a-452d-8eb1-904f5c36ec3a' due to error 'Get Token request returned http error: 400 and server response: {\"error\":\"interaction_required\",\"error_description\":\"AADSTS50076: Due to a configuration change made by your administrator, or because you moved to a new location, you must use multi-factor authentication to access '797f4846-ba00-4fd7-ba43-dac1f8f63013'.\\r\\nTrace ID: b7eae072-2ff2-4ce0-80d7-07e47d6a4500\\r\\nCorrelation ID: 1215fad7-1130-45d6-804c-4321ad841e9f\\r\\nTimestamp: 2021-04-02 05:46:40Z\",\"error_codes\":[50076],\"timestamp\":\"2021-04-02 05:46:40Z\",\"trace_id\":\"b7eae072-2ff2-4ce0-80d7-07e47d6a4500\",\"correlation_id\":\"1215fad7-1130-45d6-804c-4321ad841e9f\",\"error_uri\":\"https://login.microsoftonline.com/error?code=50076\",\"suberror\":\"basic_action\"}'.Will continue to look for other tenants to find subscriptions to which you have access\n",
            "Interactive authentication successfully completed.\n"
          ]
        }
      ],
      "source": [
        "既存のACIWebサービスを取得する場合. serviceを定義する。\n",
        "fr azureml.core.workspace import Workspace\n",
        "fromzureml.core.webservice import AciWebservice\n",
        "ws = Wkspace.from_config()\n",
        "service AciWebservice(workspace=ws, name='aci-cifar10')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"231.84pt\" version=\"1.1\" viewBox=\"0 0 231.84 231.84\" width=\"231.84pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-04-02T16:25:07.949570</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.4, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 231.84 \nL 231.84 231.84 \nL 231.84 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g clip-path=\"url(#pb9b6b446ca)\">\n    <image height=\"218\" id=\"image0853d69aee\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"7.2\" xlink:href=\"data:image/png;base64,\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\" y=\"-6.64\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pb9b6b446ca\">\n   <rect height=\"217.44\" width=\"217.44\" x=\"7.2\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "horse\n"
          ]
        }
      ],
      "source": [
        "# CIFAR-10 データセット内のテスト画像を用いて推論を行う\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "\n",
        "# # オリジナル画像を表示したい場合\n",
        "# test_dataset = CIFAR10(root=\"cifar-10\", train=False, download=False)\n",
        "# image, target_class = test_dataset[99] # 99, 10とかわかりやすい\n",
        "# plt.imshow(image)\n",
        "# plt.show()\n",
        "# print(type(image))\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "test_dataset = CIFAR10(root=\"cifar-10\", train=False, download=False, transform=transform)\n",
        "image_tensor, target_class = test_dataset[99] #数字で対象画像を指定\n",
        "image_np = image_tensor.to('cpu').detach().numpy()\n",
        "input_data = image_np\n",
        "\n",
        "# plot image\n",
        "plt.axis('off')\n",
        "plt.imshow(image_tensor.permute(1, 2, 0)) \n",
        "plt.show()\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "print(classes[target_class])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'label': 'horse', 'probability': '0.9990004'}\n"
          ]
        }
      ],
      "source": [
        "# ACIへ送信して推論実行\n",
        "result = service.run(input_data=json.dumps({'data': input_data.tolist()}))\n",
        "print(result)"
      ]
    },
    {
      "source": [
        "## クリーンアップ\n",
        "最後に、デプロイされたWebサービスを削除します。"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "service.delete()"
      ]
    }
  ],
  "metadata": {
    "authors": [
      {
        "name": "minxia"
      }
    ],
    "category": "training",
    "compute": [
      "AML Compute"
    ],
    "datasets": [
      "CIFAR-10"
    ],
    "deployment": [
      "None"
    ],
    "exclude_from_index": false,
    "framework": [
      "PyTorch"
    ],
    "friendly_name": "Distributed training with PyTorch",
    "index_order": 1,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.6.13 64-bit ('azureml_env': conda)",
      "metadata": {
        "interpreter": {
          "hash": "a42a8c4c03685684dad491b418acc9fb57f943aca37dd55d301283286111ed4f"
        }
      }
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "tags": [
      "None"
    ],
    "task": "Train a model using distributed training via PyTorch DistributedDataParallel"
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Copyright (c) Microsoft Corporation. All rights reserved.\n",
        "Licensed under the MIT License.\n",
        "Modified by Shohei Nagata, 1st April 2021."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PyTorchの分散学習 (DistributedDataParallel版)\n",
        "本日のハンズオンでは[CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html)データセットを対象に、PyTorchの`DistributedDataParallel`モジュールを用いてGPUクラスター間で分散学習を行い、PyTorchモデルを学習します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 前提条件確認\n",
        "\n",
        "事前にAzure Machine Learning Python SDKをインストールし、Azure ML `Workspace`を作成してください。  \n",
        "※Azure Machine Learning Notebook VMを使用している場合は、すべての設定が完了しています。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Azure ML SDKのバージョン確認\n",
        "import azureml.core\n",
        "\n",
        "print(\"SDK version:\", azureml.core.VERSION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ワークスペースの設定\n",
        "Azure ML ワークスペースによってAzure MLで使用するアセット類 (データ、スクリプト、出力、等々)を管理していきます。\n",
        "![](https://docs.microsoft.com/ja-jp/azure/machine-learning/media/concept-azure-machine-learning-architecture/architecture.svg)\n",
        "\n",
        "前提条件のステップで作成した既存のワークスペースから、[Workspace](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#workspace)オブジェクトを初期化します。`Workspace.from_config()` は、`config.json` に格納された詳細情報から、ワークスペース・オブジェクトを作成します。   \n",
        "\n",
        "事前にAzure ML Studioから構成ファイル (config.json)をダウンロードし、本スクリプトと同一階層に置きます。  \n",
        "\n",
        "初回実行時は認証を行う必要があるため、実行結果部分の指示に従って https://microsoft.com/devicelogin にアクセスし、認証コードを入力します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core.workspace import Workspace\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "print('Workspace name: ' + ws.name, \n",
        "      'Azure region: ' + ws.location, \n",
        "      'Subscription id: ' + ws.subscription_id, \n",
        "      'Resource group: ' + ws.resource_group, sep='\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 計算環境の準備\n",
        "\n",
        "モデルをトレーニングするためには、[コンピューティング先](hhttps://docs.microsoft.com/ja-jp/azure/machine-learning/concept-azure-machine-learning-architecture#computes)を作成する必要があります。このノートブックでは、コンピューティング クラスターをリモートトレーニング用のコンピュートリソースとして使用します。  \n",
        "具体的には，以下のコードで，`STANDARD_NC6`のGPUクラスターを作成し，`0`から`4`のノードにオートスケールします。\n",
        "\n",
        "**コンピューティングクラスターの作成には約5分かかります。** 同一名称のものがワークスペースにある場合、下記コードは作成プロセスをスキップします。\n",
        "\n",
        "他のAzureサービスと同様に、Azure Machine Learningサービスに関連する特定のリソース（コンピューティング インスタンス、コンピューティング クラスターなど）には制限があります。  \n",
        "参考：[Azure Machine Learning を使用するリソースのクォータの管理と引き上げ](https://docs.microsoft.com/ja-jp/azure/machine-learning/how-to-manage-quotas)、\n",
        "[申請手順](https://docs.microsoft.com/ja-jp/azure/azure-portal/supportability/regional-quota-requests#request-a-quota-increase-by-region-from-help--support)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "# choose a name for your cluster\n",
        "cluster_name = 'gpu-cluster'\n",
        "\n",
        "try:\n",
        "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
        "    print('Found existing compute target.')\n",
        "except ComputeTargetException:\n",
        "    print('Creating a new compute target...')\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_NC6', # 使用するVMインスタンスを指定します.  (Standard_NC6s_v3)\n",
        "                                                           max_nodes=2)\n",
        "\n",
        "    # create the cluster\n",
        "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
        "\n",
        "    compute_target.wait_for_completion(show_output=True)\n",
        "\n",
        "# use get_status() to get a detailed status for the current AmlCompute. \n",
        "print(compute_target.get_status().serialize())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## データセットの準備\n",
        "\n",
        "学習に使用するデータセットを準備します。まず、cs.toronto.eduのサイトから公開されているCIFAR-10データセットをダウンロードして抽出し、Azure ML FileDatasetを作成して学習に使用します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### CIFAR-10 データのダウンロードと解凍"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import urllib\n",
        "import tarfile\n",
        "import os\n",
        "\n",
        "url = 'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'\n",
        "filename = 'cifar-10-python.tar.gz'\n",
        "data_root = 'cifar-10'\n",
        "filepath = os.path.join(data_root, filename)\n",
        "\n",
        "if not os.path.isdir(data_root):\n",
        "    os.makedirs(data_root, exist_ok=True)\n",
        "    urllib.request.urlretrieve(url, filepath)\n",
        "    with tarfile.open(filepath, \"r:gz\") as tar:\n",
        "        tar.extractall(path=data_root)\n",
        "    os.remove(filepath)  # delete tar.gz file after extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Azure MLデータセットの作成\n",
        "\n",
        "`upload_directory`メソッドは、データストアにデータをアップロードし、そこからFileDatasetを作成します。このチュートリアルでは、ワークスペースのデフォルトのデータストアを使用します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core import Dataset\n",
        "\n",
        "datastore = ws.get_default_datastore()\n",
        "dataset = Dataset.File.upload_directory(\n",
        "    src_dir=data_root, target=(datastore, data_root)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## リモートでのモデル学習 \n",
        "リモート (Azure ML上の)計算環境が準備できたので、分散学習ジョブを実行してみましょう。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### プロジェクトディレクトリの作成\n",
        "ローカルマシンからリモートリソースにアクセスするために必要なコードをすべて格納するディレクトリを作成します。このディレクトリには、トレーニングスクリプトと、トレーニングスクリプトが依存する追加ファイルが含まれます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "project_folder = './pytorch-distr'\n",
        "os.makedirs(project_folder, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### トレーニングスクリプトの準備\n",
        "ここでは、トレーニング用のスクリプトを作成します。このチュートリアルでは、CIFAR-10の分散学習用のスクリプトを`train.py`で用意しています。実際には、カスタムのPyTorchトレーニングスクリプトをそのまま使用して、コードを変更することなくAzure MLで実行することが可能です。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "トレーニングスクリプト `train.py`をプロジェクトディレクトリ内へコピーします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "shutil.copy('train.py', project_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 実験の作成\n",
        "[実験 (Experiment)](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#experiment)を作成して、この分散PyTorchチュートリアルのワークスペースでのすべての実行を追跡します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core import Experiment\n",
        "\n",
        "experiment_name = 'pytorch-distr'\n",
        "experiment = Experiment(ws, name=experiment_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 環境の作成\n",
        "\n",
        "Azure MLではいくつかの[キュレートされた実行環境](https://docs.microsoft.com/ja-jp/azure/machine-learning/how-to-use-environments#use-a-curated-environment)が用意されています。\n",
        "今回はPyTorch 1.6 GPU環境を使用します。こちらのキュレートされた環境には今回のトレーニングスクリプトで必要なtorch, torchvisionも含まれています。\n",
        "\n",
        "参考：[キュレーションされた環境一覧](https://docs.microsoft.com/ja-jp/azure/machine-learning/resource-curated-environments)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core import Environment\n",
        "\n",
        "pytorch_env = Environment.get(ws, name='AzureML-PyTorch-1.6-GPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 中身の確認\n",
        "print(pytorch_env.python.conda_dependencies.serialize_to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### トレーニングジョブの設定\n",
        "`ScriptRunConfig`を用いてスクリプトの実行構成を作成します。\n",
        "![](../img/scriptrunconfig.png)\n",
        "\n",
        "参考：[スクリプトの実行構成を作成する](https://docs.microsoft.com/ja-jp/azure/machine-learning/how-to-set-up-training-targets#create-the-script-run-configuration)\n",
        "\n",
        "#### 分散ジョブの構成を指定する\n",
        "分散トレーニング ジョブを実行する場合は、分散ジョブ固有の構成を `distributed_job_config` パラメーターに指定します。 \n",
        "\n",
        "\n",
        "Azure MLで分散PyTorchジョブを開始するには、次の2つの方法があります。\n",
        "\n",
        "1. プロセスごとの起動 - 実行するワーカープロセスの総数を指定します (通常、GPUごとに1つ)。\n",
        "Azure ML によって各プロセスの起動が処理されます。\n",
        "2. [torch.distributed.launch](https://pytorch.org/docs/stable/distributed.html#launch-utility) を使ったノード単位の起動 - 各ノードで実行したい「torch.distributed.launch」コマンドを指定します。Torch 起動ユーティリティによって、各ノードのワーカー プロセスの起動が処理されます。\n",
        "\n",
        "これらの起動オプションには、基本的な違いはありません。\n",
        "詳細は[ドキュメント](https://docs.microsoft.com/ja-jp/azure/machine-learning/how-to-train-pytorch#distributeddataparallel)を参照してください。\n",
        "\n",
        "両方のオプションを以下に示します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### プロセスごとの起動\n",
        "\n",
        "トレーニングスクリプトを実行するための各プロセスの起動をAzure MLが処理して分散 PyTorch ジョブを実行するには、次の操作を行います。\n",
        "\n",
        "1. トレーニング スクリプトと引数を指定します。\n",
        "2. `PyTorchConfiguration` を作成し、`process_count` と `node_count` を指定します。 `process_count` は、ジョブに対して実行するプロセスの合計数に対応しています。 これは通常、ノードあたりの GPU の数にノード数を掛けた値と同じにします。 `process_count` を指定しないと、Azure ML では、既定でノードごとに 1 つのプロセスが起動されます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core import ScriptRunConfig\n",
        "from azureml.core.runconfig import PyTorchConfiguration\n",
        "\n",
        "# create distributed config\n",
        "distr_config = PyTorchConfiguration(process_count=2, node_count=2)\n",
        "\n",
        "# create args\n",
        "args = [\"--data-dir\", dataset.as_download(), \"--epochs\", 25]\n",
        "\n",
        "# create job config\n",
        "src = ScriptRunConfig(source_directory=project_folder,\n",
        "                      script='train.py',\n",
        "                      arguments=args,\n",
        "                      compute_target=compute_target,\n",
        "                      environment=pytorch_env,\n",
        "                      distributed_job_config=distr_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### `torch.distributed.launch` によるノード毎の起動\n",
        "\n",
        "もし、PyTorchが提供する起動ユーティリティー `torch.distributed.launch` を使って、各ノードのワーカープロセスの起動を処理したい場合は、以下のようにしても構いません。\n",
        "\n",
        "1. ScriptRunConfigの`command`パラメータにlaunchコマンドを指定します。PyTorch のジョブの場合、Azure ML は各ノードに環境変数 `MASTER_ADDR`, `MASTER_PORT`, `NODE_RANK` を設定しますので、コマンドの中でこれらの環境変数を参照すればよいのです。GPU数が1以上のSKUを使用している場合は、`--nproc_per_node`の引数を適宜調整してください。\n",
        "\n",
        "2. `PyTorchConfiguration`を作成し、`node_count`を指定します。デフォルトでは、Azure MLはノードごとに1つのプロセスを起動して、指定した`コマンド`を実行しますので、`process_count`を指定する必要はありません。\n",
        "\n",
        "以下のコードをコメントアウト解除して、この方法でジョブを設定してください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "from azureml.core import ScriptRunConfig\n",
        "from azureml.core.runconfig import PyTorchConfiguration\n",
        "\n",
        "# create distributed config\n",
        "distr_config = PyTorchConfiguration(node_count=2)\n",
        "\n",
        "# define command\n",
        "launch_cmd = [\"python -m torch.distributed.launch --nproc_per_node 1 --nnodes 2 \" \\\n",
        "    \"--node_rank $NODE_RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT --use_env \" \\\n",
        "    \"train.py --data-dir\", dataset.as_download(), \"--epochs 25\"]\n",
        "\n",
        "# create job config\n",
        "src = ScriptRunConfig(source_directory=project_folder,\n",
        "                      command=launch_cmd,\n",
        "                      compute_target=compute_target,\n",
        "                      environment=pytorch_env,\n",
        "                      distributed_job_config=distr_config)\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### トレーニングジョブの実行 (送信)\n",
        "前項の`ScriptRunConfig`で設定した条件に基づいて実験を実行 (送信)します。\n",
        "Run your experiment by submitting your `ScriptRunConfig` object. Note that this call is asynchronous."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "run = experiment.submit(src)\n",
        "print(run)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### モニタリング\n",
        "Jupyterウィジェットを使って実行の進捗状況を監視することができます。実行のサブミッションと同様に、ウィジェットは非同期で、ジョブが完了するまで10～15秒ごとに自動で更新されます。ウィジェットでは、Azure MLの実行に記録した損失指標が自動的に表示・可視化されます。\n",
        "\n",
        "※VSCode上で実行する場合、テーマ設定 (背景色)によってはAzure MLウィジェットが見えにくくなる可能性があります。その場合はLightテーマの使用をお勧めします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.widgets import RunDetails\n",
        "\n",
        "RunDetails(run).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "また、スクリプトのトレーニングが完了するまでノートブックの実行をブロックしてから、さらにそれ以降のコードを実行していく形にもできます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "run.wait_for_completion(show_output=True) # this provides a verbose log"
      ]
    },
    {
      "source": [
        "## モデルの登録\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#実行に関係しているファイル一覧の表示\n",
        "for i in run.get_file_names():\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = run.register_model(model_name = 'pytorch-distr', model_path = 'outputs/cifar_net.pt')\n",
        "print(model.name, model.id, model.version, sep = '\\t')"
      ]
    },
    {
      "source": [
        "## モデルデプロイ\n",
        "Azure Container Instances (ACI) にモデルをWebサービスとしてモデルをデプロイしていきます。  \n",
        "参考：[Azure Container Instances とは](https://docs.microsoft.com/ja-jp/azure/container-instances/container-instances-overview)"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "### スコアリングスクリプトの作成\n",
        "Web サービスの呼び出しに使用される score.py というスコアリング スクリプトを作成してモデルの使用方法を示します。\n",
        "スコアリング スクリプトには、2 つの必要な関数を含める必要があります。\n",
        "- `init()` 関数。通常、グローバル オブジェクトにモデルを読み込みます。 この関数は、Docker コンテナーを開始するときに 1 回だけ実行されます。\n",
        "- `run(input_data)` 関数。モデルを使用して、入力データに基づく値を予測します。 実行に対する入力と出力は、通常、JSON を使用してシリアル化およびシリアル化解除が実行されますが、その他の形式もサポートされています。"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile score.py\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "\n",
        "from azureml.core.model import Model\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3) # in_channels, out_channels, kernel_size, \n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3)\n",
        "        self.fc1 = nn.Linear(128 * 6 * 6, 120)\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = x.view(-1, 128 * 6 * 6)\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def init():\n",
        "    global model\n",
        "    # AZUREML_MODEL_DIR is an environment variable created during deployment.\n",
        "    # It is the path to the model folder (./azureml-models/$MODEL_NAME/$VERSION)\n",
        "    # For multiple models, it points to the folder containing all deployed models (./azureml-models)\n",
        "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'cifar_net.pt')\n",
        "    model = Net()    \n",
        "    model.load_state_dict(torch.load(model_path,map_location=torch.device('cpu')))\n",
        "    model.eval()\n",
        "\n",
        "def run(input_data):\n",
        "    input_data = torch.tensor(json.loads(input_data)['data'])\n",
        "\n",
        "    # get prediction\n",
        "    with torch.no_grad():\n",
        "        input_data = input_data.unsqueeze(0) # add batch dimension\n",
        "        output = model(input_data) \n",
        "        classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "        softmax = nn.Softmax(dim=1)\n",
        "        pred_probs = softmax(output).numpy()[0]\n",
        "        index = torch.argmax(output, 1) \n",
        "\n",
        "    result = {\"label\": classes[index], \"probability\": str(pred_probs[index])}\n",
        "    return result"
      ]
    },
    {
      "source": [
        "### ACIコンテナへのデプロイ\n",
        "デプロイの構成ファイルを作成し、ACI コンテナーに必要な CPU 数と RAM ギガバイト数を指定します。 実際のモデルにもよりますが、通常、多くのモデルには既定値の 1 コアと 1 ギガバイトの RAM で十分です。 後でもっと必要になった場合は、イメージを再作成し、サービスをデプロイし直す必要があります。\n",
        "※今回はデプロイ先の実行環境にはトレーニング時と同一の環境を使用しています。"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "from azureml.core.webservice import AciWebservice\n",
        "from azureml.core.model import InferenceConfig\n",
        "from azureml.core.webservice import Webservice\n",
        "from azureml.core.model import Model\n",
        "\n",
        "#推論スクリプト・環境の指定\n",
        "inference_config = InferenceConfig(entry_script=\"score.py\", environment=pytorch_env) # 学習時と同じ環境を使用\n",
        "\n",
        "#デプロイの構成設定\n",
        "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n",
        "                                               memory_gb=1, \n",
        "                                               tags={'data': 'cifar-10',  'model':'pytorch-distr', 'framework':'pytorch'},\n",
        "                                               description='Classify daily objects from the cifar-10 dataset using PyTorch')\n",
        "\n",
        "model = Model(ws, 'pytorch-distr')\n",
        "\n",
        "service = Model.deploy(workspace=ws, \n",
        "                           name='aci-cifar10', \n",
        "                           models=[model], \n",
        "                           inference_config=inference_config, \n",
        "                           deployment_config=aciconfig,\n",
        "                           overwrite=True)\n",
        "\n",
        "service.wait_for_deployment(show_output=True)\n",
        "print(service.state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # デプロイ中に問題が発生した場合にログ取得\n",
        "# service.get_logs()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # 再デプロイ前に既存のACIサービスを削除\n",
        "# service.delete()"
      ]
    },
    {
      "source": [
        "## Webサービスのテスト\n",
        "最後に、デプロイしたWebサービスをテストしてみましょう。ACIにホストされているWebサービスにJSON文字列としてデータを送信し、SDKのrun APIを使ってサービスを呼び出してみます。ここでは、検証データから画像を取り出して予測を行います。\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing interactive authentication. Please follow the instructions on the terminal.\n",
            "To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code S8KCU8A72 to authenticate.\n",
            "You have logged in. Now let us find all the subscriptions to which you have access...\n",
            "Failed to authenticate to tenant '488ea627-1f1a-452d-8eb1-904f5c36ec3a' due to error 'Get Token request returned http error: 400 and server response: {\"error\":\"interaction_required\",\"error_description\":\"AADSTS50076: Due to a configuration change made by your administrator, or because you moved to a new location, you must use multi-factor authentication to access '797f4846-ba00-4fd7-ba43-dac1f8f63013'.\\r\\nTrace ID: b7eae072-2ff2-4ce0-80d7-07e47d6a4500\\r\\nCorrelation ID: 1215fad7-1130-45d6-804c-4321ad841e9f\\r\\nTimestamp: 2021-04-02 05:46:40Z\",\"error_codes\":[50076],\"timestamp\":\"2021-04-02 05:46:40Z\",\"trace_id\":\"b7eae072-2ff2-4ce0-80d7-07e47d6a4500\",\"correlation_id\":\"1215fad7-1130-45d6-804c-4321ad841e9f\",\"error_uri\":\"https://login.microsoftonline.com/error?code=50076\",\"suberror\":\"basic_action\"}'.Will continue to look for other tenants to find subscriptions to which you have access\n",
            "Interactive authentication successfully completed.\n"
          ]
        }
      ],
      "source": [
        "既存のACIWebサービスを取得する場合. serviceを定義する。\n",
        "fr azureml.core.workspace import Workspace\n",
        "fromzureml.core.webservice import AciWebservice\n",
        "ws = Wkspace.from_config()\n",
        "service AciWebservice(workspace=ws, name='aci-cifar10')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"231.84pt\" version=\"1.1\" viewBox=\"0 0 231.84 231.84\" width=\"231.84pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-04-02T15:14:06.863724</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.4, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 231.84 \nL 231.84 231.84 \nL 231.84 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g clip-path=\"url(#p9e1ab62222)\">\n    <image height=\"218\" id=\"imagefccb3ad33b\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"7.2\" xlink:href=\"data:image/png;base64,\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\" y=\"-6.64\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p9e1ab62222\">\n   <rect height=\"217.44\" width=\"217.44\" x=\"7.2\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "horse\n"
          ]
        }
      ],
      "source": [
        "# CIFAR-10 データセット内のテスト画像を用いて推論を行う\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "\n",
        "# # オリジナル画像を表示したい場合\n",
        "# test_dataset = CIFAR10(root=\"cifar-10\", train=False, download=False)\n",
        "# image, target_class = test_dataset[99] # 99, 10とかわかりやすい\n",
        "# plt.imshow(image)\n",
        "# plt.show()\n",
        "# print(type(image))\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),transforms.Normalize((0.4915, 0.4823, 0.4468), (0.2470, 0.2435, 0.2616))\n",
        "    ])\n",
        "test_dataset = CIFAR10(root=\"cifar-10\", train=False, download=False, transform=transform)\n",
        "image_tensor, target_class = test_dataset[99] #数字で対象画像を指定\n",
        "image_np = image_tensor.to('cpu').detach().numpy()\n",
        "input_data = image_np\n",
        "\n",
        "# plot image\n",
        "plt.axis('off')\n",
        "plt.imshow(image_tensor.permute(1, 2, 0)) \n",
        "plt.show()\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "print(classes[target_class])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'label': 'horse', 'probability': '0.9990004'}\n"
          ]
        }
      ],
      "source": [
        "# ACIへ送信して推論実行\n",
        "result = service.run(input_data=json.dumps({'data': input_data.tolist()}))\n",
        "print(result)"
      ]
    },
    {
      "source": [
        "## クリーンアップ\n",
        "最後に、デプロイされたWebサービスを削除します。"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "service.delete()"
      ]
    }
  ],
  "metadata": {
    "authors": [
      {
        "name": "minxia"
      }
    ],
    "category": "training",
    "compute": [
      "AML Compute"
    ],
    "datasets": [
      "CIFAR-10"
    ],
    "deployment": [
      "None"
    ],
    "exclude_from_index": false,
    "framework": [
      "PyTorch"
    ],
    "friendly_name": "Distributed training with PyTorch",
    "index_order": 1,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.6.13 64-bit ('azureml_env': conda)",
      "metadata": {
        "interpreter": {
          "hash": "a42a8c4c03685684dad491b418acc9fb57f943aca37dd55d301283286111ed4f"
        }
      }
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "tags": [
      "None"
    ],
    "task": "Train a model using distributed training via PyTorch DistributedDataParallel"
  },
  "nbformat": 4,
  "nbformat_minor": 2
}